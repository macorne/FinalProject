---
title: "Modeling"
author: "Matthew Corne"
date: "12-05-2024"
format: html
editor: visual
---

## Introduction

Write an intro!  We will include (at least) 5 predictors in this model:  age, sex, income, smoker, and heart disease or attack.

We will load the libraries and read in the data here:
```{r}
library(baguette)
library(corrplot)
library(ggplot2)
library(glmnet)
library(lubridate)
library(ranger)
#library(randomForest)
library(stringr)
library(tidymodels)
library(tidyverse)
library(vip)
library(vroom)

#diabetes_binary_health_indicators_BRFSS2015.csv
#dbhi = diabetes binary health indicators
data <- read_csv("diabetes_binary_health_indicators_BRFSS2015.csv")
data

```

Next, we will convert variables to factor variables, where appropriate:

```{r}
data <- data |>
  mutate(Diabetes_binary=
           factor(Diabetes_binary,
                  levels=c("0","1"),
                  labels=c("no diabetes","prediabetes or diabetes")),
         HighBP=
           factor(HighBP,
                  levels=c("0","1"),
                  labels=c("no high BP","high BP")),
         HighChol=
           factor(HighChol,
                  levels=c("0","1"),
                  labels=c("no high cholesterol","high cholesterol")),
         CholCheck=
           factor(CholCheck,
                  levels=c("0","1"),
                  labels=c("no cholesterol check in 5 years","yes cholesterol check in 5 years")),
         #BMI=factor(BMI),
         Smoker=
           factor(Smoker,
                  levels=c("0","1"),
                  labels=c("no","yes")),
         Stroke=
           factor(Stroke,
                  levels=c("0","1"),
                  labels=c("no","yes")),
         HeartDiseaseorAttack=
           factor(HeartDiseaseorAttack,
                  levels=c("0","1"),
                  labels=c("no","yes")),
         PhysActivity=
           factor(PhysActivity,
                  levels=c("0","1"),
                  labels=c("no","yes")),
         Fruits=
           factor(Fruits,
                  levels=c("0","1"),
                  labels=c("no","yes")),
         Veggies=
           factor(Veggies,
                  levels=c("0","1"),
                  labels=c("no","yes")),
         HvyAlcoholConsump=
           factor(HvyAlcoholConsump,
                  levels=c("0","1"),
                  labels=c("no","yes")),
         AnyHealthcare=
           factor(AnyHealthcare,
                  levels=c("0","1"),
                  labels=c("no","yes")),
         NoDocbcCost=
           factor(NoDocbcCost,
                  levels=c("0","1"),
                  labels=c("no","yes")),
         GenHlth=
           factor(GenHlth,
                  levels=c("1","2","3","4","5"),
                  labels=c("excellent","very good","good","fair","poor")),
         #MentHlth=
           #factor(MentHlth),
         #PhysHlth=
           #factor(PhysHlth),
         DiffWalk=
           factor(DiffWalk,
                  levels=c("0","1"),
                  labels=c("no difficulty walking","yes difficulty walking")),
         Sex=
           factor(Sex,
                  levels=c("0","1"),
                  labels=c("female","male")),
         Age=
           factor(Age,
                  levels=c("1","2","3","4","5","6","7","8","9","10","11","12","13"),
                  labels=c("18 to 24","25 to 29","30 to 34","35 to 39","40 to 44","45 to 49","50 to 54","55 to 59","60 to 64","65 to 69","70 to 74","75 to 79","80 or older")),
         Education=
           factor(Education,
                  levels=c("1","2","3","4","5","6"),
                  labels=c("Never attended school or only kindergarten","Grades 1 through 8 (Elementary)","Grades 9 through 11 (Some high school)","Grade 12 or GED (High school graduate)","College 1 year to 3 years (Some college or technical school)","College 4 years or more (College graduate)")),
         Income=
           factor(Income,
                  levels=c("1","2","3","4","5","6","7","8"),
                  labels=c("Less than $10,000","$10,000 to less than $15,000","$15,000 to less than $20,000","$20,000 to less than $25,000","$25,000 to less than $35,000","$35,000 to less than $50,000","$50,000 to less than $75,000","$75,000 or more"))
         )

```

Now, subset the data to look at the 5 predictors:

```{r}
dbhi_data <- data #|> 
#  select(Diabetes_binary,Age,HeartDiseaseorAttack,Income,Sex,Smoker)
dbhi_data

```


## Split the Data

Set the seed.  Then, use functions from tidymodels to split the data into a training and test set (70/30 split). Then, use the strata argument to stratify the split on the `Seasons` variable.

```{r}
set.seed(11)
dbhi_split <- initial_split(dbhi_data, prop = 0.70) #strata = argument goes in the parentheses, if needed
dbhi_train <- training(dbhi_split)
dbhi_test <- testing(dbhi_split)

```

We will perform 5-fold cross validation:

```{r}
dbhi_5_fold <- vfold_cv(dbhi_train, 5)

```

## Models

We will consider two kinds of models:  classification tree and random forest.  We will ...

Get a recipe.  Use the `date` variable to create a weekday/weekend factor variable. Then, standardize the numeric variables since their scales are pretty different. Finally, create dummy variables for the predictors since they need to be numeric (again).

```{r}
#bystanders <- colnames(dbhi_data)[c(2:4,7:18,21)]
#bystanders

#dbhi_train
#Diabetes_binary ~ Age + BMI + Income + Sex + Smoker
dbhi_recipe <- recipe(Diabetes_binary ~ ., data = dbhi_train) |>
  update_role(HighBP,HighChol,CholCheck,Stroke,HeartDiseaseorAttack,PhysActivity,Fruits,Veggies,HvyAlcoholConsump,AnyHealthcare,NoDocbcCost,GenHlth,MentHlth,PhysHlth,DiffWalk,Education,new_role = "bystander") |>
  step_dummy(all_nominal_predictors()) |>
  step_normalize(all_numeric(), -all_outcomes()) #|>
#  summary()
#  prep(training = dbhi_train) |>
#  bake(dbhi_train)

dbhi_recipe

```

### Classification Tree

You should provide a thorough explanation of what a classification tree model is. Then you should fit a classification tree with varying values for the complexity parameter and choose the best model (based on 5 fold CV on the training set). Include at least 5 predictors in this model.

First, tell `tidymodels` that we are performing a classification task:

```{r}
tree_mod <- decision_tree(tree_depth = tune(),
                          min_n = 20,
                          cost_complexity = tune()) |>
  set_engine("rpart") |>
  set_mode("classification")

```

Next, create a workflow to use in the fitting process:

```{r}
tree_wkf <- workflow() |>
  add_recipe(dbhi_recipe) |>
  add_model(tree_mod)

```

Then, to create the tuning grid for fitting our models, we use cross validation (CV) to select the tuning parameters:

```{r}
#temp <- tree_wkf |> 
#  tune_grid(resamples = dbhi_5_fold, metrics=metric_set(mn_log_loss))
#temp |> 
#  collect_metrics()

```

```{r}
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels = c(10, 5))

```

```{r}
tree_fits <- tree_wkf |> 
  tune_grid(resamples = dbhi_5_fold,
            metrics=metric_set(mn_log_loss),
            grid = tree_grid)
tree_fits |>
  collect_metrics()

```


Combine the metrics across the folds, then plot:

```{r}
tree_fits |>
  collect_metrics() |>
  mutate(tree_depth = factor(tree_depth)) |>
  ggplot(aes(cost_complexity, mean, color = tree_depth)) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0)

tree_fits

```


### Random Forest

You should provide a thorough explanation of what a random forest is and why we might use it (be sure to relate this to a basic classification tree). You should then fit a random forest model with varying values for the `mtry` parameter and choose the best model (based on 5 fold CV on the training set). Include at least 5 predictors in this model.

```{r}

```

## Final Model Selection

We will compare the best models from each of the approaches on the test set and declare an overall winner:

```{r}

```

