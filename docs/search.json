[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "FinalProjectEDA",
    "section": "",
    "text": "We will explore the Centers for Disease Control and Prevention (CDC) Behavioral Risk Factor Surveillance System (BRFSS) data set of diabetes binary health indicators from 2015. Two questions that we would like to address in this exploratory data analysis:\n\nWhich factors are most predictive of diabetes risk?\nCan we use a subset of the risk factors to accurately predict whether an individual has diabetes?"
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "FinalProjectEDA",
    "section": "",
    "text": "We will explore the Centers for Disease Control and Prevention (CDC) Behavioral Risk Factor Surveillance System (BRFSS) data set of diabetes binary health indicators from 2015. Two questions that we would like to address in this exploratory data analysis:\n\nWhich factors are most predictive of diabetes risk?\nCan we use a subset of the risk factors to accurately predict whether an individual has diabetes?"
  },
  {
    "objectID": "EDA.html#read-in-the-data",
    "href": "EDA.html#read-in-the-data",
    "title": "FinalProjectEDA",
    "section": "Read In The Data",
    "text": "Read In The Data\nWe will first read in the data:\n\nlibrary(ascii)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::expand() masks ascii::expand()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ tidyr::expand()   masks ascii::expand()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(vroom)\n\n\nAttaching package: 'vroom'\n\nThe following object is masked from 'package:yardstick':\n\n    spec\n\nThe following object is masked from 'package:scales':\n\n    col_factor\n\nThe following objects are masked from 'package:readr':\n\n    as.col_spec, col_character, col_date, col_datetime, col_double,\n    col_factor, col_guess, col_integer, col_logical, col_number,\n    col_skip, col_time, cols, cols_condense, cols_only, date_names,\n    date_names_lang, date_names_langs, default_locale, fwf_cols,\n    fwf_empty, fwf_positions, fwf_widths, locale, output_column,\n    problems, spec\n\n#diabetes_binary_health_indicators_BRFSS2015.csv\n\ndata &lt;- read_csv(\"./diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1               0      1        1         1    40      1      0\n 2               0      0        0         0    25      1      0\n 3               0      1        1         1    28      0      0\n 4               0      1        0         1    27      0      0\n 5               0      1        1         1    24      0      0\n 6               0      1        1         1    25      1      0\n 7               0      1        0         1    30      1      0\n 8               0      1        1         1    25      1      0\n 9               1      1        1         1    30      1      0\n10               0      0        0         1    24      0      0\n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nWe have 22 variables: 1 response (Diabetes_binary) and 21 possible predictors. From the 21, we will choose 6: Age, Sex, No Doctor Because of Cost, Stroke, Heart Disease or Attack, and Heavy Alcohol Consumption. We are focusing on these variables as predictors because they are related both to lifestyle and to health.\nOther variables, such as Age or Body Mass Index (BMI), are interesting but may be less helpful. Diabetes comes in different forms - at least Type 1 and Type 2 but possibly more - and we expect there to be fewer instances of diabetes (especially Type 2) among the young.\nThe BMI is dubious as a predictor because two people may share the same BMI but have very different body compositions; these differences can manifest as health problems for one person but not another. Since we lack family history, height, or weight of the respondents in this dataset, we can’t easily make an assessment. Further, since many of the variables are categorical, we cannot find correlations between them and any of the numeric variables."
  },
  {
    "objectID": "EDA.html#determine-the-rate-of-missing-values",
    "href": "EDA.html#determine-the-rate-of-missing-values",
    "title": "FinalProjectEDA",
    "section": "Determine The Rate of Missing Values",
    "text": "Determine The Rate of Missing Values\nWe want to check for missing values, since these can impact our results.\n\ndata |&gt;\n  is.na() |&gt;\n  colSums()\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n\nThe sums are 0 for each column, so there is no missing data. Otherwise, would might need to exclude observations or come up with a reasonable scheme for handling the missing observations."
  },
  {
    "objectID": "EDA.html#how-the-data-is-stored",
    "href": "EDA.html#how-the-data-is-stored",
    "title": "FinalProjectEDA",
    "section": "How The Data Is Stored",
    "text": "How The Data Is Stored\nWe will check for column type and values.\n\nattributes(data)$spec\n\ncols(\n  Diabetes_binary = col_double(),\n  HighBP = col_double(),\n  HighChol = col_double(),\n  CholCheck = col_double(),\n  BMI = col_double(),\n  Smoker = col_double(),\n  Stroke = col_double(),\n  HeartDiseaseorAttack = col_double(),\n  PhysActivity = col_double(),\n  Fruits = col_double(),\n  Veggies = col_double(),\n  HvyAlcoholConsump = col_double(),\n  AnyHealthcare = col_double(),\n  NoDocbcCost = col_double(),\n  GenHlth = col_double(),\n  MentHlth = col_double(),\n  PhysHlth = col_double(),\n  DiffWalk = col_double(),\n  Sex = col_double(),\n  Age = col_double(),\n  Education = col_double(),\n  Income = col_double()\n)\n\n\nWe have a number of categorical variables that would be good to convert to factors.\n\ndata &lt;- data |&gt;\n  mutate(Diabetes_binary=\n           factor(Diabetes_binary,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no diabetes\",\"prediabetes or diabetes\")),\n         HighBP=\n           factor(HighBP,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high BP\",\"high BP\")),\n         HighChol=\n           factor(HighChol,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high cholesterol\",\"high cholesterol\")),\n         CholCheck=\n           factor(CholCheck,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no cholesterol check in 5 years\",\"yes cholesterol check in 5 years\")),\n         #BMI=factor(BMI),\n         Smoker=\n           factor(Smoker,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Stroke=\n           factor(Stroke,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HeartDiseaseorAttack=\n           factor(HeartDiseaseorAttack,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         PhysActivity=\n           factor(PhysActivity,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Fruits=\n           factor(Fruits,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Veggies=\n           factor(Veggies,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HvyAlcoholConsump=\n           factor(HvyAlcoholConsump,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         AnyHealthcare=\n           factor(AnyHealthcare,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         NoDocbcCost=\n           factor(NoDocbcCost,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         GenHlth=\n           factor(GenHlth,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                  labels=c(\"excellent\",\"very good\",\"good\",\"fair\",\"poor\")),\n         #MentHlth=\n           #factor(MentHlth),\n         #PhysHlth=\n           #factor(PhysHlth),\n         DiffWalk=\n           factor(DiffWalk,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no difficulty walking\",\"yes difficulty walking\")),\n         Sex=\n           factor(Sex,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"female\",\"male\")),\n         Age=\n           factor(Age,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\"),\n                  labels=c(\"18 to 24\",\"25 to 29\",\"30 to 34\",\"35 to 39\",\"40 to 44\",\"45 to 49\",\"50 to 54\",\"55 to 59\",\"60 to 64\",\"65 to 69\",\"70 to 74\",\"75 to 79\",\"80 or older\")),\n         Education=\n           factor(Education,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"),\n                  labels=c(\"Never attended school or only kindergarten\",\"Grades 1 through 8 (Elementary)\",\"Grades 9 through 11 (Some high school)\",\"Grade 12 or GED (High school graduate)\",\"College 1 year to 3 years (Some college or technical school)\",\"College 4 years or more (College graduate)\")),\n         Income=\n           factor(Income,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"),\n                  labels=c(\"Less than $10,000\",\"$10,000 to less than $15,000\",\"$15,000 to less than $20,000\",\"$20,000 to less than $25,000\",\"$25,000 to less than $35,000\",\"$35,000 to less than $50,000\",\"$50,000 to less than $75,000\",\"$75,000 or more\"))\n         )"
  },
  {
    "objectID": "EDA.html#basic-data-validation",
    "href": "EDA.html#basic-data-validation",
    "title": "FinalProjectEDA",
    "section": "Basic Data Validation",
    "text": "Basic Data Validation\nSummarize each column to see if there are any unusual values.\n\nsummary(data)\n\n                Diabetes_binary          HighBP      \n no diabetes            :218334   no high BP:144851  \n prediabetes or diabetes: 35346   high BP   :108829  \n                                                     \n                                                     \n                                                     \n                                                     \n                                                     \n                HighChol                                 CholCheck     \n no high cholesterol:146089   no cholesterol check in 5 years :  9470  \n high cholesterol   :107591   yes cholesterol check in 5 years:244210  \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n      BMI        Smoker       Stroke       HeartDiseaseorAttack PhysActivity\n Min.   :12.00   no :141257   no :243388   no :229787           no : 61760  \n 1st Qu.:24.00   yes:112423   yes: 10292   yes: 23893           yes:191920  \n Median :27.00                                                              \n Mean   :28.38                                                              \n 3rd Qu.:31.00                                                              \n Max.   :98.00                                                              \n                                                                            \n Fruits       Veggies      HvyAlcoholConsump AnyHealthcare NoDocbcCost \n no : 92782   no : 47839   no :239424        no : 12417    no :232326  \n yes:160898   yes:205841   yes: 14256        yes:241263    yes: 21354  \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n      GenHlth         MentHlth         PhysHlth     \n excellent:45299   Min.   : 0.000   Min.   : 0.000  \n very good:89084   1st Qu.: 0.000   1st Qu.: 0.000  \n good     :75646   Median : 0.000   Median : 0.000  \n fair     :31570   Mean   : 3.185   Mean   : 4.242  \n poor     :12081   3rd Qu.: 2.000   3rd Qu.: 3.000  \n                   Max.   :30.000   Max.   :30.000  \n                                                    \n                   DiffWalk          Sex               Age       \n no difficulty walking :211005   female:141974   60 to 64:33244  \n yes difficulty walking: 42675   male  :111706   65 to 69:32194  \n                                                 55 to 59:30832  \n                                                 50 to 54:26314  \n                                                 70 to 74:23533  \n                                                 45 to 49:19819  \n                                                 (Other) :87744  \n                                                        Education     \n Never attended school or only kindergarten                  :   174  \n Grades 1 through 8 (Elementary)                             :  4043  \n Grades 9 through 11 (Some high school)                      :  9478  \n Grade 12 or GED (High school graduate)                      : 62750  \n College 1 year to 3 years (Some college or technical school): 69910  \n College 4 years or more (College graduate)                  :107325  \n                                                                      \n                          Income     \n $75,000 or more             :90385  \n $50,000 to less than $75,000:43219  \n $35,000 to less than $50,000:36470  \n $25,000 to less than $35,000:25883  \n $20,000 to less than $25,000:20135  \n $15,000 to less than $20,000:15994  \n (Other)                     :21594  \n\n\nThe categorical variables are summarized into (vertical) one-way contingency tables in descending order of number of respondents. Note that for more than six categories, the summaries lump values into “(Other).” We obtain measures of center and spread for the numerical variables. Some of the BMI values are extremely low or high; we will examine these when we perform a numerical analysis."
  },
  {
    "objectID": "EDA.html#investigate-distributions",
    "href": "EDA.html#investigate-distributions",
    "title": "FinalProjectEDA",
    "section": "Investigate Distributions",
    "text": "Investigate Distributions\n\nContingency Tables for Predictors and Responses\nWe will examine one-, two-, and three-way contingency tables for the predictors and response. We will also include Age for some assessments, since it may provide insight about certain categories.\n\nOne-Way Contingency Tables\nFor the one-way contingency table related to the response:\n\ntable(data$Diabetes_binary,dnn=\"Diabetes_binary\")\n\nDiabetes_binary\n            no diabetes prediabetes or diabetes \n                 218334                   35346 \n\n\nFor the predictors:\n\ntable(data$Age,dnn=\"Age\")\n\nAge\n   18 to 24    25 to 29    30 to 34    35 to 39    40 to 44    45 to 49 \n       5700        7598       11123       13823       16157       19819 \n   50 to 54    55 to 59    60 to 64    65 to 69    70 to 74    75 to 79 \n      26314       30832       33244       32194       23533       15980 \n80 or older \n      17363 \n\n\n\ntable(data$Sex,dnn=\"Sex\")\n\nSex\nfemale   male \n141974 111706 \n\n\n\ntable(data$NoDocbcCost,dnn=\"No Doctor Because of Cost\")\n\nNo Doctor Because of Cost\n    no    yes \n232326  21354 \n\n\n\ntable(data$Stroke,dnn=\"Stroke\")\n\nStroke\n    no    yes \n243388  10292 \n\n\n\ntable(data$HeartDiseaseorAttack,dnn=\"Heart Disease or Attack\")\n\nHeart Disease or Attack\n    no    yes \n229787  23893 \n\n\n\ntable(data$HvyAlcoholConsump,dnn=\"Heavy Alcohol Consumption\")\n\nHeavy Alcohol Consumption\n    no    yes \n239424  14256 \n\n\n\n\nTwo-Way Contingency Tables\nNext, we consider two-way contingency tables between the predictors and the response. We will use the ascii package so that we can make the tables look less muddled and more precise regarding categories.\nDiabetes_binary vs. Age:\n\nprint(ascii(table(data$Age,data$Diabetes_binary,dnn=c(\"Age\",\"Diabetes_binary\"))),type=\"rest\")\n\n\n+---------+-------------+---------------------+-------------------------+\n|                       | **Diabetes_binary**                           |\n+                       +---------------------+-------------------------+\n|                       | no diabetes         | prediabetes or diabetes |\n+=========+=============+=====================+=========================+\n| **Age** | 18 to 24    | 5622.00             | 78.00                   |\n+         +-------------+---------------------+-------------------------+\n|         | 25 to 29    | 7458.00             | 140.00                  |\n+         +-------------+---------------------+-------------------------+\n|         | 30 to 34    | 10809.00            | 314.00                  |\n+         +-------------+---------------------+-------------------------+\n|         | 35 to 39    | 13197.00            | 626.00                  |\n+         +-------------+---------------------+-------------------------+\n|         | 40 to 44    | 15106.00            | 1051.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 45 to 49    | 18077.00            | 1742.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 50 to 54    | 23226.00            | 3088.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 55 to 59    | 26569.00            | 4263.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 60 to 64    | 27511.00            | 5733.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 65 to 69    | 25636.00            | 6558.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 70 to 74    | 18392.00            | 5141.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 75 to 79    | 12577.00            | 3403.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 80 or older | 14154.00            | 3209.00                 |\n+---------+-------------+---------------------+-------------------------+\n\n\nDiabetes_binary vs. Sex:\n\nprint(ascii(table(data$Sex,data$Diabetes_binary,dnn=c(\"Sex\",\"Diabetes_binary\"))),type=\"rest\")\n\n\n+---------+--------+---------------------+-------------------------+\n|                  | **Diabetes_binary**                           |\n+                  +---------------------+-------------------------+\n|                  | no diabetes         | prediabetes or diabetes |\n+=========+========+=====================+=========================+\n| **Sex** | female | 123563.00           | 18411.00                |\n+         +--------+---------------------+-------------------------+\n|         | male   | 94771.00            | 16935.00                |\n+---------+--------+---------------------+-------------------------+\n\n\nDiabetes_binary vs. NoDocbcCost:\n\nprint(ascii(table(data$NoDocbcCost,data$Diabetes_binary,dnn=c(\"No Doctor Because of Cost\",\"Diabetes_binary\"))),type=\"rest\")\n\n\n+-------------------------------+-----+---------------------+-------------------------+\n|                                     | **Diabetes_binary**                           |\n+                                     +---------------------+-------------------------+\n|                                     | no diabetes         | prediabetes or diabetes |\n+===============================+=====+=====================+=========================+\n| **No Doctor Because of Cost** | no  | 200722.00           | 31604.00                |\n+                               +-----+---------------------+-------------------------+\n|                               | yes | 17612.00            | 3742.00                 |\n+-------------------------------+-----+---------------------+-------------------------+\n\n\nDiabetes_binary vs. Stroke:\n\nprint(ascii(table(data$Stroke,data$Diabetes_binary,dnn=c(\"Stroke\",\"Diabetes_binary\"))),type=\"rest\")\n\n\n+------------+-----+---------------------+-------------------------+\n|                  | **Diabetes_binary**                           |\n+                  +---------------------+-------------------------+\n|                  | no diabetes         | prediabetes or diabetes |\n+============+=====+=====================+=========================+\n| **Stroke** | no  | 211310.00           | 32078.00                |\n+            +-----+---------------------+-------------------------+\n|            | yes | 7024.00             | 3268.00                 |\n+------------+-----+---------------------+-------------------------+\n\n\nDiabetes_binary vs. HeartDiseaseorAttack:\n\nprint(ascii(table(data$HeartDiseaseorAttack,data$Diabetes_binary,dnn=c(\"Heart Disease or Attack\",\"Diabetes_binary\"))),type=\"rest\")\n\n\n+-----------------------------+-----+---------------------+-------------------------+\n|                                   | **Diabetes_binary**                           |\n+                                   +---------------------+-------------------------+\n|                                   | no diabetes         | prediabetes or diabetes |\n+=============================+=====+=====================+=========================+\n| **Heart Disease or Attack** | no  | 202319.00           | 27468.00                |\n+                             +-----+---------------------+-------------------------+\n|                             | yes | 16015.00            | 7878.00                 |\n+-----------------------------+-----+---------------------+-------------------------+\n\n\nDiabetes_binary vs. HvyAlcoholConsump:\n\nprint(ascii(table(data$HvyAlcoholConsump,data$Diabetes_binary,dnn=c(\"Heavy Alcohol Consumption\",\"Diabetes_binary\"))),type=\"rest\")\n\n\n+-------------------------------+-----+---------------------+-------------------------+\n|                                     | **Diabetes_binary**                           |\n+                                     +---------------------+-------------------------+\n|                                     | no diabetes         | prediabetes or diabetes |\n+===============================+=====+=====================+=========================+\n| **Heavy Alcohol Consumption** | no  | 204910.00           | 34514.00                |\n+                               +-----+---------------------+-------------------------+\n|                               | yes | 13424.00            | 832.00                  |\n+-------------------------------+-----+---------------------+-------------------------+\n\n\nWe will also examine a selection of two-way contingency tables among the different chosen predictors:\nSex vs. Age:\n\nprint(ascii(table(data$Age,data$Sex,dnn=c(\"Age\",\"Sex\"))),type=\"rest\")\n\n\n+---------+-------------+----------+----------+\n|                       | **Sex**             |\n+                       +----------+----------+\n|                       | female   | male     |\n+=========+=============+==========+==========+\n| **Age** | 18 to 24    | 2745.00  | 2955.00  |\n+         +-------------+----------+----------+\n|         | 25 to 29    | 3991.00  | 3607.00  |\n+         +-------------+----------+----------+\n|         | 30 to 34    | 6062.00  | 5061.00  |\n+         +-------------+----------+----------+\n|         | 35 to 39    | 7725.00  | 6098.00  |\n+         +-------------+----------+----------+\n|         | 40 to 44    | 9136.00  | 7021.00  |\n+         +-------------+----------+----------+\n|         | 45 to 49    | 10928.00 | 8891.00  |\n+         +-------------+----------+----------+\n|         | 50 to 54    | 14805.00 | 11509.00 |\n+         +-------------+----------+----------+\n|         | 55 to 59    | 17469.00 | 13363.00 |\n+         +-------------+----------+----------+\n|         | 60 to 64    | 18271.00 | 14973.00 |\n+         +-------------+----------+----------+\n|         | 65 to 69    | 17743.00 | 14451.00 |\n+         +-------------+----------+----------+\n|         | 70 to 74    | 13159.00 | 10374.00 |\n+         +-------------+----------+----------+\n|         | 75 to 79    | 9418.00  | 6562.00  |\n+         +-------------+----------+----------+\n|         | 80 or older | 10522.00 | 6841.00  |\n+---------+-------------+----------+----------+\n\n\nFor respondents between 18 to 24, more males than females responded to the survey. For the other age ranges, more females than males responded. Also, above age 74, there are significantly more female than male respondents; it is well-known that the average lifespan of males is less than that of females. So, it is likely that there are fewer males, compared with females, to respond to the survey.\nHeartDiseaseorAttack vs. Stroke:\n\nprint(ascii(table(data$Stroke,data$HeartDiseaseorAttack,dnn=c(\"Stroke\",\"Heart Disease or Attack\"))),type=\"rest\")\n\n\n+------------+-----+-----------------------------+----------+\n|                  | **Heart Disease or Attack**            |\n+                  +-----------------------------+----------+\n|                  | no                          | yes      |\n+============+=====+=============================+==========+\n| **Stroke** | no  | 223432.00                   | 19956.00 |\n+            +-----+-----------------------------+----------+\n|            | yes | 6355.00                     | 3937.00  |\n+------------+-----+-----------------------------+----------+\n\n\nWe see that among the respondents, some have been assessed to have both a stroke and heart disease.\nHvyAlcoholConsump vs. Stroke:\n\nprint(ascii(table(data$Stroke,data$HvyAlcoholConsump,dnn=c(\"Stroke\",\"Heavy Alcohol Consumption\"))),type=\"rest\")\n\n\n+------------+-----+-------------------------------+----------+\n|                  | **Heavy Alcohol Consumption**            |\n+                  +-------------------------------+----------+\n|                  | no                            | yes      |\n+============+=====+===============================+==========+\n| **Stroke** | no  | 229515.00                     | 13873.00 |\n+            +-----+-------------------------------+----------+\n|            | yes | 9909.00                       | 383.00   |\n+------------+-----+-------------------------------+----------+\n\n\nWe see that few of the respondents are both heavy drinkers and have been assessed to have a stroke. Also, we note that the largest numer of respondents report neither drinking heavily nor having been assessed to have had a stroke.\nHvyAlcoholConsump vs. HeartAttackorDisease:\n\nprint(ascii(table(data$HeartDiseaseorAttack,data$HvyAlcoholConsump,dnn=c(\"Heart Disease or Attack\",\"Heavy Alcohol Consumption\"))),type=\"rest\")\n\n\n+-----------------------------+-----+-------------------------------+----------+\n|                                   | **Heavy Alcohol Consumption**            |\n+                                   +-------------------------------+----------+\n|                                   | no                            | yes      |\n+=============================+=====+===============================+==========+\n| **Heart Disease or Attack** | no  | 216379.00                     | 13408.00 |\n+                             +-----+-------------------------------+----------+\n|                             | yes | 23045.00                      | 848.00   |\n+-----------------------------+-----+-------------------------------+----------+\n\n\nWe see that few of the respondents are both heavy drinkers and have heart disease or have had a heart attack. Also, we note that the largest numer of respondents report neither drinking heavily nor having been assessed to have heart disease or a heart attack. This is similar to heavy drinking vs. stroke.\n\n\nThree-Way Contingency Table\nFor a three-way contingency table relating diabetes status to age and sex:\n\n#Three-way contingency tables\nprint(ascii(table(data$Age,data$Sex,data$Diabetes_binary)),type=\"rest\")\n\n\n+----+-------------+--------+-------------------------+----------+\n|    | Var1        | Var2   | Var3                    | Freq     |\n+====+=============+========+=========================+==========+\n| 1  | 18 to 24    | female | no diabetes             | 2700.00  |\n+----+-------------+--------+-------------------------+----------+\n| 2  | 25 to 29    | female | no diabetes             | 3902.00  |\n+----+-------------+--------+-------------------------+----------+\n| 3  | 30 to 34    | female | no diabetes             | 5871.00  |\n+----+-------------+--------+-------------------------+----------+\n| 4  | 35 to 39    | female | no diabetes             | 7359.00  |\n+----+-------------+--------+-------------------------+----------+\n| 5  | 40 to 44    | female | no diabetes             | 8560.00  |\n+----+-------------+--------+-------------------------+----------+\n| 6  | 45 to 49    | female | no diabetes             | 10026.00 |\n+----+-------------+--------+-------------------------+----------+\n| 7  | 50 to 54    | female | no diabetes             | 13163.00 |\n+----+-------------+--------+-------------------------+----------+\n| 8  | 55 to 59    | female | no diabetes             | 15214.00 |\n+----+-------------+--------+-------------------------+----------+\n| 9  | 60 to 64    | female | no diabetes             | 15303.00 |\n+----+-------------+--------+-------------------------+----------+\n| 10 | 65 to 69    | female | no diabetes             | 14493.00 |\n+----+-------------+--------+-------------------------+----------+\n| 11 | 70 to 74    | female | no diabetes             | 10606.00 |\n+----+-------------+--------+-------------------------+----------+\n| 12 | 75 to 79    | female | no diabetes             | 7584.00  |\n+----+-------------+--------+-------------------------+----------+\n| 13 | 80 or older | female | no diabetes             | 8782.00  |\n+----+-------------+--------+-------------------------+----------+\n| 14 | 18 to 24    | male   | no diabetes             | 2922.00  |\n+----+-------------+--------+-------------------------+----------+\n| 15 | 25 to 29    | male   | no diabetes             | 3556.00  |\n+----+-------------+--------+-------------------------+----------+\n| 16 | 30 to 34    | male   | no diabetes             | 4938.00  |\n+----+-------------+--------+-------------------------+----------+\n| 17 | 35 to 39    | male   | no diabetes             | 5838.00  |\n+----+-------------+--------+-------------------------+----------+\n| 18 | 40 to 44    | male   | no diabetes             | 6546.00  |\n+----+-------------+--------+-------------------------+----------+\n| 19 | 45 to 49    | male   | no diabetes             | 8051.00  |\n+----+-------------+--------+-------------------------+----------+\n| 20 | 50 to 54    | male   | no diabetes             | 10063.00 |\n+----+-------------+--------+-------------------------+----------+\n| 21 | 55 to 59    | male   | no diabetes             | 11355.00 |\n+----+-------------+--------+-------------------------+----------+\n| 22 | 60 to 64    | male   | no diabetes             | 12208.00 |\n+----+-------------+--------+-------------------------+----------+\n| 23 | 65 to 69    | male   | no diabetes             | 11143.00 |\n+----+-------------+--------+-------------------------+----------+\n| 24 | 70 to 74    | male   | no diabetes             | 7786.00  |\n+----+-------------+--------+-------------------------+----------+\n| 25 | 75 to 79    | male   | no diabetes             | 4993.00  |\n+----+-------------+--------+-------------------------+----------+\n| 26 | 80 or older | male   | no diabetes             | 5372.00  |\n+----+-------------+--------+-------------------------+----------+\n| 27 | 18 to 24    | female | prediabetes or diabetes | 45.00    |\n+----+-------------+--------+-------------------------+----------+\n| 28 | 25 to 29    | female | prediabetes or diabetes | 89.00    |\n+----+-------------+--------+-------------------------+----------+\n| 29 | 30 to 34    | female | prediabetes or diabetes | 191.00   |\n+----+-------------+--------+-------------------------+----------+\n| 30 | 35 to 39    | female | prediabetes or diabetes | 366.00   |\n+----+-------------+--------+-------------------------+----------+\n| 31 | 40 to 44    | female | prediabetes or diabetes | 576.00   |\n+----+-------------+--------+-------------------------+----------+\n| 32 | 45 to 49    | female | prediabetes or diabetes | 902.00   |\n+----+-------------+--------+-------------------------+----------+\n| 33 | 50 to 54    | female | prediabetes or diabetes | 1642.00  |\n+----+-------------+--------+-------------------------+----------+\n| 34 | 55 to 59    | female | prediabetes or diabetes | 2255.00  |\n+----+-------------+--------+-------------------------+----------+\n| 35 | 60 to 64    | female | prediabetes or diabetes | 2968.00  |\n+----+-------------+--------+-------------------------+----------+\n| 36 | 65 to 69    | female | prediabetes or diabetes | 3250.00  |\n+----+-------------+--------+-------------------------+----------+\n| 37 | 70 to 74    | female | prediabetes or diabetes | 2553.00  |\n+----+-------------+--------+-------------------------+----------+\n| 38 | 75 to 79    | female | prediabetes or diabetes | 1834.00  |\n+----+-------------+--------+-------------------------+----------+\n| 39 | 80 or older | female | prediabetes or diabetes | 1740.00  |\n+----+-------------+--------+-------------------------+----------+\n| 40 | 18 to 24    | male   | prediabetes or diabetes | 33.00    |\n+----+-------------+--------+-------------------------+----------+\n| 41 | 25 to 29    | male   | prediabetes or diabetes | 51.00    |\n+----+-------------+--------+-------------------------+----------+\n| 42 | 30 to 34    | male   | prediabetes or diabetes | 123.00   |\n+----+-------------+--------+-------------------------+----------+\n| 43 | 35 to 39    | male   | prediabetes or diabetes | 260.00   |\n+----+-------------+--------+-------------------------+----------+\n| 44 | 40 to 44    | male   | prediabetes or diabetes | 475.00   |\n+----+-------------+--------+-------------------------+----------+\n| 45 | 45 to 49    | male   | prediabetes or diabetes | 840.00   |\n+----+-------------+--------+-------------------------+----------+\n| 46 | 50 to 54    | male   | prediabetes or diabetes | 1446.00  |\n+----+-------------+--------+-------------------------+----------+\n| 47 | 55 to 59    | male   | prediabetes or diabetes | 2008.00  |\n+----+-------------+--------+-------------------------+----------+\n| 48 | 60 to 64    | male   | prediabetes or diabetes | 2765.00  |\n+----+-------------+--------+-------------------------+----------+\n| 49 | 65 to 69    | male   | prediabetes or diabetes | 3308.00  |\n+----+-------------+--------+-------------------------+----------+\n| 50 | 70 to 74    | male   | prediabetes or diabetes | 2588.00  |\n+----+-------------+--------+-------------------------+----------+\n| 51 | 75 to 79    | male   | prediabetes or diabetes | 1569.00  |\n+----+-------------+--------+-------------------------+----------+\n| 52 | 80 or older | male   | prediabetes or diabetes | 1469.00  |\n+----+-------------+--------+-------------------------+----------+\n\n\nThis format flattens the three-way table, which is good in a way since we can see everything in one table rather than in two separated tables. We will provide an interpretation below when we examine the first bar chart below!\n\n\nNumeric Summaries\nAlthough we do not include any numeric variables as predictors, we will summarize our numeric variables over the entire set of respondents, then filter for diabetes status:\n\nsummary(data |&gt;\n          select(where(is.numeric)))\n\n      BMI           MentHlth         PhysHlth     \n Min.   :12.00   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:24.00   1st Qu.: 0.000   1st Qu.: 0.000  \n Median :27.00   Median : 0.000   Median : 0.000  \n Mean   :28.38   Mean   : 3.185   Mean   : 4.242  \n 3rd Qu.:31.00   3rd Qu.: 2.000   3rd Qu.: 3.000  \n Max.   :98.00   Max.   :30.000   Max.   :30.000  \n\nsummary(data |&gt;\n          filter(Diabetes_binary == \"no diabetes\") |&gt;\n          select(where(is.numeric)))\n\n      BMI           MentHlth         PhysHlth     \n Min.   :12.00   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:24.00   1st Qu.: 0.000   1st Qu.: 0.000  \n Median :27.00   Median : 0.000   Median : 0.000  \n Mean   :27.81   Mean   : 2.978   Mean   : 3.641  \n 3rd Qu.:31.00   3rd Qu.: 2.000   3rd Qu.: 2.000  \n Max.   :98.00   Max.   :30.000   Max.   :30.000  \n\nsummary(data |&gt;\n          filter(Diabetes_binary == \"prediabetes or diabetes\") |&gt;\n          select(where(is.numeric)))\n\n      BMI           MentHlth         PhysHlth     \n Min.   :13.00   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:27.00   1st Qu.: 0.000   1st Qu.: 0.000  \n Median :31.00   Median : 0.000   Median : 1.000  \n Mean   :31.94   Mean   : 4.462   Mean   : 7.954  \n 3rd Qu.:35.00   3rd Qu.: 3.000   3rd Qu.:15.000  \n Max.   :98.00   Max.   :30.000   Max.   :30.000  \n\n\nThe top table corresponds to overall correlation of the numeric variables. The second one from the top filters for no diabetes. The final one (bottom) is for prediabetes or diabetes.\nThe BMI among prediabetic and diabetic respondents is higher than among nondiabetics, though the IQR is similar. There seem to be outliers - the minimum and maximum BMI values seem too low and too high for a human being! However, it looks like CDC reports these using the typical BMI measure (these wouldn’t be percentiles since 12 being the lowest percentile would suggest a problem with the survey sample).\nPrediabetics and diabetics report more days with poor mental health than nondiabetics. The IQR is also larger, and the mean is notably larger. This pattern is more pronounced for physical health, where the mean number of days of reported bad health among prediabetics and diabetics is over twice that of nondiabetics. The IQR is also quite large for poor physical health days for prediabetics and diabetics when compared with nondiabetics. However, the 1st quartile for mental and physical health for all respondents is 0 days, and the medians are low (mostly 0), so that suggests many respondents did not report bad mental or physical health.\nWe will examine correlations among our numeric variables:\n\ndata |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  round(3)\n\n           BMI MentHlth PhysHlth\nBMI      1.000    0.085    0.121\nMentHlth 0.085    1.000    0.354\nPhysHlth 0.121    0.354    1.000\n\ndata |&gt;\n  filter(Diabetes_binary == \"no diabetes\") |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  round(3)\n\n           BMI MentHlth PhysHlth\nBMI      1.000    0.065    0.078\nMentHlth 0.065    1.000    0.336\nPhysHlth 0.078    0.336    1.000\n\ndata |&gt;\n  filter(Diabetes_binary == \"prediabetes or diabetes\") |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  round(3)\n\n           BMI MentHlth PhysHlth\nBMI      1.000    0.103    0.122\nMentHlth 0.103    1.000    0.391\nPhysHlth 0.122    0.391    1.000\n\n\nThe top table corresponds to overall correlation of the numeric variables. The second one from the top filters for no diabetes. The final one (bottom) is for prediabetes or diabetes.\nThe correlations between the different numeric variables are not strong. The strongest correlation is between mental and physical health, which is not surprising. For non-diabetics, the correlation between mental and physical health is weaker than for prediabetics and diabetics. The BMI is very weakly correlated with mental and physical health, regardless of diabetes status.\n\n\n\nBar Charts\nWe will look at bar charts to visualize counts of diabetes status by age and sex:\n\nggplot(data, \n       aes(\n         x = Diabetes_binary, fill = Age)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Age\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts vs. Diabetes Status, by Sex and Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nWe see a peak of respondents for nondiabetic males and females in the 60 to 64 age bracket, while there is a peak of prediabetic or diabetic respondents in the 65 to 69 age bracket. The three-way contingency table above has the precise counts provided in this visual.\nWe will also look for relationships between diabetes status, sex, and age:\n\nggplot(data |&gt; filter(Age %in% c(\"18 to 24\",\"25 to 29\")), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 18 to 29\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"30 to 34\",\"35 to 39\")), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 30 to 39\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"40 to 44\",\"45 to 49\")), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 40 to 49\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"50 to 54\",\"55 to 59\")), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 50 to 59\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"60 to 64\",\"65 to 69\")), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 60 to 69\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"70 to 74\",\"75 to 79\")), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 70 to 79\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age == \"80 or older\"), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 80 or Older\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nThe results are, perhaps, not surprising. In the youngest age bracket, there are almost no incidences of stroke, regardless of diabetic status. There are also few instances of diabetes. With increasing age, more respondents report having strokes, regardless of diabetes status. However, the proportion of strokes is higher among prediabetics and diabetics than among nondiabetics.\nFinally for this section, we will look for relationships between diabetes status, no doctor because of cost, and age:\n\nggplot(data |&gt; filter(Age %in% c(\"18 to 24\",\"25 to 29\")), \n       aes(\n         x = Diabetes_binary, fill = NoDocbcCost)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"NoDocbcCost\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of No Doctor Because of Cost vs. Diabetes Status, by Sex and Age 18 to 29\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"30 to 34\",\"35 to 39\")), \n       aes(\n         x = Diabetes_binary, fill = NoDocbcCost)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"NoDocbcCost\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of No Doctor Because of Cost vs. Diabetes Status, by Sex and Age 30 to 39\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"40 to 44\",\"45 to 49\")), \n       aes(\n         x = Diabetes_binary, fill = NoDocbcCost)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"NoDocbcCost\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of No Doctor Because of Cost vs. Diabetes Status, by Sex and Age 40 to 49\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"50 to 54\",\"55 to 59\")), \n       aes(\n         x = Diabetes_binary, fill = NoDocbcCost)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"NoDocbcCost\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of No Doctor Because of Cost vs. Diabetes Status, by Sex and Age 50 to 59\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"60 to 64\",\"65 to 69\")), \n       aes(\n         x = Diabetes_binary, fill = NoDocbcCost)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"NoDocbcCost\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of No Doctor Because of Cost vs. Diabetes Status, by Sex and Age 60 to 69\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"70 to 74\",\"75 to 79\")), \n       aes(\n         x = Diabetes_binary, fill = NoDocbcCost)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"NoDocbcCost\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of No Doctor Because of Cost vs. Diabetes Status, by Sex and Age 70 to 79\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age == \"80 or older\"), \n       aes(\n         x = Diabetes_binary, fill = NoDocbcCost)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"NoDocbcCost\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of No Doctor Because of Cost vs. Diabetes Status, by Sex and Age 80 or Older\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nSeemingly separate from diabetes status, it appears that not having a doctor because of cost is associated more with age (younger people report more often that they have no doctors because of cost.)\n\n\nScatterplots & Histograms For Numeric Variables\nWe will examine the relationship between the number of days of poor mental health (in the past 30 days) and the number of days of physical illness or injury (in the past 30 days), by age bracket, then filter for diabetes status:\n\n  ggplot(data,\n         aes(\n           x=PhysHlth,y=MentHlth,color=Age)) +\n  geom_point(alpha=0.01) +\n  geom_jitter(width = 0.2, alpha = 0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Mental Health vs. Physical Health, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data |&gt; filter(Diabetes_binary == \"no diabetes\"),\n         aes(\n           x=PhysHlth,y=MentHlth,color=Age)) +\n  geom_point(alpha=0.01) +\n  geom_jitter(width = 0.2, alpha = 0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Mental Health vs. Physical Health, by Age (No Diabetes)\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data |&gt; filter(Diabetes_binary == \"prediabetes or diabetes\"),\n         aes(\n           x=PhysHlth,y=MentHlth,color=Age)) +\n  geom_point(alpha=0.01) +\n  geom_jitter(width = 0.2, alpha = 0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Mental Health vs. Physical Health, by Age (Prediabetes or Diabetes)\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFor people younger than 60, there is a stronger association between mental and physical health than for people over 60, and especially than for people over 70.\nNext, we will examine the relationship of each of these to BMI, then stratify according to diabetes status:\n\n  ggplot(data,\n         aes(\n           x=BMI,y=PhysHlth,color=Age)) +\n  geom_point(alpha = 0.01) +\n  geom_jitter(width = 0.2, alpha=0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Physical Health vs. BMI, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data |&gt; filter(Diabetes_binary == \"no diabetes\"),\n         aes(\n           x=BMI,y=PhysHlth,color=Age)) +\n  geom_point(alpha = 0.01) +\n  geom_jitter(width = 0.2, alpha=0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Physical Health vs. BMI for Non-Diabetics, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data |&gt; filter(Diabetes_binary == \"prediabetes or diabetes\"),\n         aes(\n           x=BMI,y=PhysHlth,color=Age)) +\n  geom_point(alpha = 0.01) +\n  geom_jitter(width = 0.2, alpha=0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Physical Health vs. BMI for Prediabetics and Diabetics, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data,\n         aes(\n           x=BMI,y=MentHlth,color=Age)) +\n  geom_point(alpha = 0.01) +\n  geom_jitter(width = 0.2, alpha=0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Mental Health vs. BMI, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data |&gt; filter(Diabetes_binary == \"no diabetes\"),\n         aes(\n           x=BMI,y=MentHlth,color=Age)) +\n  geom_point(alpha = 0.01) +\n  geom_jitter(width = 0.2, alpha=0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Mental Health vs. BMI for Non-Diabetics, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data |&gt; filter(Diabetes_binary == \"prediabetes or diabetes\"),\n         aes(\n           x=BMI,y=MentHlth,color=Age)) +\n  geom_point(alpha = 0.01) +\n  geom_jitter(width = 0.2, alpha=0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Mental Health vs. BMI for Prediabetics and Diabetics, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe association between physical health and BMI grows stronger with age. We can see this by\nThen, we will examine the distributions of PhysHlth, MentHlth, and BMI based on whether individuals have diabetes.\n\nggplot(data,\n       aes(\n         x=PhysHlth\n       )) + \n  geom_histogram(alpha=0.5,\n    aes(fill = Diabetes_binary, \n        col=I(\"black\")),\n    position = \"identity\",\n    binwidth=1) + \n  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) + xlab(\"PhysHlth\") + ylab(\"Count\") + ggtitle(str_wrap(\"Count of Respondents per Number of Days of Physical Illness or Injury, by Diabetes Status\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data,\n       aes(\n         x=MentHlth\n       )) + \n  geom_histogram(alpha=0.5,\n    aes(fill = Diabetes_binary, \n        col=I(\"black\")),\n    position = \"identity\",\n    binwidth=1) + \n  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) + xlab(\"MentHlth\") + ylab(\"Count\") + ggtitle(str_wrap(\"Count of Respondents per Number of Poor Mental Health Days, by Diabetes Status\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data,\n       aes(\n         x=BMI\n       )) + \n  geom_histogram(alpha=0.5,\n    aes(y=after_stat(density),\n        fill = Diabetes_binary, \n        col=I(\"black\")),\n    position = \"identity\",\n    binwidth=1) + \n  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) + xlab(\"BMI\") + ylab(\"Density\") + ggtitle(str_wrap(\"Density of Respondents per BMI, by Diabetes Status\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nMost of the respondents indicated no poor mental health or poor physical health days. However, the ratio of prediabetics or diabetics to nondiabetics who reported number of days of physical illness or injury was greater at 30 days than at 0 days; the same is true for poor mental health days. However, this only shows an association and does not prove that the respondents’ illnesses were due to diabetes or something else.\nThe density of respondents by BMI, by diabetes status, shows a higher BMI for prediabetics and diabetics than for nondiabetics. (This is elucidated more clearly in the box plots below.). The peak density of respondents is the same at just over 25 BMI. However, the nondiabetic respondents’ BMI values fall off much more quickly than the prediabetic and diabetic respondents’ BMI values.\n\n\nBox Plots\nWe will look at box plots to see how the BMI varies by sex and diabetes status:\n\nggplot(data |&gt; filter(Age %in% c(\"18 to 24\",\"25 to 29\")), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"30 to 34\",\"35 to 39\")), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"40 to 44\",\"45 to 49\")), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"50 to 54\",\"55 to 59\")), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"60 to 64\",\"65 to 69\")), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"70 to 74\",\"75 to 79\")), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age == \"80 or older\"), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\n\nAmong the 18 to 29 age bracket, the distributions of BMI look right-skewed regardless of sex or diabetes status. 30 to 34 year old nondiabetic females continue to show a right-skewed distribution of BMI. The mean BMI (red dot) is notably higher than the median BMI in diabetic males and females between 18 and 29 years compared with other age brackets.\nInterestingly, 45 to 49 year old prediabetic and diabetic females show a slight right-skewed BMI again, as do 55 to 59 year old prediabetic and diabetic males.\n60 to 69 year old nondiabetic males show a right-skewed BMI distribution, as do 70 to 74 year old males and 80 or older females with no diabetes.\nIt is unclear without doing more analysis to determine why the BMI are skewed (lifestyle or other factors). Also, it is possibly beyond the scope of investigating diabetes status.\nIn most of the age brackets, prediabetics and diabetics have a wider IQR for their BMI than nondiabetics. The 1st, 2nd, and 3rd quartiles of prediabetics and diabetics tend to be higher than those of nondiabetics. Females with prediabetes or diabetes have medians that are near or above the 3rd quartile of nondiabetic women. This trend persists across age brackets."
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "Write an intro! We will include 6 predictors in this model: age, sex, no doctor because of cost, stroke, heart disease or attack, and heavy alcohol consumption. (We tried income but swapped it for age in a 5-predictor model.)\nWe will load the libraries and read in the data here:\n\nlibrary(baguette)\n\nLoading required package: parsnip\n\nlibrary(glmnet)\n\nLoading required package: Matrix\n\n\nLoaded glmnet 4.1-8\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(ranger)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tibble       3.2.1\n✔ dplyr        1.1.4     ✔ tidyr        1.3.1\n✔ ggplot2      3.5.1     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ purrr        1.0.2     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()  masks scales::discard()\n✖ tidyr::expand()   masks Matrix::expand()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ tidyr::pack()     masks Matrix::pack()\n✖ recipes::step()   masks stats::step()\n✖ tidyr::unpack()   masks Matrix::unpack()\n✖ recipes::update() masks Matrix::update(), stats::update()\n• Learn how to get started at https://www.tidymodels.org/start/\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats 1.0.0     ✔ stringr 1.5.1\n✔ readr   2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ readr::spec()       masks yardstick::spec()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(vroom)\n\n\nAttaching package: 'vroom'\n\nThe following objects are masked from 'package:readr':\n\n    as.col_spec, col_character, col_date, col_datetime, col_double,\n    col_factor, col_guess, col_integer, col_logical, col_number,\n    col_skip, col_time, cols, cols_condense, cols_only, date_names,\n    date_names_lang, date_names_langs, default_locale, fwf_cols,\n    fwf_empty, fwf_positions, fwf_widths, locale, output_column,\n    problems, spec\n\nThe following object is masked from 'package:yardstick':\n\n    spec\n\nThe following object is masked from 'package:scales':\n\n    col_factor\n\n#diabetes_binary_health_indicators_BRFSS2015.csv\n#dbhi = diabetes binary health indicators\ndata &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1               0      1        1         1    40      1      0\n 2               0      0        0         0    25      1      0\n 3               0      1        1         1    28      0      0\n 4               0      1        0         1    27      0      0\n 5               0      1        1         1    24      0      0\n 6               0      1        1         1    25      1      0\n 7               0      1        0         1    30      1      0\n 8               0      1        1         1    25      1      0\n 9               1      1        1         1    30      1      0\n10               0      0        0         1    24      0      0\n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nNext, we will convert variables to factor variables, where appropriate:\n\ndbhi_data &lt;- data |&gt;\n  mutate(Diabetes_binary=\n           factor(Diabetes_binary,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no diabetes\",\"prediabetes or diabetes\")),\n         HighBP=\n           factor(HighBP,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high BP\",\"high BP\")),\n         HighChol=\n           factor(HighChol,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high cholesterol\",\"high cholesterol\")),\n         CholCheck=\n           factor(CholCheck,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no cholesterol check in 5 years\",\"yes cholesterol check in 5 years\")),\n         Smoker=\n           factor(Smoker,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Stroke=\n           factor(Stroke,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HeartDiseaseorAttack=\n           factor(HeartDiseaseorAttack,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         PhysActivity=\n           factor(PhysActivity,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Fruits=\n           factor(Fruits,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Veggies=\n           factor(Veggies,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HvyAlcoholConsump=\n           factor(HvyAlcoholConsump,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         AnyHealthcare=\n           factor(AnyHealthcare,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         NoDocbcCost=\n           factor(NoDocbcCost,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         GenHlth=\n           factor(GenHlth,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                  labels=c(\"excellent\",\"very good\",\"good\",\"fair\",\"poor\")),\n         DiffWalk=\n           factor(DiffWalk,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no difficulty walking\",\"yes difficulty walking\")),\n         Sex=\n           factor(Sex,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"female\",\"male\")),\n         Age=\n           factor(Age,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\"),\n                  labels=c(\"18 to 24\",\"25 to 29\",\"30 to 34\",\"35 to 39\",\"40 to 44\",\"45 to 49\",\"50 to 54\",\"55 to 59\",\"60 to 64\",\"65 to 69\",\"70 to 74\",\"75 to 79\",\"80 or older\")),\n         Education=\n           factor(Education,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"),\n                  labels=c(\"Never attended school or only kindergarten\",\"Grades 1 through 8 (Elementary)\",\"Grades 9 through 11 (Some high school)\",\"Grade 12 or GED (High school graduate)\",\"College 1 year to 3 years (Some college or technical school)\",\"College 4 years or more (College graduate)\")),\n         Income=\n           factor(Income,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"),\n                  labels=c(\"Less than $10,000\",\"$10,000 to less than $15,000\",\"$15,000 to less than $20,000\",\"$20,000 to less than $25,000\",\"$25,000 to less than $35,000\",\"$35,000 to less than $50,000\",\"$50,000 to less than $75,000\",\"$75,000 or more\"))\n         )"
  },
  {
    "objectID": "Modeling.html#introduction",
    "href": "Modeling.html#introduction",
    "title": "Modeling",
    "section": "",
    "text": "Write an intro! We will include 6 predictors in this model: age, sex, no doctor because of cost, stroke, heart disease or attack, and heavy alcohol consumption. (We tried income but swapped it for age in a 5-predictor model.)\nWe will load the libraries and read in the data here:\n\nlibrary(baguette)\n\nLoading required package: parsnip\n\nlibrary(glmnet)\n\nLoading required package: Matrix\n\n\nLoaded glmnet 4.1-8\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(ranger)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tibble       3.2.1\n✔ dplyr        1.1.4     ✔ tidyr        1.3.1\n✔ ggplot2      3.5.1     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ purrr        1.0.2     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()  masks scales::discard()\n✖ tidyr::expand()   masks Matrix::expand()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ tidyr::pack()     masks Matrix::pack()\n✖ recipes::step()   masks stats::step()\n✖ tidyr::unpack()   masks Matrix::unpack()\n✖ recipes::update() masks Matrix::update(), stats::update()\n• Learn how to get started at https://www.tidymodels.org/start/\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats 1.0.0     ✔ stringr 1.5.1\n✔ readr   2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ readr::spec()       masks yardstick::spec()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(vroom)\n\n\nAttaching package: 'vroom'\n\nThe following objects are masked from 'package:readr':\n\n    as.col_spec, col_character, col_date, col_datetime, col_double,\n    col_factor, col_guess, col_integer, col_logical, col_number,\n    col_skip, col_time, cols, cols_condense, cols_only, date_names,\n    date_names_lang, date_names_langs, default_locale, fwf_cols,\n    fwf_empty, fwf_positions, fwf_widths, locale, output_column,\n    problems, spec\n\nThe following object is masked from 'package:yardstick':\n\n    spec\n\nThe following object is masked from 'package:scales':\n\n    col_factor\n\n#diabetes_binary_health_indicators_BRFSS2015.csv\n#dbhi = diabetes binary health indicators\ndata &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1               0      1        1         1    40      1      0\n 2               0      0        0         0    25      1      0\n 3               0      1        1         1    28      0      0\n 4               0      1        0         1    27      0      0\n 5               0      1        1         1    24      0      0\n 6               0      1        1         1    25      1      0\n 7               0      1        0         1    30      1      0\n 8               0      1        1         1    25      1      0\n 9               1      1        1         1    30      1      0\n10               0      0        0         1    24      0      0\n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nNext, we will convert variables to factor variables, where appropriate:\n\ndbhi_data &lt;- data |&gt;\n  mutate(Diabetes_binary=\n           factor(Diabetes_binary,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no diabetes\",\"prediabetes or diabetes\")),\n         HighBP=\n           factor(HighBP,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high BP\",\"high BP\")),\n         HighChol=\n           factor(HighChol,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high cholesterol\",\"high cholesterol\")),\n         CholCheck=\n           factor(CholCheck,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no cholesterol check in 5 years\",\"yes cholesterol check in 5 years\")),\n         Smoker=\n           factor(Smoker,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Stroke=\n           factor(Stroke,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HeartDiseaseorAttack=\n           factor(HeartDiseaseorAttack,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         PhysActivity=\n           factor(PhysActivity,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Fruits=\n           factor(Fruits,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Veggies=\n           factor(Veggies,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HvyAlcoholConsump=\n           factor(HvyAlcoholConsump,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         AnyHealthcare=\n           factor(AnyHealthcare,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         NoDocbcCost=\n           factor(NoDocbcCost,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         GenHlth=\n           factor(GenHlth,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                  labels=c(\"excellent\",\"very good\",\"good\",\"fair\",\"poor\")),\n         DiffWalk=\n           factor(DiffWalk,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no difficulty walking\",\"yes difficulty walking\")),\n         Sex=\n           factor(Sex,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"female\",\"male\")),\n         Age=\n           factor(Age,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\"),\n                  labels=c(\"18 to 24\",\"25 to 29\",\"30 to 34\",\"35 to 39\",\"40 to 44\",\"45 to 49\",\"50 to 54\",\"55 to 59\",\"60 to 64\",\"65 to 69\",\"70 to 74\",\"75 to 79\",\"80 or older\")),\n         Education=\n           factor(Education,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"),\n                  labels=c(\"Never attended school or only kindergarten\",\"Grades 1 through 8 (Elementary)\",\"Grades 9 through 11 (Some high school)\",\"Grade 12 or GED (High school graduate)\",\"College 1 year to 3 years (Some college or technical school)\",\"College 4 years or more (College graduate)\")),\n         Income=\n           factor(Income,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"),\n                  labels=c(\"Less than $10,000\",\"$10,000 to less than $15,000\",\"$15,000 to less than $20,000\",\"$20,000 to less than $25,000\",\"$25,000 to less than $35,000\",\"$35,000 to less than $50,000\",\"$50,000 to less than $75,000\",\"$75,000 or more\"))\n         )"
  },
  {
    "objectID": "Modeling.html#split-the-data",
    "href": "Modeling.html#split-the-data",
    "title": "Modeling",
    "section": "Split the Data",
    "text": "Split the Data\nSet the seed. Then, use functions from tidymodels to split the data into a training and test set (70/30 split). Then, use the strata argument to stratify the split on the Sex variable.\n\nset.seed(11)\ndbhi_split &lt;- initial_split(dbhi_data, prop = 0.70, strata=Sex) #strata = argument goes in the parentheses, if needed\ndbhi_train &lt;- training(dbhi_split)\ndbhi_test &lt;- testing(dbhi_split)\n\nWe will perform 5-fold cross validation:\n\ndbhi_5_fold &lt;- vfold_cv(dbhi_train, 5)\n\ndbhi_5_fold\n\n#  5-fold cross-validation \n# A tibble: 5 × 2\n  splits                 id   \n  &lt;list&gt;                 &lt;chr&gt;\n1 &lt;split [142060/35515]&gt; Fold1\n2 &lt;split [142060/35515]&gt; Fold2\n3 &lt;split [142060/35515]&gt; Fold3\n4 &lt;split [142060/35515]&gt; Fold4\n5 &lt;split [142060/35515]&gt; Fold5"
  },
  {
    "objectID": "Modeling.html#models",
    "href": "Modeling.html#models",
    "title": "Modeling",
    "section": "Models",
    "text": "Models\nWe will consider two kinds of models: classification tree and random forest. We will …\nGet a recipe. Then, standardize the numeric variables since their scales are pretty different. Finally, create dummy variables for the predictors since they need to be numeric (again).\n\n#bystanders &lt;- colnames(dbhi_data)[c(2:4,7:18,21)]\n#bystanders\n\n#dbhi_train\n#Diabetes_binary ~ Age + Sex + NoDocbcCost + Stroke + HeartAttackorDisease + HvyAlcoholConsump\n\ndbhi_recipe &lt;- recipe(Diabetes_binary ~ ., data = dbhi_train) |&gt;\n  update_role(Income,Smoker,BMI,HighBP,HighChol,CholCheck,PhysActivity,Fruits,Veggies,AnyHealthcare,GenHlth,MentHlth,PhysHlth,DiffWalk,Education,new_role = \"bystander\") |&gt;\n  step_dummy(all_nominal_predictors()) |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) #|&gt;\n#  summary()\n#  prep(training = dbhi_train) |&gt;\n#  bake(dbhi_train)\n\ndbhi_recipe\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor:  6\nbystander: 15\n\n\n\n\n\n── Operations \n\n\n• Dummy variables from: all_nominal_predictors()\n\n\n• Centering and scaling for: all_numeric() and -all_outcomes()\n\n\n\nClassification Tree\nA classification tree is a supervised learning, tree-based method with a goal of classifying (predicting) group membership. In tree-based methods, we attempt to split up the space of predictors into different regions. The tree typically chooses the most prevalent class in a region as the prediction. Then, over each region, we can make a different prediction. Note that adjacent regions need not have predictions close to each other.\nClassification trees have a categorical variable as a response. Once we’ve chosen our model form, we need to fit the model to the data. We split the data into a training set and a test set, then write the fitting process as the minimization of some loss function over the training data. Loss functions for classification trees include mean log loss (which we will use here), accuracy, area under the receiver operator characteristic curve (plot that illustrates performance of binary classifier model at different threshold values), and F1 score (related to precision and recall).\nWe tune on certain hyperparameters: tree depth (number of splits), the minimum number of data points in a note required for the node to be split further, and cost-complexity. We create a workflow, then a tuning grid where we use cross-validation to select the tuning parameters (here we also introduce the loss function). The goal is to obtain the hyperparameter values that minimize the loss function. We finalize the workflow, then fit on the test set to see how our model performs.\n\nProcedure\nFirst, tell tidymodels that we are performing a classification task:\n\n#For API.R, use\n#cost_complexity = 1e-10\n#tree_depth = 15 (was 11 using Income instead of Age)\n#min_n = 10\ntree_mod &lt;- decision_tree(tree_depth = tune(),\n                          min_n = 10,\n                          cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\nNext, create a workflow to use in the fitting process:\n\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(dbhi_recipe) |&gt;\n  add_model(tree_mod)\n\nThen, to create the tuning grid for fitting our models, we use cross validation (CV) to select the tuning parameters:\n\ntemp &lt;- tree_wkf |&gt; \n  tune_grid(resamples = dbhi_5_fold, metrics=metric_set(mn_log_loss))\ntemp |&gt; \n  collect_metrics()\n\n# A tibble: 10 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1        1.41e- 5          6 mn_log_loss binary     0.394     5 3.58e-3 Prepro…\n 2        9.46e- 3          9 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 3        1.05e-10         11 mn_log_loss binary     0.387     5 6.40e-4 Prepro…\n 4        2.89e- 4          3 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 5        2.97e- 8         13 mn_log_loss binary     0.387     5 6.58e-4 Prepro…\n 6        7.51e- 8          8 mn_log_loss binary     0.391     5 3.08e-3 Prepro…\n 7        5.06e- 5         14 mn_log_loss binary     0.392     5 2.81e-3 Prepro…\n 8        2.87e- 9          4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 9        5.92e- 2          1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n10        1.02e- 6         11 mn_log_loss binary     0.387     5 6.40e-4 Prepro…\n\n\n\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          #min_n(),\n                          tree_depth(),\n                          levels = c(5, 5))\n\ntree_grid\n\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             &lt;dbl&gt;      &lt;int&gt;\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# ℹ 15 more rows\n\n\nThis generates 25 (5x5) candidate decision tree models.\n\ntree_fits &lt;- tree_wkf |&gt; \n  tune_grid(resamples = dbhi_5_fold,\n            metrics=metric_set(mn_log_loss),\n            grid = tree_grid)\ntree_fits |&gt;\n  collect_metrics()\n\n# A tibble: 25 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1    0.0000000001          1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 2    0.0000000178          1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 3    0.00000316            1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 4    0.000562              1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 5    0.1                   1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 6    0.0000000001          4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 7    0.0000000178          4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 8    0.00000316            4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 9    0.000562              4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n10    0.1                   4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n# ℹ 15 more rows\n\n\nCombine the metrics across the folds, then plot:\n\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  mutate(tree_depth = factor(tree_depth)) |&gt;\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\ntree_fits\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits                 id    .metrics          .notes          \n  &lt;list&gt;                 &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          \n1 &lt;split [142060/35515]&gt; Fold1 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [142060/35515]&gt; Fold2 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [142060/35515]&gt; Fold3 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [142060/35515]&gt; Fold4 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [142060/35515]&gt; Fold5 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n\n\nOur best model has a tree_depth of 15 (this minimizes the mean log loss).\nArrange by the mean log loss:\n\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  arrange(mean)\n\n# A tibble: 25 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1    0.0000000001         15 mn_log_loss binary     0.387     5 6.48e-4 Prepro…\n 2    0.0000000178         15 mn_log_loss binary     0.387     5 6.48e-4 Prepro…\n 3    0.00000316           15 mn_log_loss binary     0.387     5 6.48e-4 Prepro…\n 4    0.0000000001         11 mn_log_loss binary     0.387     5 6.40e-4 Prepro…\n 5    0.0000000178         11 mn_log_loss binary     0.387     5 6.40e-4 Prepro…\n 6    0.00000316           11 mn_log_loss binary     0.387     5 6.40e-4 Prepro…\n 7    0.0000000001          8 mn_log_loss binary     0.391     5 3.08e-3 Prepro…\n 8    0.0000000178          8 mn_log_loss binary     0.391     5 3.08e-3 Prepro…\n 9    0.00000316            8 mn_log_loss binary     0.391     5 3.08e-3 Prepro…\n10    0.0000000001          1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n# ℹ 15 more rows\n\n\nGrab the best model’s tuning parameter values:\n\ntree_best_params &lt;- select_best(tree_fits)\n\nWarning in select_best(tree_fits): No value of `metric` was given;\n\"mn_log_loss\" will be used.\n\ntree_best_params\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1    0.0000000001         15 Preprocessor1_Model21\n\n\nThese are the values for tree_depth and cost_complexity that minimize mean log loss in the dbhi data set.\nFit this chosen model by finalize_workflow() to finalize the model on the training set:\n\ntree_final_wkf &lt;- tree_wkf |&gt;\n  finalize_workflow(tree_best_params)\n\ntree_final_wkf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_dummy()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 15\n  min_n = 10\n\nComputational engine: rpart \n\n\nPerform last_fit() on the dbhi_split object:\n\ntree_final_fit &lt;- tree_final_wkf |&gt;\n  last_fit(dbhi_split, metrics=metric_set(mn_log_loss))\ntree_final_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits                 id            .metrics .notes   .predictions .workflow \n  &lt;list&gt;                 &lt;chr&gt;         &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [177575/76105]&gt; train/test s… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n\nThis has information about how the final fitted model - which was fit on the entire training data set - performs on the test set.\nLook at the metric with collect_metrics():\n\ntree_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 mn_log_loss binary         0.393 Preprocessor1_Model1\n\n\nPlot to learn about the fit:\n\n#Extract the workflow to better understand the structure of the plot!\ntree_final_model &lt;- extract_workflow(tree_final_fit)\n\n#Plot!\ntree_final_model &lt;- tree_final_model |&gt;\n  extract_fit_engine() |&gt;\n  rpart.plot::rpart.plot(roundint = FALSE,extra=101,digits=-6)\n\nWarning: labs do not fit even at cex 0.15, there may be some overplotting\n\n\n\n\n\n\n\n\ntree_final_model\n\n$obj\nn= 177575 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n    1) root 177575 24553 no diabetes (0.86173166 0.13826834)  \n      2) HeartDiseaseorAttack_yes&lt; 1.386034 160791 19073 no diabetes (0.88138018 0.11861982)  \n        4) Stroke_yes&lt; 2.322867 156344 17926 no diabetes (0.88534258 0.11465742) *\n        5) Stroke_yes&gt;=2.322867 4447  1147 no diabetes (0.74207331 0.25792669)  \n         10) HvyAlcoholConsump_yes&gt;=1.923615 189    17 no diabetes (0.91005291 0.08994709) *\n         11) HvyAlcoholConsump_yes&lt; 1.923615 4258  1130 no diabetes (0.73461719 0.26538281)  \n           22) Age_X65.to.69&lt; 1.122195 3613   915 no diabetes (0.74674785 0.25325215)  \n             44) Age_X60.to.64&lt; 1.097894 3030   721 no diabetes (0.76204620 0.23795380)  \n               88) Age_X35.to.39&gt;=1.951873 71     7 no diabetes (0.90140845 0.09859155) *\n               89) Age_X35.to.39&lt; 1.951873 2959   714 no diabetes (0.75870226 0.24129774)  \n                178) Age_X80.or.older&gt;=1.722133 646   128 no diabetes (0.80185759 0.19814241) *\n                179) Age_X80.or.older&lt; 1.722133 2313   586 no diabetes (0.74664937 0.25335063)  \n                  358) Age_X40.to.44&gt;=1.783672 126    18 no diabetes (0.85714286 0.14285714) *\n                  359) Age_X40.to.44&lt; 1.783672 2187   568 no diabetes (0.74028349 0.25971651)  \n                    718) Age_X30.to.34&gt;=2.240538 39     3 no diabetes (0.92307692 0.07692308) *\n                    719) Age_X30.to.34&lt; 2.240538 2148   565 no diabetes (0.73696462 0.26303538)  \n                     1438) Age_X55.to.59&lt; 1.15564 1669   428 no diabetes (0.74355902 0.25644098)  \n                       2876) Age_X50.to.54&lt; 1.29714 1352   338 no diabetes (0.75000000 0.25000000)  \n                         5752) Age_X70.to.74&lt; 1.404896 729   173 no diabetes (0.76268861 0.23731139) *\n                         5753) Age_X70.to.74&gt;=1.404896 623   165 no diabetes (0.73515249 0.26484751)  \n                          11506) NoDocbcCost_yes&lt; 1.500513 600   156 no diabetes (0.74000000 0.26000000) *\n                          11507) NoDocbcCost_yes&gt;=1.500513 23     9 no diabetes (0.60869565 0.39130435)  \n                            23014) Sex_male&lt; 0.120171 16     5 no diabetes (0.68750000 0.31250000) *\n                            23015) Sex_male&gt;=0.120171 7     3 prediabetes or diabetes (0.42857143 0.57142857) *\n                       2877) Age_X50.to.54&gt;=1.29714 317    90 no diabetes (0.71608833 0.28391167) *\n                     1439) Age_X55.to.59&gt;=1.15564 479   137 no diabetes (0.71398747 0.28601253) *\n             45) Age_X60.to.64&gt;=1.097894 583   194 no diabetes (0.66723842 0.33276158) *\n           23) Age_X65.to.69&gt;=1.122195 645   215 no diabetes (0.66666667 0.33333333)  \n             46) Sex_male&lt; 0.120171 348   108 no diabetes (0.68965517 0.31034483) *\n             47) Sex_male&gt;=0.120171 297   107 no diabetes (0.63973064 0.36026936)  \n               94) NoDocbcCost_yes&lt; 1.500513 279    97 no diabetes (0.65232975 0.34767025) *\n               95) NoDocbcCost_yes&gt;=1.500513 18     8 prediabetes or diabetes (0.44444444 0.55555556) *\n      3) HeartDiseaseorAttack_yes&gt;=1.386034 16784  5480 no diabetes (0.67349857 0.32650143)  \n        6) Stroke_yes&lt; 2.322867 13995  4337 no diabetes (0.69010361 0.30989639) *\n        7) Stroke_yes&gt;=2.322867 2789  1143 no diabetes (0.59017569 0.40982431)  \n         14) Age_X80.or.older&gt;=1.722133 548   165 no diabetes (0.69890511 0.30109489) *\n         15) Age_X80.or.older&lt; 1.722133 2241   978 no diabetes (0.56358768 0.43641232)  \n           30) HvyAlcoholConsump_yes&gt;=1.923615 67    15 no diabetes (0.77611940 0.22388060) *\n           31) HvyAlcoholConsump_yes&lt; 1.923615 2174   963 no diabetes (0.55703772 0.44296228)  \n             62) Age_X30.to.34&gt;=2.240538 16     3 no diabetes (0.81250000 0.18750000) *\n             63) Age_X30.to.34&lt; 2.240538 2158   960 no diabetes (0.55514365 0.44485635)  \n              126) NoDocbcCost_yes&gt;=1.500513 403   165 no diabetes (0.59057072 0.40942928)  \n                252) Age_X75.to.79&lt; 1.790442 379   150 no diabetes (0.60422164 0.39577836)  \n                  504) Age_X70.to.74&lt; 1.404896 332   126 no diabetes (0.62048193 0.37951807)  \n                   1008) Age_X50.to.54&gt;=1.29714 51    15 no diabetes (0.70588235 0.29411765) *\n                   1009) Age_X50.to.54&lt; 1.29714 281   111 no diabetes (0.60498221 0.39501779)  \n                     2018) Age_X45.to.49&lt; 1.57069 249    96 no diabetes (0.61445783 0.38554217) *\n                     2019) Age_X45.to.49&gt;=1.57069 32    15 no diabetes (0.53125000 0.46875000)  \n                       4038) Sex_male&lt; 0.120171 19     8 no diabetes (0.57894737 0.42105263) *\n                       4039) Sex_male&gt;=0.120171 13     6 prediabetes or diabetes (0.46153846 0.53846154) *\n                  505) Age_X70.to.74&gt;=1.404896 47    23 prediabetes or diabetes (0.48936170 0.51063830)  \n                   1010) Sex_male&gt;=0.120171 15     7 no diabetes (0.53333333 0.46666667) *\n                   1011) Sex_male&lt; 0.120171 32    15 prediabetes or diabetes (0.46875000 0.53125000) *\n                253) Age_X75.to.79&gt;=1.790442 24     9 prediabetes or diabetes (0.37500000 0.62500000) *\n              127) NoDocbcCost_yes&lt; 1.500513 1755   795 no diabetes (0.54700855 0.45299145)  \n                254) Age_X60.to.64&lt; 1.097894 1475   652 no diabetes (0.55796610 0.44203390)  \n                  508) Age_X45.to.49&gt;=1.57069 50    16 no diabetes (0.68000000 0.32000000) *\n                  509) Age_X45.to.49&lt; 1.57069 1425   636 no diabetes (0.55368421 0.44631579)  \n                   1018) Age_X75.to.79&gt;=1.790442 325   135 no diabetes (0.58461538 0.41538462) *\n                   1019) Age_X75.to.79&lt; 1.790442 1100   501 no diabetes (0.54454545 0.45545455)  \n                     2038) Age_X35.to.39&gt;=1.951873 16     5 no diabetes (0.68750000 0.31250000) *\n                     2039) Age_X35.to.39&lt; 1.951873 1084   496 no diabetes (0.54243542 0.45756458)  \n                       4078) Age_X40.to.44&gt;=1.783672 12     4 no diabetes (0.66666667 0.33333333) *\n                       4079) Age_X40.to.44&lt; 1.783672 1072   492 no diabetes (0.54104478 0.45895522)  \n                         8158) Age_X65.to.69&lt; 1.122195 698   316 no diabetes (0.54727794 0.45272206)  \n                          16316) Age_X70.to.74&lt; 1.404896 296   131 no diabetes (0.55743243 0.44256757)  \n                            32632) Sex_male&lt; 0.120171 148    57 no diabetes (0.61486486 0.38513514) *\n                            32633) Sex_male&gt;=0.120171 148    74 no diabetes (0.50000000 0.50000000)  \n                              65266) Age_X50.to.54&gt;=1.29714 62    28 no diabetes (0.54838710 0.45161290) *\n                              65267) Age_X50.to.54&lt; 1.29714 86    40 prediabetes or diabetes (0.46511628 0.53488372) *\n                          16317) Age_X70.to.74&gt;=1.404896 402   185 no diabetes (0.53980100 0.46019900)  \n                            32634) Sex_male&gt;=0.120171 230    97 no diabetes (0.57826087 0.42173913) *\n                            32635) Sex_male&lt; 0.120171 172    84 prediabetes or diabetes (0.48837209 0.51162791) *\n                         8159) Age_X65.to.69&gt;=1.122195 374   176 no diabetes (0.52941176 0.47058824) *\n                255) Age_X60.to.64&gt;=1.097894 280   137 prediabetes or diabetes (0.48928571 0.51071429)  \n                  510) Sex_male&gt;=0.120171 166    82 no diabetes (0.50602410 0.49397590) *\n                  511) Sex_male&lt; 0.120171 114    53 prediabetes or diabetes (0.46491228 0.53508772) *\n\n$snipped.nodes\nNULL\n\n$xlim\n[1] 0 1\n\n$ylim\n[1] 0 1\n\n$x\n [1] 0.27334401 0.08904134 0.01518334 0.16289934 0.04050431 0.28529436\n [7] 0.20724195 0.09544885 0.06582529 0.12507242 0.09114627 0.15899857\n[13] 0.11646724 0.20152990 0.14178822 0.26127158 0.22882907 0.18926505\n[19] 0.16710920 0.21142090 0.19243017 0.23041164 0.21775115 0.24307212\n[25] 0.26839310 0.29371408 0.31903505 0.36334676 0.34435603 0.38233749\n[31] 0.36967701 0.39499798 0.45764669 0.42031896 0.49497442 0.44563994\n[37] 0.54430891 0.47096091 0.61765690 0.49628189 0.73903191 0.63159086\n[43] 0.58965299 0.54375872 0.52160286 0.56591457 0.54692384 0.58490531\n[49] 0.57224482 0.59756579 0.63554726 0.62288677 0.64820775 0.67352872\n[55] 0.84647297 0.72822599 0.69884970 0.75760228 0.72417068 0.79103388\n[61] 0.74949165 0.83257611 0.77481263 0.89033958 0.85394068 0.81912434\n[67] 0.80013360 0.83811507 0.82545458 0.85077556 0.88875702 0.87609653\n[73] 0.90141751 0.92673849 0.96471995 0.95205946 0.97738044\n\n$y\n [1] 0.986589416 0.883597953 0.008518208 0.873675901 0.055052913 0.817219143\n [7] 0.714227680 0.657770922 0.008518208 0.647848870 0.055052913 0.591392112\n[13] 0.008518208 0.534935354 0.055052913 0.478478597 0.375487133 0.319030375\n[19] 0.008518208 0.309108323 0.055052913 0.252651566 0.008518208 0.055052913\n[25] 0.008518208 0.055052913 0.008518208 0.760762385 0.055052913 0.704305628\n[31] 0.008518208 0.055052913 0.930132659 0.008518208 0.873675901 0.055052913\n[37] 0.817219143 0.008518208 0.760762385 0.055052913 0.704305628 0.601314164\n[43] 0.544857406 0.488400648 0.008518208 0.478478597 0.055052913 0.422021839\n[49] 0.008518208 0.055052913 0.534935354 0.008518208 0.055052913 0.008518208\n[55] 0.647848870 0.544857406 0.055052913 0.534935354 0.008518208 0.478478597\n[61] 0.055052913 0.422021839 0.008518208 0.365565081 0.262573617 0.206116860\n[67] 0.055052913 0.196194808 0.008518208 0.055052913 0.252651566 0.008518208\n[73] 0.055052913 0.008518208 0.591392112 0.055052913 0.008518208\n\n$branch.x\n      [,1]       [,2]       [,3]       [,4]       [,5]      [,6]      [,7]\nx 0.273344 0.08904134 0.01518334 0.16289934 0.04050431 0.2852944 0.2072420\n        NA 0.08904134 0.01518334 0.16289934 0.04050431 0.2852944 0.2072420\n        NA 0.27334401 0.08904134 0.08904134 0.16289934 0.1628993 0.2852944\n        [,8]       [,9]      [,10]      [,11]     [,12]     [,13]     [,14]\nx 0.09544885 0.06582529 0.12507242 0.09114627 0.1589986 0.1164672 0.2015299\n  0.09544885 0.06582529 0.12507242 0.09114627 0.1589986 0.1164672 0.2015299\n  0.20724195 0.09544885 0.09544885 0.12507242 0.1250724 0.1589986 0.1589986\n      [,15]     [,16]     [,17]     [,18]     [,19]     [,20]     [,21]\nx 0.1417882 0.2612716 0.2288291 0.1892650 0.1671092 0.2114209 0.1924302\n  0.1417882 0.2612716 0.2288291 0.1892650 0.1671092 0.2114209 0.1924302\n  0.2015299 0.2015299 0.2612716 0.2288291 0.1892650 0.1892650 0.2114209\n      [,22]     [,23]     [,24]     [,25]     [,26]     [,27]     [,28]\nx 0.2304116 0.2177511 0.2430721 0.2683931 0.2937141 0.3190351 0.3633468\n  0.2304116 0.2177511 0.2430721 0.2683931 0.2937141 0.3190351 0.3633468\n  0.2114209 0.2304116 0.2304116 0.2288291 0.2612716 0.2072420 0.2852944\n      [,29]     [,30]     [,31]     [,32]     [,33]     [,34]     [,35]\nx 0.3443560 0.3823375 0.3696770 0.3949980 0.4576467 0.4203190 0.4949744\n  0.3443560 0.3823375 0.3696770 0.3949980 0.4576467 0.4203190 0.4949744\n  0.3633468 0.3633468 0.3823375 0.3823375 0.2733440 0.4576467 0.4576467\n      [,36]     [,37]     [,38]     [,39]     [,40]     [,41]     [,42]\nx 0.4456399 0.5443089 0.4709609 0.6176569 0.4962819 0.7390319 0.6315909\n  0.4456399 0.5443089 0.4709609 0.6176569 0.4962819 0.7390319 0.6315909\n  0.4949744 0.4949744 0.5443089 0.5443089 0.6176569 0.6176569 0.7390319\n      [,43]     [,44]     [,45]     [,46]     [,47]     [,48]     [,49]\nx 0.5896530 0.5437587 0.5216029 0.5659146 0.5469238 0.5849053 0.5722448\n  0.5896530 0.5437587 0.5216029 0.5659146 0.5469238 0.5849053 0.5722448\n  0.6315909 0.5896530 0.5437587 0.5437587 0.5659146 0.5659146 0.5849053\n      [,50]     [,51]     [,52]     [,53]     [,54]     [,55]    [,56]\nx 0.5975658 0.6355473 0.6228868 0.6482077 0.6735287 0.8464730 0.728226\n  0.5975658 0.6355473 0.6228868 0.6482077 0.6735287 0.8464730 0.728226\n  0.5849053 0.5896530 0.6355473 0.6355473 0.6315909 0.7390319 0.846473\n      [,57]     [,58]     [,59]     [,60]     [,61]     [,62]     [,63]\nx 0.6988497 0.7576023 0.7241707 0.7910339 0.7494917 0.8325761 0.7748126\n  0.6988497 0.7576023 0.7241707 0.7910339 0.7494917 0.8325761 0.7748126\n  0.7282260 0.7282260 0.7576023 0.7576023 0.7910339 0.7910339 0.8325761\n      [,64]     [,65]     [,66]     [,67]     [,68]     [,69]     [,70]\nx 0.8903396 0.8539407 0.8191243 0.8001336 0.8381151 0.8254546 0.8507756\n  0.8903396 0.8539407 0.8191243 0.8001336 0.8381151 0.8254546 0.8507756\n  0.8325761 0.8903396 0.8539407 0.8191243 0.8191243 0.8381151 0.8381151\n      [,71]     [,72]     [,73]     [,74]    [,75]     [,76]     [,77]\nx 0.8887570 0.8760965 0.9014175 0.9267385 0.964720 0.9520595 0.9773804\n  0.8887570 0.8760965 0.9014175 0.9267385 0.964720 0.9520595 0.9773804\n  0.8539407 0.8887570 0.8887570 0.8903396 0.846473 0.9647200 0.9647200\n\n$branch.y\n       [,1]      [,2]       [,3]      [,4]       [,5]      [,6]      [,7]\ny 0.9999352 0.8969438 0.02186402 0.8688925 0.06839872 0.8305650 0.7275735\n         NA 0.9718840 0.86889251 0.8688925 0.85897046 0.8589705 0.8025137\n         NA 0.9718840 0.86889251 0.8688925 0.85897046 0.8589705 0.8025137\n       [,8]       [,9]     [,10]      [,11]     [,12]      [,13]     [,14]\ny 0.6711167 0.02186402 0.6430655 0.06839872 0.6047379 0.02186402 0.5482812\n  0.6995222 0.64306548 0.6430655 0.63314343 0.6331434 0.57668667 0.5766867\n  0.6995222 0.64306548 0.6430655 0.63314343 0.6331434 0.57668667 0.5766867\n       [,15]     [,16]     [,17]     [,18]      [,19]     [,20]      [,21]\ny 0.06839872 0.4918244 0.3888329 0.3323762 0.02186402 0.3043249 0.06839872\n  0.52022992 0.5202299 0.4637732 0.3607817 0.30432494 0.3043249 0.29440288\n  0.52022992 0.5202299 0.4637732 0.3607817 0.30432494 0.3043249 0.29440288\n      [,22]      [,23]      [,24]      [,25]      [,26]      [,27]     [,28]\ny 0.2659974 0.02186402 0.06839872 0.02186402 0.06839872 0.02186402 0.7741082\n  0.2944029 0.23794613 0.23794613 0.36078169 0.46377316 0.69952224 0.8025137\n  0.2944029 0.23794613 0.23794613 0.36078169 0.46377316 0.69952224 0.8025137\n       [,29]     [,30]      [,31]      [,32]     [,33]      [,34]     [,35]\ny 0.06839872 0.7176514 0.02186402 0.06839872 0.9434785 0.02186402 0.8870217\n  0.74605695 0.7460569 0.68960019 0.68960019 0.9718840 0.91542722 0.9154272\n  0.74605695 0.7460569 0.68960019 0.68960019 0.9718840 0.91542722 0.9154272\n       [,36]     [,37]      [,38]     [,39]      [,40]     [,41]     [,42]\ny 0.06839872 0.8305650 0.02186402 0.7741082 0.06839872 0.7176514 0.6146600\n  0.85897046 0.8589705 0.80251370 0.8025137 0.74605695 0.7460569 0.6896002\n  0.85897046 0.8589705 0.80251370 0.8025137 0.74605695 0.7460569 0.6896002\n      [,43]     [,44]      [,45]     [,46]      [,47]     [,48]      [,49]\ny 0.5582032 0.5017465 0.02186402 0.4736952 0.06839872 0.4353676 0.02186402\n  0.5866087 0.5301520 0.47369521 0.4736952 0.46377316 0.4637732 0.40731640\n  0.5866087 0.5301520 0.47369521 0.4736952 0.46377316 0.4637732 0.40731640\n       [,50]    [,51]      [,52]      [,53]      [,54]     [,55]     [,56]\ny 0.06839872 0.530152 0.02186402 0.06839872 0.02186402 0.6611947 0.5582032\n  0.40731640 0.530152 0.52022992 0.52022992 0.58660873 0.6896002 0.6331434\n  0.40731640 0.530152 0.52022992 0.52022992 0.58660873 0.6896002 0.6331434\n       [,57]    [,58]      [,59]     [,60]      [,61]     [,62]      [,63]\ny 0.06839872 0.530152 0.02186402 0.4918244 0.06839872 0.4353676 0.02186402\n  0.53015197 0.530152 0.52022992 0.5202299 0.46377316 0.4637732 0.40731640\n  0.53015197 0.530152 0.52022992 0.5202299 0.46377316 0.4637732 0.40731640\n      [,64]     [,65]     [,66]      [,67]     [,68]      [,69]      [,70]\ny 0.3789109 0.2759194 0.2194627 0.06839872 0.1914114 0.02186402 0.06839872\n  0.4073164 0.3508596 0.2478682 0.19141142 0.1914114 0.18148937 0.18148937\n  0.4073164 0.3508596 0.2478682 0.19141142 0.1914114 0.18148937 0.18148937\n      [,71]      [,72]      [,73]      [,74]     [,75]      [,76]      [,77]\ny 0.2478682 0.02186402 0.06839872 0.02186402 0.6047379 0.06839872 0.02186402\n  0.2478682 0.23794613 0.23794613 0.35085964 0.6331434 0.57668667 0.57668667\n  0.2478682 0.23794613 0.23794613 0.35085964 0.6331434 0.57668667 0.57668667\n\n$labs\n [1] \"no diabetes\\n153022  24553\\n100.0000%\"     \n [2] \"no diabetes\\n141718  19073\\n90.5482%\"      \n [3] \"no diabetes\\n138418  17926\\n88.0439%\"      \n [4] \"no diabetes\\n3300  1147\\n2.5043%\"          \n [5] \"no diabetes\\n172  17\\n0.1064%\"             \n [6] \"no diabetes\\n3128  1130\\n2.3979%\"          \n [7] \"no diabetes\\n2698  915\\n2.0346%\"           \n [8] \"no diabetes\\n2309  721\\n1.7063%\"           \n [9] \"no diabetes\\n64  7\\n0.0400%\"               \n[10] \"no diabetes\\n2245  714\\n1.6663%\"           \n[11] \"no diabetes\\n518  128\\n0.3638%\"            \n[12] \"no diabetes\\n1727  586\\n1.3025%\"           \n[13] \"no diabetes\\n108  18\\n0.0710%\"             \n[14] \"no diabetes\\n1619  568\\n1.2316%\"           \n[15] \"no diabetes\\n36  3\\n0.0220%\"               \n[16] \"no diabetes\\n1583  565\\n1.2096%\"           \n[17] \"no diabetes\\n1241  428\\n0.9399%\"           \n[18] \"no diabetes\\n1014  338\\n0.7614%\"           \n[19] \"no diabetes\\n556  173\\n0.4105%\"            \n[20] \"no diabetes\\n458  165\\n0.3508%\"            \n[21] \"no diabetes\\n444  156\\n0.3379%\"            \n[22] \"no diabetes\\n14  9\\n0.0130%\"               \n[23] \"no diabetes\\n11  5\\n0.0090%\"               \n[24] \"prediabetes or diabetes\\n3  4\\n0.0039%\"    \n[25] \"no diabetes\\n227  90\\n0.1785%\"             \n[26] \"no diabetes\\n342  137\\n0.2697%\"            \n[27] \"no diabetes\\n389  194\\n0.3283%\"            \n[28] \"no diabetes\\n430  215\\n0.3632%\"            \n[29] \"no diabetes\\n240  108\\n0.1960%\"            \n[30] \"no diabetes\\n190  107\\n0.1673%\"            \n[31] \"no diabetes\\n182  97\\n0.1571%\"             \n[32] \"prediabetes or diabetes\\n8  10\\n0.0101%\"   \n[33] \"no diabetes\\n11304  5480\\n9.4518%\"         \n[34] \"no diabetes\\n9658  4337\\n7.8812%\"          \n[35] \"no diabetes\\n1646  1143\\n1.5706%\"          \n[36] \"no diabetes\\n383  165\\n0.3086%\"            \n[37] \"no diabetes\\n1263  978\\n1.2620%\"           \n[38] \"no diabetes\\n52  15\\n0.0377%\"              \n[39] \"no diabetes\\n1211  963\\n1.2243%\"           \n[40] \"no diabetes\\n13  3\\n0.0090%\"               \n[41] \"no diabetes\\n1198  960\\n1.2153%\"           \n[42] \"no diabetes\\n238  165\\n0.2269%\"            \n[43] \"no diabetes\\n229  150\\n0.2134%\"            \n[44] \"no diabetes\\n206  126\\n0.1870%\"            \n[45] \"no diabetes\\n36  15\\n0.0287%\"              \n[46] \"no diabetes\\n170  111\\n0.1582%\"            \n[47] \"no diabetes\\n153  96\\n0.1402%\"             \n[48] \"no diabetes\\n17  15\\n0.0180%\"              \n[49] \"no diabetes\\n11  8\\n0.0107%\"               \n[50] \"prediabetes or diabetes\\n6  7\\n0.0073%\"    \n[51] \"prediabetes or diabetes\\n23  24\\n0.0265%\"  \n[52] \"no diabetes\\n8  7\\n0.0084%\"                \n[53] \"prediabetes or diabetes\\n15  17\\n0.0180%\"  \n[54] \"prediabetes or diabetes\\n9  15\\n0.0135%\"   \n[55] \"no diabetes\\n960  795\\n0.9883%\"            \n[56] \"no diabetes\\n823  652\\n0.8306%\"            \n[57] \"no diabetes\\n34  16\\n0.0282%\"              \n[58] \"no diabetes\\n789  636\\n0.8025%\"            \n[59] \"no diabetes\\n190  135\\n0.1830%\"            \n[60] \"no diabetes\\n599  501\\n0.6195%\"            \n[61] \"no diabetes\\n11  5\\n0.0090%\"               \n[62] \"no diabetes\\n588  496\\n0.6104%\"            \n[63] \"no diabetes\\n8  4\\n0.0068%\"                \n[64] \"no diabetes\\n580  492\\n0.6037%\"            \n[65] \"no diabetes\\n382  316\\n0.3931%\"            \n[66] \"no diabetes\\n165  131\\n0.1667%\"            \n[67] \"no diabetes\\n91  57\\n0.0833%\"              \n[68] \"no diabetes\\n74  74\\n0.0833%\"              \n[69] \"no diabetes\\n34  28\\n0.0349%\"              \n[70] \"prediabetes or diabetes\\n40  46\\n0.0484%\"  \n[71] \"no diabetes\\n217  185\\n0.2264%\"            \n[72] \"no diabetes\\n133  97\\n0.1295%\"             \n[73] \"prediabetes or diabetes\\n84  88\\n0.0969%\"  \n[74] \"no diabetes\\n198  176\\n0.2106%\"            \n[75] \"prediabetes or diabetes\\n137  143\\n0.1577%\"\n[76] \"no diabetes\\n84  82\\n0.0935%\"              \n[77] \"prediabetes or diabetes\\n53  61\\n0.0642%\"  \n\n$cex\n[1] 0.15\n\n$boxes\n$boxes$x1\n [1]  0.2579901214  0.0736874447 -0.0001705546  0.1506186183  0.0282235961\n [6]  0.2730136405  0.1949612363  0.0831681366  0.0535445724  0.1127917007\n[11]  0.0788655488  0.1467178526  0.1041865252  0.1892491801  0.1295075015\n[16]  0.2489908587  0.2165483578  0.1769843322  0.1548284779  0.1991401865\n[21]  0.1801494542  0.2181309188  0.2054704306  0.2199898533  0.2561123833\n[26]  0.2814333597  0.3067543361  0.3510660447  0.3320753124  0.3700567770\n[31]  0.3573962888  0.3719157114  0.4445679659  0.4080382415  0.4826937032\n[36]  0.4333592179  0.5320281886  0.4586801943  0.6053761828  0.4840011706\n[41]  0.7267511950  0.6193101381  0.5773722710  0.5314780013  0.5093221470\n[46]  0.5536338556  0.5346431234  0.5726245879  0.5599640997  0.5744835224\n[51]  0.6124649869  0.6106060525  0.6251254751  0.6504464515  0.8341922520\n[56]  0.7159452706  0.6865689816  0.7453215595  0.7118899579  0.7787531611\n[61]  0.7372109343  0.8202953880  0.7625319107  0.8780588653  0.8416599618\n[66]  0.8068436193  0.7878528870  0.8258343516  0.8131738634  0.8276932860\n[71]  0.8764763043  0.8638158161  0.8783352388  0.9144577689  0.9416376797\n[76]  0.9397787452  0.9542981679\n\n$boxes$y1\n [1]  0.9774451612  0.8744536976 -0.0006260477  0.8645316457  0.0459086582\n [6]  0.8080748880  0.7050834243  0.6486266665 -0.0006260477  0.6387046147\n[11]  0.0459086582  0.5822478569 -0.0006260477  0.5257910992  0.0459086582\n[16]  0.4693343414  0.3663428778  0.3098861200 -0.0006260477  0.2999640681\n[21]  0.0459086582  0.2435073104 -0.0006260477  0.0459086582 -0.0006260477\n[26]  0.0459086582 -0.0006260477  0.7516181302  0.0459086582  0.6951613724\n[31] -0.0006260477  0.0459086582  0.9209884035 -0.0006260477  0.8645316457\n[36]  0.0459086582  0.8080748880 -0.0006260477  0.7516181302  0.0459086582\n[41]  0.6951613724  0.5921699088  0.5357131510  0.4792563933 -0.0006260477\n[46]  0.4693343414  0.0459086582  0.4128775836 -0.0006260477  0.0459086582\n[51]  0.5257910992 -0.0006260477  0.0459086582 -0.0006260477  0.6387046147\n[56]  0.5357131510  0.0459086582  0.5257910992 -0.0006260477  0.4693343414\n[61]  0.0459086582  0.4128775836 -0.0006260477  0.3564208259  0.2534293622\n[66]  0.1969726045  0.0459086582  0.1870505526 -0.0006260477  0.0459086582\n[71]  0.2435073104 -0.0006260477  0.0459086582 -0.0006260477  0.5822478569\n[76]  0.0459086582 -0.0006260477\n\n$boxes$x2\n [1] 0.28869790 0.10439523 0.03053723 0.17518005 0.05278503 0.29757507\n [7] 0.21952267 0.10772957 0.07810601 0.13735314 0.10342698 0.17127929\n[13] 0.12874796 0.21381061 0.15406894 0.27355229 0.24110979 0.20154577\n[19] 0.17938991 0.22370162 0.20471089 0.24269235 0.23003187 0.26615440\n[25] 0.28067382 0.30599479 0.33131577 0.37562748 0.35663675 0.39461821\n[31] 0.38195772 0.41808025 0.47072541 0.43259968 0.50725514 0.45792065\n[37] 0.55658962 0.48324163 0.62993762 0.50856261 0.75131263 0.64387157\n[43] 0.60193371 0.55603944 0.53388358 0.57819529 0.55920456 0.59718602\n[49] 0.58452553 0.62064806 0.65862953 0.63516749 0.67129002 0.69661099\n[55] 0.85875369 0.74050670 0.71113042 0.76988299 0.73645139 0.80331460\n[61] 0.76177237 0.84485682 0.78709335 0.90262030 0.86622140 0.83140505\n[67] 0.81241432 0.85039579 0.83773530 0.87385783 0.90103774 0.88837725\n[73] 0.92449978 0.93901920 0.98780222 0.96434018 1.00046271\n\n$boxes$y2\n [1] 0.99993523 0.89694376 0.02186402 0.88702171 0.06839872 0.83056495\n [7] 0.72757349 0.67111673 0.02186402 0.66119468 0.06839872 0.60473792\n[13] 0.02186402 0.54828116 0.06839872 0.49182441 0.38883294 0.33237618\n[19] 0.02186402 0.32245413 0.06839872 0.26599737 0.02186402 0.06839872\n[25] 0.02186402 0.06839872 0.02186402 0.77410819 0.06839872 0.71765144\n[31] 0.02186402 0.06839872 0.94347847 0.02186402 0.88702171 0.06839872\n[37] 0.83056495 0.02186402 0.77410819 0.06839872 0.71765144 0.61465997\n[43] 0.55820322 0.50174646 0.02186402 0.49182441 0.06839872 0.43536765\n[49] 0.02186402 0.06839872 0.54828116 0.02186402 0.06839872 0.02186402\n[55] 0.66119468 0.55820322 0.06839872 0.54828116 0.02186402 0.49182441\n[61] 0.06839872 0.43536765 0.02186402 0.37891089 0.27591943 0.21946267\n[67] 0.06839872 0.20954062 0.02186402 0.06839872 0.26599737 0.02186402\n[73] 0.06839872 0.02186402 0.60473792 0.06839872 0.02186402\n\n\n$split.labs\n[1] \"\"\n\n$split.cex\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[77] 1\n\n$split.box\n$split.box$x1\n [1] 0.23610436 0.06669615         NA 0.12504245         NA 0.25988199\n [7] 0.18182958 0.06884197         NA 0.09562507         NA 0.13239168\n[13]         NA 0.17492301         NA 0.23585920 0.20341670 0.16499026\n[19]         NA 0.18191862         NA 0.20840602         NA         NA\n[25]         NA         NA         NA 0.34134115         NA 0.35283521\n[31]         NA         NA 0.43530150         NA 0.46552707         NA\n[37] 0.50645202         NA 0.59105001         NA 0.70833512 0.60617848\n[43] 0.56537820 0.51715183         NA 0.54050220         NA 0.56289969\n[49]         NA         NA 0.61234713         NA         NA         NA\n[55] 0.82106060 0.70161910         NA 0.73099539         NA 0.76442699\n[61]         NA 0.80596922         NA 0.86492721 0.82966589 0.79711872\n[67]         NA 0.81150818         NA         NA 0.86555690         NA\n[73]         NA         NA 0.94151983         NA         NA\n\n$split.box$y1\n [1] 0.9676824 0.8646910        NA 0.8547689        NA 0.7983122 0.6953207\n [8] 0.6388639        NA 0.6289419        NA 0.5724851        NA 0.5160284\n[15]        NA 0.4595716 0.3565801 0.3001234        NA 0.2902013        NA\n[22] 0.2337446        NA        NA        NA        NA        NA 0.7418554\n[29]        NA 0.6853986        NA        NA 0.9112257        NA 0.8547689\n[36]        NA 0.7983122        NA 0.7418554        NA 0.6853986 0.5824072\n[43] 0.5259504 0.4694937        NA 0.4595716        NA 0.4031148        NA\n[50]        NA 0.5160284        NA        NA        NA 0.6289419 0.5259504\n[57]        NA 0.5160284        NA 0.4595716        NA 0.4031148        NA\n[64] 0.3466581 0.2436666 0.1872099        NA 0.1772878        NA        NA\n[71] 0.2337446        NA        NA        NA 0.5724851        NA        NA\n\n$split.box$x2\n [1] 0.3105837 0.1113865        NA 0.2007562        NA 0.3107067 0.2326543\n [8] 0.1220557        NA 0.1545198        NA 0.1856055        NA 0.2281368\n[15]        NA 0.2866839 0.2542414 0.2135398        NA 0.2409232        NA\n[22] 0.2524172        NA        NA        NA        NA        NA 0.3853524\n[29]        NA 0.4118398        NA        NA 0.4799919        NA 0.5244218\n[36]        NA 0.5821658        NA 0.6442638        NA 0.7697287 0.6570032\n[43] 0.6139278 0.5703656        NA 0.5913269        NA 0.6069109        NA\n[50]        NA 0.6587474        NA        NA        NA 0.8718853 0.7548329\n[57]        NA 0.7842092        NA 0.8176408        NA 0.8591830        NA\n[64] 0.9157520 0.8782155 0.8411299        NA 0.8647220        NA        NA\n[71] 0.9119571        NA        NA        NA 0.9879201        NA        NA\n\n$split.box$y2\n [1] 0.9760855 0.8730941        NA 0.8631720        NA 0.8067153 0.7037238\n [8] 0.6472670        NA 0.6373450        NA 0.5808882        NA 0.5244315\n[15]        NA 0.4679747 0.3649832 0.3085265        NA 0.2986044        NA\n[22] 0.2421477        NA        NA        NA        NA        NA 0.7502585\n[29]        NA 0.6938017        NA        NA 0.9196288        NA 0.8631720\n[36]        NA 0.8067153        NA 0.7502585        NA 0.6938017 0.5908103\n[43] 0.5343535 0.4778968        NA 0.4679747        NA 0.4115180        NA\n[50]        NA 0.5244315        NA        NA        NA 0.6373450 0.5343535\n[57]        NA 0.5244315        NA 0.4679747        NA 0.4115180        NA\n[64] 0.3550612 0.2520697 0.1956130        NA 0.1856909        NA        NA\n[71] 0.2421477        NA        NA        NA 0.5808882        NA        NA\n\n\n\n\n\nRandom Forest\nA random forest is an ensemble learning method, which can be used for classification. It creates a multitude of decision trees during training. For classification tasks, the output of the random forest is the class selected by most trees.\nRandom forests have three tuning parameters: the number of predictors that will be randomly sampled at each split when creating tree models (mtry); the number of trees; and the minimal node size. Once we have decided on our model, we follow a similar workflow and cross-validation scheme as for classification trees. (As an alternative to cross-validation, we could use out-of-bag observations.) If using cross-validation, then we check the metrics across the folds, sort by the loss function (same kinds as for classification trees), get the best tuning parameter, and refit across the entire training data set.\n\nProcedure\nGet the random forest (rf) specification:\n\n#mtry=9 for the API.R file (was 11 for Age instead of Income, back to 9 by adding NoDocbcCost; 9 for Income instead of Age)\nrf_spec &lt;- rand_forest(mtry = tune()) |&gt;\n set_engine(\"ranger\", importance=\"impurity\") |&gt;\n set_mode(\"classification\")\n\nCreate the workflow using the same recipe:\n\nrf_wkf &lt;- workflow() |&gt;\n add_recipe(dbhi_recipe) |&gt;\n add_model(rf_spec)\n\nFit to the cross-validation folds:\n\nrf_fit &lt;- rf_wkf |&gt;\n tune_grid(resamples = dbhi_5_fold,\n           grid = 7,\n           metrics = metric_set(mn_log_loss))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\nrf_fit\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits                 id    .metrics         .notes          \n  &lt;list&gt;                 &lt;chr&gt; &lt;list&gt;           &lt;list&gt;          \n1 &lt;split [142060/35515]&gt; Fold1 &lt;tibble [7 × 5]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [142060/35515]&gt; Fold2 &lt;tibble [7 × 5]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [142060/35515]&gt; Fold3 &lt;tibble [7 × 5]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [142060/35515]&gt; Fold4 &lt;tibble [7 × 5]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [142060/35515]&gt; Fold5 &lt;tibble [7 × 5]&gt; &lt;tibble [0 × 3]&gt;\n\n\nArrange by the mean log loss:\n\nrf_fit |&gt;\n collect_metrics() |&gt;\n arrange(mean)\n\n# A tibble: 7 × 7\n   mtry .metric     .estimator  mean     n  std_err .config             \n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1     9 mn_log_loss binary     0.370     5 0.000563 Preprocessor1_Model2\n2    12 mn_log_loss binary     0.370     5 0.000590 Preprocessor1_Model7\n3    14 mn_log_loss binary     0.370     5 0.000589 Preprocessor1_Model6\n4    15 mn_log_loss binary     0.370     5 0.000600 Preprocessor1_Model3\n5     6 mn_log_loss binary     0.370     5 0.000515 Preprocessor1_Model5\n6     5 mn_log_loss binary     0.371     5 0.000512 Preprocessor1_Model1\n7     3 mn_log_loss binary     0.373     5 0.000450 Preprocessor1_Model4\n\n\nObtain the best tuning parameter, use it to refit on the entire training set, examine mn_log_loss, then extract the final model:\n\n#Obtain best tuning parameter\nrf_best_params &lt;- select_best(rf_fit)\n\nWarning in select_best(rf_fit): No value of `metric` was given; \"mn_log_loss\"\nwill be used.\n\nrf_best_params\n\n# A tibble: 1 × 2\n   mtry .config             \n  &lt;int&gt; &lt;chr&gt;               \n1     9 Preprocessor1_Model2\n\n#Refit on the entire training set\nrf_final_wkf &lt;- rf_wkf |&gt;\n  finalize_workflow(rf_best_params)\n\nrf_final_fit &lt;- rf_final_wkf |&gt;\n  last_fit(dbhi_split, metrics = metric_set(mn_log_loss))\n\n#Examine mn_log_loss\nrf_final_fit |&gt; collect_metrics()\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 mn_log_loss binary         0.375 Preprocessor1_Model1\n\n#Extract the final model\nrf_final_model &lt;- extract_fit_engine(rf_final_fit)\nattributes(rf_final_model)\n\n$names\n [1] \"predictions\"               \"num.trees\"                \n [3] \"num.independent.variables\" \"mtry\"                     \n [5] \"min.node.size\"             \"variable.importance\"      \n [7] \"prediction.error\"          \"forest\"                   \n [9] \"splitrule\"                 \"treetype\"                 \n[11] \"call\"                      \"importance.mode\"          \n[13] \"num.samples\"               \"replace\"                  \n[15] \"max.depth\"                \n\n$class\n[1] \"ranger\"\n\n\nProduce a variable importance plot to examine the final model:\n\nimp &lt;- enframe(rf_final_model$variable.importance,\n        name = \"variable\",\n        value = \"importance\")\nggplot(imp, aes(x = reorder(variable, -importance), y = importance)) +\n  geom_bar(stat = 'identity') + \n  xlab('term') +\n  ylab('value') +\n  coord_flip()\n\n\n\n\n\n\n\n\nThe most important predictor of diabetes status, among those we considered, is whether or not the respondent has been diagnosed with heart disease or a heart attack. Stroke is less important but next in line. Older age, with alcohol consumption, not having a doctor because of cost, male sex, and younger ages are less importance."
  },
  {
    "objectID": "Modeling.html#final-model-selection",
    "href": "Modeling.html#final-model-selection",
    "title": "Modeling",
    "section": "Final Model Selection",
    "text": "Final Model Selection\nRandom forest is best on the test set, so we will fit it to the entire data set:\n\n#Investigate the random forest model\n#Refit to the entire data set\nbest_model &lt;- rf_final_wkf |&gt;\n  fit(dbhi_data)\n\nbest_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_dummy()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~9L,      x), importance = ~\"impurity\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  500 \nSample size:                      253680 \nNumber of independent variables:  17 \nMtry:                             9 \nTarget node size:                 10 \nVariable importance mode:         impurity \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.1120441"
  }
]