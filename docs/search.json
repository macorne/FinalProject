[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "FinalProjectEDA",
    "section": "",
    "text": "We will explore the Centers for Disease Control and Prevention (CDC) Behavioral Risk Factor Surveillance System (BRFSS) data set of diabetes binary health indicators from 2015. Two questions that we would like to address in this exploratory data analysis:\n\nWhich factors are most predictive of diabetes risk?\nCan we use a subset of the risk factors to accurately predict whether an individual has diabetes?"
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "FinalProjectEDA",
    "section": "",
    "text": "We will explore the Centers for Disease Control and Prevention (CDC) Behavioral Risk Factor Surveillance System (BRFSS) data set of diabetes binary health indicators from 2015. Two questions that we would like to address in this exploratory data analysis:\n\nWhich factors are most predictive of diabetes risk?\nCan we use a subset of the risk factors to accurately predict whether an individual has diabetes?"
  },
  {
    "objectID": "EDA.html#read-in-the-data",
    "href": "EDA.html#read-in-the-data",
    "title": "FinalProjectEDA",
    "section": "Read In The Data",
    "text": "Read In The Data\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\nlibrary(vroom)\n\n\nAttaching package: 'vroom'\n\nThe following object is masked from 'package:yardstick':\n\n    spec\n\nThe following object is masked from 'package:scales':\n\n    col_factor\n\nThe following objects are masked from 'package:readr':\n\n    as.col_spec, col_character, col_date, col_datetime, col_double,\n    col_factor, col_guess, col_integer, col_logical, col_number,\n    col_skip, col_time, cols, cols_condense, cols_only, date_names,\n    date_names_lang, date_names_langs, default_locale, fwf_cols,\n    fwf_empty, fwf_positions, fwf_widths, locale, output_column,\n    problems, spec\n\n#diabetes_binary_health_indicators_BRFSS2015.csv\n\ndata &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1               0      1        1         1    40      1      0\n 2               0      0        0         0    25      1      0\n 3               0      1        1         1    28      0      0\n 4               0      1        0         1    27      0      0\n 5               0      1        1         1    24      0      0\n 6               0      1        1         1    25      1      0\n 7               0      1        0         1    30      1      0\n 8               0      1        1         1    25      1      0\n 9               1      1        1         1    30      1      0\n10               0      0        0         1    24      0      0\n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;"
  },
  {
    "objectID": "EDA.html#determine-the-rate-of-missing-values",
    "href": "EDA.html#determine-the-rate-of-missing-values",
    "title": "FinalProjectEDA",
    "section": "Determine The Rate of Missing Values",
    "text": "Determine The Rate of Missing Values\n\n#The `echo: false` option disables the printing of code (only output is displayed).\ndata |&gt;\n  is.na() |&gt;\n  colSums()\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n\nThe sums are 0 for each column, so there is no missing data."
  },
  {
    "objectID": "EDA.html#how-the-data-is-stored",
    "href": "EDA.html#how-the-data-is-stored",
    "title": "FinalProjectEDA",
    "section": "How The Data Is Stored",
    "text": "How The Data Is Stored\nWe will check for column type and values.\n\n#readr::spec(data)\nattributes(data)$spec\n\ncols(\n  Diabetes_binary = col_double(),\n  HighBP = col_double(),\n  HighChol = col_double(),\n  CholCheck = col_double(),\n  BMI = col_double(),\n  Smoker = col_double(),\n  Stroke = col_double(),\n  HeartDiseaseorAttack = col_double(),\n  PhysActivity = col_double(),\n  Fruits = col_double(),\n  Veggies = col_double(),\n  HvyAlcoholConsump = col_double(),\n  AnyHealthcare = col_double(),\n  NoDocbcCost = col_double(),\n  GenHlth = col_double(),\n  MentHlth = col_double(),\n  PhysHlth = col_double(),\n  DiffWalk = col_double(),\n  Sex = col_double(),\n  Age = col_double(),\n  Education = col_double(),\n  Income = col_double()\n)"
  },
  {
    "objectID": "EDA.html#basic-data-validation",
    "href": "EDA.html#basic-data-validation",
    "title": "FinalProjectEDA",
    "section": "Basic Data Validation",
    "text": "Basic Data Validation\nSummarize each column to see if there are any unusual values.\n\nsummary(data)\n\n Diabetes_binary      HighBP         HighChol        CholCheck     \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:1.0000  \n Median :0.0000   Median :0.000   Median :0.0000   Median :1.0000  \n Mean   :0.1393   Mean   :0.429   Mean   :0.4241   Mean   :0.9627  \n 3rd Qu.:0.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  \n      BMI            Smoker           Stroke        HeartDiseaseorAttack\n Min.   :12.00   Min.   :0.0000   Min.   :0.00000   Min.   :0.00000     \n 1st Qu.:24.00   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.00000     \n Median :27.00   Median :0.0000   Median :0.00000   Median :0.00000     \n Mean   :28.38   Mean   :0.4432   Mean   :0.04057   Mean   :0.09419     \n 3rd Qu.:31.00   3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.00000     \n Max.   :98.00   Max.   :1.0000   Max.   :1.00000   Max.   :1.00000     \n  PhysActivity        Fruits          Veggies       HvyAlcoholConsump\n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   \n 1st Qu.:1.0000   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000   \n Median :1.0000   Median :1.0000   Median :1.0000   Median :0.0000   \n Mean   :0.7565   Mean   :0.6343   Mean   :0.8114   Mean   :0.0562   \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   \n AnyHealthcare     NoDocbcCost         GenHlth         MentHlth     \n Min.   :0.0000   Min.   :0.00000   Min.   :1.000   Min.   : 0.000  \n 1st Qu.:1.0000   1st Qu.:0.00000   1st Qu.:2.000   1st Qu.: 0.000  \n Median :1.0000   Median :0.00000   Median :2.000   Median : 0.000  \n Mean   :0.9511   Mean   :0.08418   Mean   :2.511   Mean   : 3.185  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:3.000   3rd Qu.: 2.000  \n Max.   :1.0000   Max.   :1.00000   Max.   :5.000   Max.   :30.000  \n    PhysHlth         DiffWalk           Sex              Age        \n Min.   : 0.000   Min.   :0.0000   Min.   :0.0000   Min.   : 1.000  \n 1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 6.000  \n Median : 0.000   Median :0.0000   Median :0.0000   Median : 8.000  \n Mean   : 4.242   Mean   :0.1682   Mean   :0.4403   Mean   : 8.032  \n 3rd Qu.: 3.000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:10.000  \n Max.   :30.000   Max.   :1.0000   Max.   :1.0000   Max.   :13.000  \n   Education        Income     \n Min.   :1.00   Min.   :1.000  \n 1st Qu.:4.00   1st Qu.:5.000  \n Median :5.00   Median :7.000  \n Mean   :5.05   Mean   :6.054  \n 3rd Qu.:6.00   3rd Qu.:8.000  \n Max.   :6.00   Max.   :8.000  \n\n\nIt appears that BMI is given as a percentile (otherwise, 98 would be quite high). We have a number of categorical variables that would be good to convert to factors.\n\ndata &lt;- data |&gt;\n  mutate(Diabetes_binary=\n           factor(Diabetes_binary,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no diabetes\",\"prediabetes or diabetes\")),\n         HighBP=\n           factor(HighBP,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high BP\",\"high BP\")),\n         HighChol=\n           factor(HighChol,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high cholesterol\",\"high cholesterol\")),\n         CholCheck=\n           factor(CholCheck,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no cholesterol check in 5 years\",\"yes cholesterol check in 5 years\")),\n         #BMI=factor(BMI),\n         Smoker=\n           factor(Smoker,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Stroke=\n           factor(Stroke,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HeartDiseaseorAttack=\n           factor(HeartDiseaseorAttack,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         PhysActivity=\n           factor(PhysActivity,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Fruits=\n           factor(Fruits,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Veggies=\n           factor(Veggies,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HvyAlcoholConsump=\n           factor(HvyAlcoholConsump,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         AnyHealthcare=\n           factor(AnyHealthcare,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         NoDocbcCost=\n           factor(NoDocbcCost,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         GenHlth=\n           factor(GenHlth,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                  labels=c(\"excellent\",\"very good\",\"good\",\"fair\",\"poor\")),\n         #MentHlth=\n           #factor(MentHlth),\n         #PhysHlth=\n           #factor(PhysHlth),\n         DiffWalk=\n           factor(DiffWalk,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no difficulty walking\",\"yes difficulty walking\")),\n         Sex=\n           factor(Sex,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"female\",\"male\")),\n         Age=\n           factor(Age,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\"),\n                  labels=c(\"18 to 24\",\"25 to 29\",\"30 to 34\",\"35 to 39\",\"40 to 44\",\"45 to 49\",\"50 to 54\",\"55 to 59\",\"60 to 64\",\"65 to 69\",\"70 to 74\",\"75 to 79\",\"80 or older\")),\n         Education=\n           factor(Education,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"),\n                  labels=c(\"Never attended school or only kindergarten\",\"Grades 1 through 8 (Elementary)\",\"Grades 9 through 11 (Some high school)\",\"Grade 12 or GED (High school graduate)\",\"College 1 year to 3 years (Some college or technical school)\",\"College 4 years or more (College graduate)\")),\n         Income=\n           factor(Income,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"),\n                  labels=c(\"Less than $10,000\",\"$10,000 to less than $15,000\",\"$15,000 to less than $20,000\",\"$20,000 to less than $25,000\",\"$25,000 to less than $35,000\",\"$35,000 to less than $50,000\",\"$50,000 to less than $75,000\",\"$75,000 or more\"))\n         )"
  },
  {
    "objectID": "EDA.html#clean-up-data-as-needed",
    "href": "EDA.html#clean-up-data-as-needed",
    "title": "FinalProjectEDA",
    "section": "Clean Up Data As Needed",
    "text": "Clean Up Data As Needed"
  },
  {
    "objectID": "EDA.html#investigate-distributions",
    "href": "EDA.html#investigate-distributions",
    "title": "FinalProjectEDA",
    "section": "Investigate Distributions",
    "text": "Investigate Distributions\n\nContingency Tables\nWe will examine one-, two-, and three-way contingency tables. For the one-way contingency table related to the diabetes status of respondents:\n\n#One-way contingency table\ntable(data$Diabetes_binary)\n\n\n            no diabetes prediabetes or diabetes \n                 218334                   35346 \n\n\nFor the two-way contingency tables:\n\n#Two-way contingency tables\ntable(data$Sex,data$Diabetes_binary)\n\n        \n         no diabetes prediabetes or diabetes\n  female      123563                   18411\n  male         94771                   16935\n\ntable(data$Age,data$Diabetes_binary)\n\n             \n              no diabetes prediabetes or diabetes\n  18 to 24           5622                      78\n  25 to 29           7458                     140\n  30 to 34          10809                     314\n  35 to 39          13197                     626\n  40 to 44          15106                    1051\n  45 to 49          18077                    1742\n  50 to 54          23226                    3088\n  55 to 59          26569                    4263\n  60 to 64          27511                    5733\n  65 to 69          25636                    6558\n  70 to 74          18392                    5141\n  75 to 79          12577                    3403\n  80 or older       14154                    3209\n\ntable(data$Education,data$Diabetes_binary)\n\n                                                              \n                                                               no diabetes\n  Never attended school or only kindergarten                           127\n  Grades 1 through 8 (Elementary)                                     2860\n  Grades 9 through 11 (Some high school)                              7182\n  Grade 12 or GED (High school graduate)                             51684\n  College 1 year to 3 years (Some college or technical school)       59556\n  College 4 years or more (College graduate)                         96925\n                                                              \n                                                               prediabetes or diabetes\n  Never attended school or only kindergarten                                        47\n  Grades 1 through 8 (Elementary)                                                 1183\n  Grades 9 through 11 (Some high school)                                          2296\n  Grade 12 or GED (High school graduate)                                         11066\n  College 1 year to 3 years (Some college or technical school)                   10354\n  College 4 years or more (College graduate)                                     10400\n\ntable(data$Income,data$Diabetes_binary)\n\n                              \n                               no diabetes prediabetes or diabetes\n  Less than $10,000                   7428                    2383\n  $10,000 to less than $15,000        8697                    3086\n  $15,000 to less than $20,000       12426                    3568\n  $20,000 to less than $25,000       16081                    4054\n  $25,000 to less than $35,000       21379                    4504\n  $35,000 to less than $50,000       31179                    5291\n  $50,000 to less than $75,000       37954                    5265\n  $75,000 or more                    83190                    7195\n\ntable(data$GenHlth,data$Diabetes_binary)\n\n           \n            no diabetes prediabetes or diabetes\n  excellent       44159                    1140\n  very good       82703                    6381\n  good            62189                   13457\n  fair            21780                    9790\n  poor             7503                    4578\n\ntable(data$Smoker,data$Diabetes_binary)\n\n     \n      no diabetes prediabetes or diabetes\n  no       124228                   17029\n  yes       94106                   18317\n\ntable(data$HvyAlcoholConsump,data$Diabetes_binary)\n\n     \n      no diabetes prediabetes or diabetes\n  no       204910                   34514\n  yes       13424                     832\n\n#table(data$MentHlth,data$Diabetes_binary)\n#table(data$PhysHlth,data$Diabetes_binary)\ntbl &lt;- table(data$DiffWalk,data$Diabetes_binary)\nprop.table(tbl,margin=1)\n\n                        \n                         no diabetes prediabetes or diabetes\n  no difficulty walking    0.8946707               0.1053293\n  yes difficulty walking   0.6925366               0.3074634\n\n\nFor three-way contingency tables:\n\n#Three-way contingency tables\ntbl &lt;- table(data$Age,data$DiffWalk,data$Diabetes_binary)\ntable(data$Smoker,data$HvyAlcoholConsump,data$Diabetes_binary)\n\n, ,  = no diabetes\n\n     \n          no    yes\n  no  119452   4776\n  yes  85458   8648\n\n, ,  = prediabetes or diabetes\n\n     \n          no    yes\n  no   16816    213\n  yes  17698    619\n\n\nWe can get the proportions of non-diabetic people who have difficulty walking, by age bracket:\n\nprop.table(tbl[, , \"no diabetes\"],margin=1)\n\n             \n              no difficulty walking yes difficulty walking\n  18 to 24               0.97954465             0.02045535\n  25 to 29               0.96969697             0.03030303\n  30 to 34               0.96225368             0.03774632\n  35 to 39               0.94779116             0.05220884\n  40 to 44               0.93148418             0.06851582\n  45 to 49               0.90916634             0.09083366\n  50 to 54               0.87707741             0.12292259\n  55 to 59               0.85667507             0.14332493\n  60 to 64               0.84420777             0.15579223\n  65 to 69               0.84338430             0.15661570\n  70 to 74               0.82215094             0.17784906\n  75 to 79               0.77466804             0.22533196\n  80 or older            0.69125336             0.30874664\n\n\nWe can get the proportions of prediabetic or diabetic people who have difficulty walking, by age bracket:\n\nprop.table(tbl[, , \"prediabetes or diabetes\"],margin=1)\n\n             \n              no difficulty walking yes difficulty walking\n  18 to 24               0.91025641             0.08974359\n  25 to 29               0.82857143             0.17142857\n  30 to 34               0.83757962             0.16242038\n  35 to 39               0.80031949             0.19968051\n  40 to 44               0.74119886             0.25880114\n  45 to 49               0.67795637             0.32204363\n  50 to 54               0.64702073             0.35297927\n  55 to 59               0.61459066             0.38540934\n  60 to 64               0.61329147             0.38670853\n  65 to 69               0.62930772             0.37069228\n  70 to 74               0.63314530             0.36685470\n  75 to 79               0.61210696             0.38789304\n  80 or older            0.53443440             0.46556560\n\n\nWe will summarize our numeric variables:\n\nsummary(data |&gt;\n          select(where(is.numeric)))\n\n      BMI           MentHlth         PhysHlth     \n Min.   :12.00   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:24.00   1st Qu.: 0.000   1st Qu.: 0.000  \n Median :27.00   Median : 0.000   Median : 0.000  \n Mean   :28.38   Mean   : 3.185   Mean   : 4.242  \n 3rd Qu.:31.00   3rd Qu.: 2.000   3rd Qu.: 3.000  \n Max.   :98.00   Max.   :30.000   Max.   :30.000  \n\nsummary(data |&gt;\n          filter(Diabetes_binary == \"no diabetes\") |&gt;\n          select(where(is.numeric)))\n\n      BMI           MentHlth         PhysHlth     \n Min.   :12.00   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:24.00   1st Qu.: 0.000   1st Qu.: 0.000  \n Median :27.00   Median : 0.000   Median : 0.000  \n Mean   :27.81   Mean   : 2.978   Mean   : 3.641  \n 3rd Qu.:31.00   3rd Qu.: 2.000   3rd Qu.: 2.000  \n Max.   :98.00   Max.   :30.000   Max.   :30.000  \n\nsummary(data |&gt;\n          filter(Diabetes_binary == \"prediabetes or diabetes\") |&gt;\n          select(where(is.numeric)))\n\n      BMI           MentHlth         PhysHlth     \n Min.   :13.00   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:27.00   1st Qu.: 0.000   1st Qu.: 0.000  \n Median :31.00   Median : 0.000   Median : 1.000  \n Mean   :31.94   Mean   : 4.462   Mean   : 7.954  \n 3rd Qu.:35.00   3rd Qu.: 3.000   3rd Qu.:15.000  \n Max.   :98.00   Max.   :30.000   Max.   :30.000  \n\n\nWe will examine correlations among our numeric variables:\n\ndata |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  round(3)\n\n           BMI MentHlth PhysHlth\nBMI      1.000    0.085    0.121\nMentHlth 0.085    1.000    0.354\nPhysHlth 0.121    0.354    1.000\n\ndata |&gt;\n  filter(Diabetes_binary == \"no diabetes\") |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  round(3)\n\n           BMI MentHlth PhysHlth\nBMI      1.000    0.065    0.078\nMentHlth 0.065    1.000    0.336\nPhysHlth 0.078    0.336    1.000\n\ndata |&gt;\n  filter(Diabetes_binary == \"prediabetes or diabetes\") |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  round(3)\n\n           BMI MentHlth PhysHlth\nBMI      1.000    0.103    0.122\nMentHlth 0.103    1.000    0.391\nPhysHlth 0.122    0.391    1.000\n\n\n\n\nBar Charts & Heatmaps\nWe will look at bar charts and heatmaps relating diabetes status and walking difficulty across different age brackets:\n\nggplot(data, \n       aes(\n         x = Diabetes_binary, fill = DiffWalk)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"DiffWalk\") +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\ndata |&gt; \n  count(Age, DiffWalk, Diabetes_binary) |&gt;  \n  ggplot(aes(x = DiffWalk, y = Diabetes_binary)) +\n  geom_tile(aes(fill = n)) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\n\nWe will also look for relationships between diabetes status, smoking, and alcohol consumption across age brackets:\n\ndata |&gt; \n  count(Age, Smoker, Diabetes_binary) |&gt;  \n  ggplot(aes(x = Smoker, y = Diabetes_binary)) +\n  geom_tile(aes(fill = n)) +\n  scale_fill_gradientn(colours = c(\"#E69F00\", \"#56B4E9\"), values = c(0,0.3,1)) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\ndata |&gt; \n  count(Age, HvyAlcoholConsump, Diabetes_binary) |&gt;  \n  ggplot(aes(x = HvyAlcoholConsump, y = Diabetes_binary)) +\n  geom_tile(aes(fill = n)) +\n  scale_fill_gradientn(colours = c(\"#E69F00\", \"#56B4E9\"), values = c(0,0.3,1)) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\n\n\n\nScatterplots & Histograms For Numeric Variables\nWe will examine the relationship between the number of days of poor mental health (in the past 30 days) and the number of days of physical illness or injury (in the past 30 days):\n\n  ggplot(data |&gt; filter(Age == \"18 to 24\"),\n         aes(\n           x=PhysHlth,y=MentHlth,color=GenHlth)) +\n  geom_point(size=0.01) +\n  geom_jitter(width = 0.2, alpha = 0.3) +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nNext, we will examine the relationship of each of these to BMI:\n\nggplot(data,\n         aes(\n           x=BMI,y=PhysHlth)) +\n  geom_point() +\n  geom_jitter(width = 0.2, alpha = 0.3) +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data,\n         aes(\n           x=BMI,y=MentHlth)) +\n  geom_point() +\n  geom_jitter(width = 0.2, alpha = 0.3) +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThen, we will examine the distributions of PhysHlth, MentHlth, and BMI based on whether individuals have diabetes.\n\nggplot(data |&gt; filter(PhysHlth &gt; 1 & PhysHlth &lt; 30),\n       aes(\n         x=PhysHlth\n       )) + \n  geom_histogram(alpha=0.5,\n    aes(y=..density..,\n        fill = Diabetes_binary, \n        col=I(\"black\")),\n    position = \"identity\",\n    binwidth=1) + \n  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) + xlab(\"PhysHlth\") + ylab(\"Count\") + ggtitle(str_wrap(\"Number of Respondents per Number of Days of Physical Illness or Injury, by Presence or Absence of Diabetes\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nggplot(data |&gt; filter(MentHlth &gt; 1 & MentHlth &lt; 30),\n       aes(\n         x=MentHlth\n       )) + \n  geom_histogram(alpha=0.5,\n    aes(y=..density..,\n        fill = Diabetes_binary, \n        col=I(\"black\")),\n    position = \"identity\",\n    binwidth=1) + \n  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) + xlab(\"MentHlth\") + ylab(\"Count\") + ggtitle(str_wrap(\"Number of Respondents per Number of Poor Mental Health Days, by Presence or Absence of Diabetes\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data,\n       aes(\n         x=BMI\n       )) + \n  geom_histogram(alpha=0.5,\n    aes(y=..density..,\n        fill = Diabetes_binary, \n        col=I(\"black\")),\n    position = \"identity\",\n    binwidth=1) + \n  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) + xlab(\"BMI\") + ylab(\"Count\") + ggtitle(str_wrap(\"Number of Respondents per BMI, by Presence or Absence of Diabetes\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data) +\ngeom_boxplot(aes(x = Sex, y = BMI, fill = Diabetes_binary)) + scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\"))"
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "Write an intro! We will include (at least) 5 predictors in this model: (ORIGINALS! age, sex, income, smoker, and heart disease or attack) sex, income, stroke, heart disease or attack, and heavy alcohol consumption.\nWe will load the libraries and read in the data here:\n\nlibrary(baguette)\n\nLoading required package: parsnip\n\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nlibrary(ggplot2)\nlibrary(glmnet)\n\nLoading required package: Matrix\n\n\nLoaded glmnet 4.1-8\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(ranger)\n#library(randomForest)\nlibrary(stringr)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tibble       3.2.1\n✔ dplyr        1.1.4     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.2.1\n✔ modeldata    1.4.0     ✔ workflows    1.1.4\n✔ purrr        1.0.2     ✔ workflowsets 1.1.0\n✔ recipes      1.1.0     ✔ yardstick    1.3.1\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()  masks scales::discard()\n✖ tidyr::expand()   masks Matrix::expand()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ tidyr::pack()     masks Matrix::pack()\n✖ recipes::step()   masks stats::step()\n✖ tidyr::unpack()   masks Matrix::unpack()\n✖ recipes::update() masks Matrix::update(), stats::update()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats 1.0.0     ✔ readr   2.1.5\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ recipes::fixed()    masks stringr::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ readr::spec()       masks yardstick::spec()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(vroom)\n\n\nAttaching package: 'vroom'\n\nThe following objects are masked from 'package:readr':\n\n    as.col_spec, col_character, col_date, col_datetime, col_double,\n    col_factor, col_guess, col_integer, col_logical, col_number,\n    col_skip, col_time, cols, cols_condense, cols_only, date_names,\n    date_names_lang, date_names_langs, default_locale, fwf_cols,\n    fwf_empty, fwf_positions, fwf_widths, locale, output_column,\n    problems, spec\n\nThe following object is masked from 'package:yardstick':\n\n    spec\n\nThe following object is masked from 'package:scales':\n\n    col_factor\n\n#diabetes_binary_health_indicators_BRFSS2015.csv\n#dbhi = diabetes binary health indicators\ndata &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1               0      1        1         1    40      1      0\n 2               0      0        0         0    25      1      0\n 3               0      1        1         1    28      0      0\n 4               0      1        0         1    27      0      0\n 5               0      1        1         1    24      0      0\n 6               0      1        1         1    25      1      0\n 7               0      1        0         1    30      1      0\n 8               0      1        1         1    25      1      0\n 9               1      1        1         1    30      1      0\n10               0      0        0         1    24      0      0\n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nNext, we will convert variables to factor variables, where appropriate:\n\ndata &lt;- data |&gt;\n  mutate(Diabetes_binary=\n           factor(Diabetes_binary,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no diabetes\",\"prediabetes or diabetes\")),\n         HighBP=\n           factor(HighBP,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high BP\",\"high BP\")),\n         HighChol=\n           factor(HighChol,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high cholesterol\",\"high cholesterol\")),\n         CholCheck=\n           factor(CholCheck,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no cholesterol check in 5 years\",\"yes cholesterol check in 5 years\")),\n         #BMI=factor(BMI),\n         Smoker=\n           factor(Smoker,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Stroke=\n           factor(Stroke,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HeartDiseaseorAttack=\n           factor(HeartDiseaseorAttack,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         PhysActivity=\n           factor(PhysActivity,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Fruits=\n           factor(Fruits,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Veggies=\n           factor(Veggies,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HvyAlcoholConsump=\n           factor(HvyAlcoholConsump,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         AnyHealthcare=\n           factor(AnyHealthcare,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         NoDocbcCost=\n           factor(NoDocbcCost,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         GenHlth=\n           factor(GenHlth,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                  labels=c(\"excellent\",\"very good\",\"good\",\"fair\",\"poor\")),\n         #MentHlth=\n           #factor(MentHlth),\n         #PhysHlth=\n           #factor(PhysHlth),\n         DiffWalk=\n           factor(DiffWalk,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no difficulty walking\",\"yes difficulty walking\")),\n         Sex=\n           factor(Sex,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"female\",\"male\")),\n         Age=\n           factor(Age,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\"),\n                  labels=c(\"18 to 24\",\"25 to 29\",\"30 to 34\",\"35 to 39\",\"40 to 44\",\"45 to 49\",\"50 to 54\",\"55 to 59\",\"60 to 64\",\"65 to 69\",\"70 to 74\",\"75 to 79\",\"80 or older\")),\n         Education=\n           factor(Education,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"),\n                  labels=c(\"Never attended school or only kindergarten\",\"Grades 1 through 8 (Elementary)\",\"Grades 9 through 11 (Some high school)\",\"Grade 12 or GED (High school graduate)\",\"College 1 year to 3 years (Some college or technical school)\",\"College 4 years or more (College graduate)\")),\n         Income=\n           factor(Income,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"),\n                  labels=c(\"Less than $10,000\",\"$10,000 to less than $15,000\",\"$15,000 to less than $20,000\",\"$20,000 to less than $25,000\",\"$25,000 to less than $35,000\",\"$35,000 to less than $50,000\",\"$50,000 to less than $75,000\",\"$75,000 or more\"))\n         )\n\nNow, subset the data to look at the 5 predictors:\n\ndbhi_data &lt;- data #|&gt; \n#  select(Diabetes_binary,Age,HeartDiseaseorAttack,Income,Sex,Smoker)\ndbhi_data\n\n# A tibble: 253,680 × 22\n   Diabetes_binary         HighBP     HighChol     CholCheck   BMI Smoker Stroke\n   &lt;fct&gt;                   &lt;fct&gt;      &lt;fct&gt;        &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; \n 1 no diabetes             high BP    high choles… yes chol…    40 yes    no    \n 2 no diabetes             no high BP no high cho… no chole…    25 yes    no    \n 3 no diabetes             high BP    high choles… yes chol…    28 no     no    \n 4 no diabetes             high BP    no high cho… yes chol…    27 no     no    \n 5 no diabetes             high BP    high choles… yes chol…    24 no     no    \n 6 no diabetes             high BP    high choles… yes chol…    25 yes    no    \n 7 no diabetes             high BP    no high cho… yes chol…    30 yes    no    \n 8 no diabetes             high BP    high choles… yes chol…    25 yes    no    \n 9 prediabetes or diabetes high BP    high choles… yes chol…    30 yes    no    \n10 no diabetes             no high BP no high cho… yes chol…    24 no     no    \n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,\n#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;fct&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;fct&gt;"
  },
  {
    "objectID": "Modeling.html#introduction",
    "href": "Modeling.html#introduction",
    "title": "Modeling",
    "section": "",
    "text": "Write an intro! We will include (at least) 5 predictors in this model: (ORIGINALS! age, sex, income, smoker, and heart disease or attack) sex, income, stroke, heart disease or attack, and heavy alcohol consumption.\nWe will load the libraries and read in the data here:\n\nlibrary(baguette)\n\nLoading required package: parsnip\n\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nlibrary(ggplot2)\nlibrary(glmnet)\n\nLoading required package: Matrix\n\n\nLoaded glmnet 4.1-8\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(ranger)\n#library(randomForest)\nlibrary(stringr)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tibble       3.2.1\n✔ dplyr        1.1.4     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.2.1\n✔ modeldata    1.4.0     ✔ workflows    1.1.4\n✔ purrr        1.0.2     ✔ workflowsets 1.1.0\n✔ recipes      1.1.0     ✔ yardstick    1.3.1\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()  masks scales::discard()\n✖ tidyr::expand()   masks Matrix::expand()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ tidyr::pack()     masks Matrix::pack()\n✖ recipes::step()   masks stats::step()\n✖ tidyr::unpack()   masks Matrix::unpack()\n✖ recipes::update() masks Matrix::update(), stats::update()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats 1.0.0     ✔ readr   2.1.5\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ recipes::fixed()    masks stringr::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ readr::spec()       masks yardstick::spec()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(vroom)\n\n\nAttaching package: 'vroom'\n\nThe following objects are masked from 'package:readr':\n\n    as.col_spec, col_character, col_date, col_datetime, col_double,\n    col_factor, col_guess, col_integer, col_logical, col_number,\n    col_skip, col_time, cols, cols_condense, cols_only, date_names,\n    date_names_lang, date_names_langs, default_locale, fwf_cols,\n    fwf_empty, fwf_positions, fwf_widths, locale, output_column,\n    problems, spec\n\nThe following object is masked from 'package:yardstick':\n\n    spec\n\nThe following object is masked from 'package:scales':\n\n    col_factor\n\n#diabetes_binary_health_indicators_BRFSS2015.csv\n#dbhi = diabetes binary health indicators\ndata &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1               0      1        1         1    40      1      0\n 2               0      0        0         0    25      1      0\n 3               0      1        1         1    28      0      0\n 4               0      1        0         1    27      0      0\n 5               0      1        1         1    24      0      0\n 6               0      1        1         1    25      1      0\n 7               0      1        0         1    30      1      0\n 8               0      1        1         1    25      1      0\n 9               1      1        1         1    30      1      0\n10               0      0        0         1    24      0      0\n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nNext, we will convert variables to factor variables, where appropriate:\n\ndata &lt;- data |&gt;\n  mutate(Diabetes_binary=\n           factor(Diabetes_binary,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no diabetes\",\"prediabetes or diabetes\")),\n         HighBP=\n           factor(HighBP,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high BP\",\"high BP\")),\n         HighChol=\n           factor(HighChol,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high cholesterol\",\"high cholesterol\")),\n         CholCheck=\n           factor(CholCheck,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no cholesterol check in 5 years\",\"yes cholesterol check in 5 years\")),\n         #BMI=factor(BMI),\n         Smoker=\n           factor(Smoker,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Stroke=\n           factor(Stroke,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HeartDiseaseorAttack=\n           factor(HeartDiseaseorAttack,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         PhysActivity=\n           factor(PhysActivity,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Fruits=\n           factor(Fruits,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Veggies=\n           factor(Veggies,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HvyAlcoholConsump=\n           factor(HvyAlcoholConsump,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         AnyHealthcare=\n           factor(AnyHealthcare,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         NoDocbcCost=\n           factor(NoDocbcCost,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         GenHlth=\n           factor(GenHlth,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                  labels=c(\"excellent\",\"very good\",\"good\",\"fair\",\"poor\")),\n         #MentHlth=\n           #factor(MentHlth),\n         #PhysHlth=\n           #factor(PhysHlth),\n         DiffWalk=\n           factor(DiffWalk,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no difficulty walking\",\"yes difficulty walking\")),\n         Sex=\n           factor(Sex,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"female\",\"male\")),\n         Age=\n           factor(Age,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\"),\n                  labels=c(\"18 to 24\",\"25 to 29\",\"30 to 34\",\"35 to 39\",\"40 to 44\",\"45 to 49\",\"50 to 54\",\"55 to 59\",\"60 to 64\",\"65 to 69\",\"70 to 74\",\"75 to 79\",\"80 or older\")),\n         Education=\n           factor(Education,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"),\n                  labels=c(\"Never attended school or only kindergarten\",\"Grades 1 through 8 (Elementary)\",\"Grades 9 through 11 (Some high school)\",\"Grade 12 or GED (High school graduate)\",\"College 1 year to 3 years (Some college or technical school)\",\"College 4 years or more (College graduate)\")),\n         Income=\n           factor(Income,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"),\n                  labels=c(\"Less than $10,000\",\"$10,000 to less than $15,000\",\"$15,000 to less than $20,000\",\"$20,000 to less than $25,000\",\"$25,000 to less than $35,000\",\"$35,000 to less than $50,000\",\"$50,000 to less than $75,000\",\"$75,000 or more\"))\n         )\n\nNow, subset the data to look at the 5 predictors:\n\ndbhi_data &lt;- data #|&gt; \n#  select(Diabetes_binary,Age,HeartDiseaseorAttack,Income,Sex,Smoker)\ndbhi_data\n\n# A tibble: 253,680 × 22\n   Diabetes_binary         HighBP     HighChol     CholCheck   BMI Smoker Stroke\n   &lt;fct&gt;                   &lt;fct&gt;      &lt;fct&gt;        &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; \n 1 no diabetes             high BP    high choles… yes chol…    40 yes    no    \n 2 no diabetes             no high BP no high cho… no chole…    25 yes    no    \n 3 no diabetes             high BP    high choles… yes chol…    28 no     no    \n 4 no diabetes             high BP    no high cho… yes chol…    27 no     no    \n 5 no diabetes             high BP    high choles… yes chol…    24 no     no    \n 6 no diabetes             high BP    high choles… yes chol…    25 yes    no    \n 7 no diabetes             high BP    no high cho… yes chol…    30 yes    no    \n 8 no diabetes             high BP    high choles… yes chol…    25 yes    no    \n 9 prediabetes or diabetes high BP    high choles… yes chol…    30 yes    no    \n10 no diabetes             no high BP no high cho… yes chol…    24 no     no    \n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,\n#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;fct&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;fct&gt;"
  },
  {
    "objectID": "Modeling.html#split-the-data",
    "href": "Modeling.html#split-the-data",
    "title": "Modeling",
    "section": "Split the Data",
    "text": "Split the Data\nSet the seed. Then, use functions from tidymodels to split the data into a training and test set (70/30 split). Then, use the strata argument to stratify the split on the Sex variable.\n\nset.seed(11)\ndbhi_split &lt;- initial_split(dbhi_data, prop = 0.70, strata=Sex) #strata = argument goes in the parentheses, if needed\ndbhi_train &lt;- training(dbhi_split)\ndbhi_test &lt;- testing(dbhi_split)\n\nWe will perform 5-fold cross validation:\n\ndbhi_5_fold &lt;- vfold_cv(dbhi_train, 5)\n\ndbhi_5_fold\n\n#  5-fold cross-validation \n# A tibble: 5 × 2\n  splits                 id   \n  &lt;list&gt;                 &lt;chr&gt;\n1 &lt;split [142060/35515]&gt; Fold1\n2 &lt;split [142060/35515]&gt; Fold2\n3 &lt;split [142060/35515]&gt; Fold3\n4 &lt;split [142060/35515]&gt; Fold4\n5 &lt;split [142060/35515]&gt; Fold5"
  },
  {
    "objectID": "Modeling.html#models",
    "href": "Modeling.html#models",
    "title": "Modeling",
    "section": "Models",
    "text": "Models\nWe will consider two kinds of models: classification tree and random forest. We will …\nGet a recipe. Then, standardize the numeric variables since their scales are pretty different. Finally, create dummy variables for the predictors since they need to be numeric (again).\n\n#bystanders &lt;- colnames(dbhi_data)[c(2:4,7:18,21)]\n#bystanders\n\n#dbhi_train\n#Diabetes_binary ~ Age + BMI + Income + Sex + Smoker\n#ORIGINALS:  update_role(HighBP,HighChol,CholCheck,Stroke,HeartDiseaseorAttack,PhysActivity,Fruits,Veggies,HvyAlcoholConsump,AnyHealthcare,NoDocbcCost,GenHlth,MentHlth,PhysHlth,DiffWalk,Education,new_role = \"bystander\") \ndbhi_recipe &lt;- recipe(Diabetes_binary ~ ., data = dbhi_train) |&gt;\n  update_role(Age,Smoker,BMI,HighBP,HighChol,CholCheck,PhysActivity,Fruits,Veggies,AnyHealthcare,NoDocbcCost,GenHlth,MentHlth,PhysHlth,DiffWalk,Education,new_role = \"bystander\") |&gt;\n  step_dummy(all_nominal_predictors()) |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) #|&gt;\n#  summary()\n#  prep(training = dbhi_train) |&gt;\n#  bake(dbhi_train)\n\ndbhi_recipe\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor:  5\nbystander: 16\n\n\n\n\n\n── Operations \n\n\n• Dummy variables from: all_nominal_predictors()\n\n\n• Centering and scaling for: all_numeric() and -all_outcomes()\n\n\n\nClassification Tree\nYou should provide a thorough explanation of what a classification tree model is. Then you should fit a classification tree with varying values for the complexity parameter and choose the best model (based on 5 fold CV on the training set). Include at least 5 predictors in this model.\nFirst, tell tidymodels that we are performing a classification task:\n\ntree_mod &lt;- decision_tree(tree_depth = tune(),\n                          min_n = 10,\n                          cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\nNext, create a workflow to use in the fitting process:\n\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(dbhi_recipe) |&gt;\n  add_model(tree_mod)\n\nThen, to create the tuning grid for fitting our models, we use cross validation (CV) to select the tuning parameters:\n\ntemp &lt;- tree_wkf |&gt; \n  tune_grid(resamples = dbhi_5_fold, metrics=metric_set(mn_log_loss))\ntemp |&gt; \n  collect_metrics()\n\n# A tibble: 10 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1        1.41e- 5          6 mn_log_loss binary     0.397     5 3.21e-3 Prepro…\n 2        9.46e- 3          9 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 3        1.05e-10         11 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 4        2.89e- 4          3 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 5        2.97e- 8         13 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 6        7.51e- 8          8 mn_log_loss binary     0.392     5 2.56e-3 Prepro…\n 7        5.06e- 5         14 mn_log_loss binary     0.399     5 2.28e-3 Prepro…\n 8        2.87e- 9          4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 9        5.92e- 2          1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n10        1.02e- 6         11 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n\n\n\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          #min_n(),\n                          tree_depth(),\n                          levels = c(5, 5))\n\ntree_grid\n\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             &lt;dbl&gt;      &lt;int&gt;\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# ℹ 15 more rows\n\n\nThis generates 25 (5x5) candidate decision tree models.\n\ntree_fits &lt;- tree_wkf |&gt; \n  tune_grid(resamples = dbhi_5_fold,\n            metrics=metric_set(mn_log_loss),\n            grid = tree_grid)\ntree_fits |&gt;\n  collect_metrics()\n\n# A tibble: 25 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1    0.0000000001          1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 2    0.0000000178          1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 3    0.00000316            1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 4    0.000562              1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 5    0.1                   1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 6    0.0000000001          4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 7    0.0000000178          4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 8    0.00000316            4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 9    0.000562              4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n10    0.1                   4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n# ℹ 15 more rows\n\n\nCombine the metrics across the folds, then plot:\n\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  mutate(tree_depth = factor(tree_depth)) |&gt;\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\ntree_fits\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits                 id    .metrics          .notes          \n  &lt;list&gt;                 &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          \n1 &lt;split [142060/35515]&gt; Fold1 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [142060/35515]&gt; Fold2 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [142060/35515]&gt; Fold3 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [142060/35515]&gt; Fold4 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [142060/35515]&gt; Fold5 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n\n\nOur best model has a tree_depth of 15 (this minimizes the mean log loss).\nSort by the log loss value:\n\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"mn_log_loss\") |&gt;\n  arrange(mean)\n\n# A tibble: 25 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1    0.0000000001         11 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 2    0.0000000178         11 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 3    0.00000316           11 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 4    0.0000000001         15 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 5    0.0000000178         15 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 6    0.00000316           15 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 7    0.0000000001          8 mn_log_loss binary     0.392     5 2.56e-3 Prepro…\n 8    0.0000000178          8 mn_log_loss binary     0.392     5 2.56e-3 Prepro…\n 9    0.00000316            8 mn_log_loss binary     0.392     5 2.56e-3 Prepro…\n10    0.0000000001          1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n# ℹ 15 more rows\n\n\nGrab the best model’s tuning parameter values:\n\ntree_best_params &lt;- select_best(tree_fits)\n\nWarning in select_best(tree_fits): No value of `metric` was given;\n\"mn_log_loss\" will be used.\n\ntree_best_params\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1    0.0000000001         11 Preprocessor1_Model16\n\n\nThese are the values for tree_depth and cost_complexity that minimize mean log loss in the dbhi data set.\nFit this chosen model by finalize_workflow() to finalize the model on the training set:\n\ntree_final_wkf &lt;- tree_wkf |&gt;\n  finalize_workflow(tree_best_params)\n\ntree_final_wkf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_dummy()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 11\n  min_n = 10\n\nComputational engine: rpart \n\n\nPerform last_fit() on the dbhi_split object:\n\ntree_final_fit &lt;- tree_final_wkf |&gt;\n  last_fit(dbhi_split, metrics=metric_set(mn_log_loss))\ntree_final_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits                 id            .metrics .notes   .predictions .workflow \n  &lt;list&gt;                 &lt;chr&gt;         &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [177575/76105]&gt; train/test s… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n\nLook at the metric with collect_metrics():\n\ntree_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 mn_log_loss binary         0.396 Preprocessor1_Model1\n\n\nPlot to learn about the fit:\n\ntree_final_model &lt;- extract_workflow(tree_final_fit)\n\ntree_final_model &lt;- tree_final_model |&gt;\n  extract_fit_engine() |&gt;\n  rpart.plot::rpart.plot(roundint = FALSE,extra=101,digits=-6)\n\n\n\n\n\n\n\ntree_final_model\n\n$obj\nn= 177575 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 177575 24553 no diabetes (0.8617317 0.1382683)  \n    2) HeartDiseaseorAttack_yes&lt; 1.386034 160791 19073 no diabetes (0.8813802 0.1186198) *\n    3) HeartDiseaseorAttack_yes&gt;=1.386034 16784  5480 no diabetes (0.6734986 0.3265014)  \n      6) Stroke_yes&lt; 2.322867 13995  4337 no diabetes (0.6901036 0.3098964) *\n      7) Stroke_yes&gt;=2.322867 2789  1143 no diabetes (0.5901757 0.4098243)  \n       14) HvyAlcoholConsump_yes&gt;=1.923615 83    16 no diabetes (0.8072289 0.1927711)  \n         28) Income_X.50.000.to.less.than..75.000&gt;=0.8810366 5     0 no diabetes (1.0000000 0.0000000) *\n         29) Income_X.50.000.to.less.than..75.000&lt; 0.8810366 78    16 no diabetes (0.7948718 0.2051282)  \n           58) Income_X.75.000.or.more&gt;=0.2976892 16     2 no diabetes (0.8750000 0.1250000) *\n           59) Income_X.75.000.or.more&lt; 0.2976892 62    14 no diabetes (0.7741935 0.2258065)  \n            118) Income_X.25.000.to.less.than..35.000&gt;=1.316765 9     1 no diabetes (0.8888889 0.1111111) *\n            119) Income_X.25.000.to.less.than..35.000&lt; 1.316765 53    13 no diabetes (0.7547170 0.2452830)  \n              238) Sex_male&gt;=0.120171 29     6 no diabetes (0.7931034 0.2068966) *\n              239) Sex_male&lt; 0.120171 24     7 no diabetes (0.7083333 0.2916667)  \n                478) Income_X.35.000.to.less.than..50.000&lt; 1.010926 17     3 no diabetes (0.8235294 0.1764706) *\n                479) Income_X.35.000.to.less.than..50.000&gt;=1.010926 7     3 prediabetes or diabetes (0.4285714 0.5714286) *\n       15) HvyAlcoholConsump_yes&lt; 1.923615 2706  1127 no diabetes (0.5835181 0.4164819) *\n\n$snipped.nodes\nNULL\n\n$xlim\n[1] 0 1\n\n$ylim\n[1] 0 1\n\n$x\n [1] 0.23100161 0.04472613 0.41727710 0.15963341 0.67492078 0.38585713\n [7] 0.27454070 0.49717357 0.38944799 0.60489915 0.50435527 0.70544303\n[13] 0.61926256 0.79162349 0.73416985 0.84907714 0.96398442\n\n$y\n [1] 0.95861553 0.02628681 0.85266909 0.02628681 0.74672264 0.64077620\n [7] 0.02628681 0.53482975 0.02628681 0.42888330 0.02628681 0.32293686\n[13] 0.02628681 0.21699041 0.02628681 0.02628681 0.02628681\n\n$branch.x\n       [,1]       [,2]      [,3]      [,4]      [,5]      [,6]      [,7]\nx 0.2310016 0.04472613 0.4172771 0.1596334 0.6749208 0.3858571 0.2745407\n         NA 0.04472613 0.4172771 0.1596334 0.6749208 0.3858571 0.2745407\n         NA 0.23100161 0.2310016 0.4172771 0.4172771 0.6749208 0.3858571\n       [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]\nx 0.4971736 0.3894480 0.6048992 0.5043553 0.7054430 0.6192626 0.7916235\n  0.4971736 0.3894480 0.6048992 0.5043553 0.7054430 0.6192626 0.7916235\n  0.3858571 0.4971736 0.4971736 0.6048992 0.6048992 0.7054430 0.7054430\n      [,15]     [,16]     [,17]\nx 0.7341698 0.8490771 0.9639844\n  0.7341698 0.8490771 0.9639844\n  0.7916235 0.7916235 0.6749208\n\n$branch.y\n       [,1]       [,2]      [,3]       [,4]      [,5]      [,6]       [,7]\ny 0.9997651 0.06743639 0.8938187 0.06743639 0.7878722 0.6819258 0.06743639\n         NA 0.91327376 0.9132738 0.80732732 0.8073273 0.7013809 0.59543442\n         NA 0.91327376 0.9132738 0.80732732 0.8073273 0.7013809 0.59543442\n       [,8]       [,9]     [,10]      [,11]     [,12]      [,13]     [,14]\ny 0.5759793 0.06743639 0.4700329 0.06743639 0.3640864 0.06743639 0.2581400\n  0.5954344 0.48948798 0.4894880 0.38354153 0.3835415 0.27759509 0.2775951\n  0.5954344 0.48948798 0.4894880 0.38354153 0.3835415 0.27759509 0.2775951\n       [,15]      [,16]      [,17]\ny 0.06743639 0.06743639 0.06743639\n  0.17164864 0.17164864 0.70138087\n  0.17164864 0.17164864 0.70138087\n\n$labs\n [1] \"no diabetes\\n153022  24553\\n100.0000%\" \n [2] \"no diabetes\\n141718  19073\\n90.5482%\"  \n [3] \"no diabetes\\n11304  5480\\n9.4518%\"     \n [4] \"no diabetes\\n9658  4337\\n7.8812%\"      \n [5] \"no diabetes\\n1646  1143\\n1.5706%\"      \n [6] \"no diabetes\\n67  16\\n0.0467%\"          \n [7] \"no diabetes\\n5  0\\n0.0028%\"            \n [8] \"no diabetes\\n62  16\\n0.0439%\"          \n [9] \"no diabetes\\n14  2\\n0.0090%\"           \n[10] \"no diabetes\\n48  14\\n0.0349%\"          \n[11] \"no diabetes\\n8  1\\n0.0051%\"            \n[12] \"no diabetes\\n40  13\\n0.0298%\"          \n[13] \"no diabetes\\n23  6\\n0.0163%\"           \n[14] \"no diabetes\\n17  7\\n0.0135%\"           \n[15] \"no diabetes\\n14  3\\n0.0096%\"           \n[16] \"prediabetes or diabetes\\n3  4\\n0.0039%\"\n[17] \"no diabetes\\n1579  1127\\n1.5239%\"      \n\n$cex\n[1] 0.4625\n\n$boxes\n$boxes$x1\n [1]  0.183660439 -0.002615046  0.376951032  0.121767869  0.637055236\n [6]  0.347991591  0.236675157  0.459308026  0.351582444  0.567033608\n[11]  0.466489731  0.667577484  0.581397019  0.753757950  0.696304306\n[16]  0.777906774  0.926118881\n\n$boxes$y1\n [1]  0.930420747 -0.001907977  0.824474301 -0.001907977  0.718527855\n [6]  0.612581409 -0.001907977  0.506634963 -0.001907977  0.400688517\n[11] -0.001907977  0.294742071 -0.001907977  0.188795625 -0.001907977\n[16] -0.001907977 -0.001907977\n\n$boxes$x2\n [1] 0.2783428 0.0920673 0.4576032 0.1974990 0.7127863 0.4237227 0.3124062\n [8] 0.5350391 0.4273135 0.6427647 0.5422208 0.7433086 0.6571281 0.8294890\n[15] 0.7720354 0.9202475 1.0018500\n\n$boxes$y2\n [1] 0.99976511 0.06743639 0.89381867 0.06743639 0.78787222 0.68192578\n [7] 0.06743639 0.57597933 0.06743639 0.47003288 0.06743639 0.36408644\n[13] 0.06743639 0.25813999 0.06743639 0.06743639 0.06743639\n\n\n$split.labs\n[1] \"\"\n\n$split.cex\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n$split.box\n$split.box$x1\n [1] 0.1161793        NA 0.3483794        NA 0.5581954 0.2329999        NA\n [8] 0.3786743        NA 0.4555495        NA 0.6339093        NA 0.6459569\n[15]        NA        NA        NA\n\n$split.box$y1\n [1] 0.9003190        NA 0.7943725        NA 0.6884261 0.5824796        NA\n [8] 0.4765332        NA 0.3705867        NA 0.2646403        NA 0.1586938\n[15]        NA        NA        NA\n\n$split.box$x2\n [1] 0.3458239        NA 0.4861748        NA 0.7916462 0.5387144        NA\n [8] 0.6156728        NA 0.7542488        NA 0.7769768        NA 0.9372901\n[15]        NA        NA        NA\n\n$split.box$y2\n [1] 0.9262286        NA 0.8202821        NA 0.7143357 0.6083892        NA\n [8] 0.5024428        NA 0.3964963        NA 0.2905499        NA 0.1846034\n[15]        NA        NA        NA\n\n\n\n\nRandom Forest\nYou should provide a thorough explanation of what a random forest is and why we might use it (be sure to relate this to a basic classification tree). You should then fit a random forest model with varying values for the mtry parameter and choose the best model (based on 5 fold CV on the training set). Include at least 5 predictors in this model."
  },
  {
    "objectID": "Modeling.html#final-model-selection",
    "href": "Modeling.html#final-model-selection",
    "title": "Modeling",
    "section": "Final Model Selection",
    "text": "Final Model Selection\nWe will compare the best models from each of the approaches on the test set and declare an overall winner:"
  }
]