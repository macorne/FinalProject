[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "FinalProjectEDA",
    "section": "",
    "text": "We will explore the Centers for Disease Control and Prevention (CDC) Behavioral Risk Factor Surveillance System (BRFSS) data set of diabetes binary health indicators from 2015. Two questions that we would like to address in this exploratory data analysis:\n\nWhich factors are most predictive of diabetes risk?\nCan we use a subset of the risk factors to accurately predict whether an individual has diabetes?"
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "FinalProjectEDA",
    "section": "",
    "text": "We will explore the Centers for Disease Control and Prevention (CDC) Behavioral Risk Factor Surveillance System (BRFSS) data set of diabetes binary health indicators from 2015. Two questions that we would like to address in this exploratory data analysis:\n\nWhich factors are most predictive of diabetes risk?\nCan we use a subset of the risk factors to accurately predict whether an individual has diabetes?"
  },
  {
    "objectID": "EDA.html#read-in-the-data",
    "href": "EDA.html#read-in-the-data",
    "title": "FinalProjectEDA",
    "section": "Read In The Data",
    "text": "Read In The Data\nWe will first read in the data:\n\nlibrary(ascii)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::expand() masks ascii::expand()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ tidyr::expand()   masks ascii::expand()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(vroom)\n\n\nAttaching package: 'vroom'\n\nThe following object is masked from 'package:yardstick':\n\n    spec\n\nThe following object is masked from 'package:scales':\n\n    col_factor\n\nThe following objects are masked from 'package:readr':\n\n    as.col_spec, col_character, col_date, col_datetime, col_double,\n    col_factor, col_guess, col_integer, col_logical, col_number,\n    col_skip, col_time, cols, cols_condense, cols_only, date_names,\n    date_names_lang, date_names_langs, default_locale, fwf_cols,\n    fwf_empty, fwf_positions, fwf_widths, locale, output_column,\n    problems, spec\n\n#diabetes_binary_health_indicators_BRFSS2015.csv\n\ndata &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1               0      1        1         1    40      1      0\n 2               0      0        0         0    25      1      0\n 3               0      1        1         1    28      0      0\n 4               0      1        0         1    27      0      0\n 5               0      1        1         1    24      0      0\n 6               0      1        1         1    25      1      0\n 7               0      1        0         1    30      1      0\n 8               0      1        1         1    25      1      0\n 9               1      1        1         1    30      1      0\n10               0      0        0         1    24      0      0\n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nWe have 22 variables: 1 response (Diabetes_binary) and 21 possible predictors. From the 21, we will choose 6: Age, Sex, Income, Stroke, Heart Disease or Attack, and Heavy Alcohol Consumption. We are focusing on these variables as predictors because they are related both to lifestyle and to health.\nOther variables, such as Age or Body Mass Index (BMI), are interesting but may be less helpful. Diabetes comes in different forms - at least Type 1 and Type 2 but possibly more - and we expect there to be fewer instances of diabetes (especially Type 2) among the young.\nThe BMI is dubious as a predictor because two people may share the same BMI but have very different body compositions; these differences can manifest as health problems for one person but not another. Since we lack family history, height, or weight of the respondents in this dataset, we can’t easily make an assessment. Further, since many of the variables are categorical, we cannot find correlations between them and any of the numeric variables."
  },
  {
    "objectID": "EDA.html#determine-the-rate-of-missing-values",
    "href": "EDA.html#determine-the-rate-of-missing-values",
    "title": "FinalProjectEDA",
    "section": "Determine The Rate of Missing Values",
    "text": "Determine The Rate of Missing Values\nWe want to check for missing values, since these can impact our results.\n\ndata |&gt;\n  is.na() |&gt;\n  colSums()\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n\nThe sums are 0 for each column, so there is no missing data. Otherwise, would might need to exclude observations or come up with a reasonable scheme for handling the missing observations."
  },
  {
    "objectID": "EDA.html#how-the-data-is-stored",
    "href": "EDA.html#how-the-data-is-stored",
    "title": "FinalProjectEDA",
    "section": "How The Data Is Stored",
    "text": "How The Data Is Stored\nWe will check for column type and values.\n\nattributes(data)$spec\n\ncols(\n  Diabetes_binary = col_double(),\n  HighBP = col_double(),\n  HighChol = col_double(),\n  CholCheck = col_double(),\n  BMI = col_double(),\n  Smoker = col_double(),\n  Stroke = col_double(),\n  HeartDiseaseorAttack = col_double(),\n  PhysActivity = col_double(),\n  Fruits = col_double(),\n  Veggies = col_double(),\n  HvyAlcoholConsump = col_double(),\n  AnyHealthcare = col_double(),\n  NoDocbcCost = col_double(),\n  GenHlth = col_double(),\n  MentHlth = col_double(),\n  PhysHlth = col_double(),\n  DiffWalk = col_double(),\n  Sex = col_double(),\n  Age = col_double(),\n  Education = col_double(),\n  Income = col_double()\n)\n\n\nWe have a number of categorical variables that would be good to convert to factors.\n\ndata &lt;- data |&gt;\n  mutate(Diabetes_binary=\n           factor(Diabetes_binary,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no diabetes\",\"prediabetes or diabetes\")),\n         HighBP=\n           factor(HighBP,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high BP\",\"high BP\")),\n         HighChol=\n           factor(HighChol,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high cholesterol\",\"high cholesterol\")),\n         CholCheck=\n           factor(CholCheck,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no cholesterol check in 5 years\",\"yes cholesterol check in 5 years\")),\n         #BMI=factor(BMI),\n         Smoker=\n           factor(Smoker,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Stroke=\n           factor(Stroke,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HeartDiseaseorAttack=\n           factor(HeartDiseaseorAttack,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         PhysActivity=\n           factor(PhysActivity,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Fruits=\n           factor(Fruits,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Veggies=\n           factor(Veggies,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HvyAlcoholConsump=\n           factor(HvyAlcoholConsump,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         AnyHealthcare=\n           factor(AnyHealthcare,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         NoDocbcCost=\n           factor(NoDocbcCost,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         GenHlth=\n           factor(GenHlth,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                  labels=c(\"excellent\",\"very good\",\"good\",\"fair\",\"poor\")),\n         #MentHlth=\n           #factor(MentHlth),\n         #PhysHlth=\n           #factor(PhysHlth),\n         DiffWalk=\n           factor(DiffWalk,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no difficulty walking\",\"yes difficulty walking\")),\n         Sex=\n           factor(Sex,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"female\",\"male\")),\n         Age=\n           factor(Age,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\"),\n                  labels=c(\"18 to 24\",\"25 to 29\",\"30 to 34\",\"35 to 39\",\"40 to 44\",\"45 to 49\",\"50 to 54\",\"55 to 59\",\"60 to 64\",\"65 to 69\",\"70 to 74\",\"75 to 79\",\"80 or older\")),\n         Education=\n           factor(Education,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"),\n                  labels=c(\"Never attended school or only kindergarten\",\"Grades 1 through 8 (Elementary)\",\"Grades 9 through 11 (Some high school)\",\"Grade 12 or GED (High school graduate)\",\"College 1 year to 3 years (Some college or technical school)\",\"College 4 years or more (College graduate)\")),\n         Income=\n           factor(Income,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"),\n                  labels=c(\"Less than $10,000\",\"$10,000 to less than $15,000\",\"$15,000 to less than $20,000\",\"$20,000 to less than $25,000\",\"$25,000 to less than $35,000\",\"$35,000 to less than $50,000\",\"$50,000 to less than $75,000\",\"$75,000 or more\"))\n         )"
  },
  {
    "objectID": "EDA.html#basic-data-validation",
    "href": "EDA.html#basic-data-validation",
    "title": "FinalProjectEDA",
    "section": "Basic Data Validation",
    "text": "Basic Data Validation\nSummarize each column to see if there are any unusual values.\n\nsummary(data)\n\n                Diabetes_binary          HighBP      \n no diabetes            :218334   no high BP:144851  \n prediabetes or diabetes: 35346   high BP   :108829  \n                                                     \n                                                     \n                                                     \n                                                     \n                                                     \n                HighChol                                 CholCheck     \n no high cholesterol:146089   no cholesterol check in 5 years :  9470  \n high cholesterol   :107591   yes cholesterol check in 5 years:244210  \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n      BMI        Smoker       Stroke       HeartDiseaseorAttack PhysActivity\n Min.   :12.00   no :141257   no :243388   no :229787           no : 61760  \n 1st Qu.:24.00   yes:112423   yes: 10292   yes: 23893           yes:191920  \n Median :27.00                                                              \n Mean   :28.38                                                              \n 3rd Qu.:31.00                                                              \n Max.   :98.00                                                              \n                                                                            \n Fruits       Veggies      HvyAlcoholConsump AnyHealthcare NoDocbcCost \n no : 92782   no : 47839   no :239424        no : 12417    no :232326  \n yes:160898   yes:205841   yes: 14256        yes:241263    yes: 21354  \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n      GenHlth         MentHlth         PhysHlth     \n excellent:45299   Min.   : 0.000   Min.   : 0.000  \n very good:89084   1st Qu.: 0.000   1st Qu.: 0.000  \n good     :75646   Median : 0.000   Median : 0.000  \n fair     :31570   Mean   : 3.185   Mean   : 4.242  \n poor     :12081   3rd Qu.: 2.000   3rd Qu.: 3.000  \n                   Max.   :30.000   Max.   :30.000  \n                                                    \n                   DiffWalk          Sex               Age       \n no difficulty walking :211005   female:141974   60 to 64:33244  \n yes difficulty walking: 42675   male  :111706   65 to 69:32194  \n                                                 55 to 59:30832  \n                                                 50 to 54:26314  \n                                                 70 to 74:23533  \n                                                 45 to 49:19819  \n                                                 (Other) :87744  \n                                                        Education     \n Never attended school or only kindergarten                  :   174  \n Grades 1 through 8 (Elementary)                             :  4043  \n Grades 9 through 11 (Some high school)                      :  9478  \n Grade 12 or GED (High school graduate)                      : 62750  \n College 1 year to 3 years (Some college or technical school): 69910  \n College 4 years or more (College graduate)                  :107325  \n                                                                      \n                          Income     \n $75,000 or more             :90385  \n $50,000 to less than $75,000:43219  \n $35,000 to less than $50,000:36470  \n $25,000 to less than $35,000:25883  \n $20,000 to less than $25,000:20135  \n $15,000 to less than $20,000:15994  \n (Other)                     :21594  \n\n\nThe categorical variables are summarized into (vertical) one-way contingency tables in descending order of number of respondents. Note that for more than six categories, the summaries lump values into “(Other).” We obtain measures of center and spread for the numerical variables. Some of the BMI values are extremely low or high; we will examine these when we perform a numerical analysis."
  },
  {
    "objectID": "EDA.html#clean-up-data-as-needed",
    "href": "EDA.html#clean-up-data-as-needed",
    "title": "FinalProjectEDA",
    "section": "Clean Up Data As Needed",
    "text": "Clean Up Data As Needed"
  },
  {
    "objectID": "EDA.html#investigate-distributions",
    "href": "EDA.html#investigate-distributions",
    "title": "FinalProjectEDA",
    "section": "Investigate Distributions",
    "text": "Investigate Distributions\n\nContingency Tables for Predictors and Responses\nWe will examine one-, two-, and three-way contingency tables for the predictors and response. We will also include Age for some assessments, since it may provide insight about certain categories.\n\nOne-Way Contingency Tables\nFor the one-way contingency table related to the response:\n\ntable(data$Diabetes_binary,dnn=\"Diabetes_binary\")\n\nDiabetes_binary\n            no diabetes prediabetes or diabetes \n                 218334                   35346 \n\n\nFor the predictors:\n\ntable(data$Age,dnn=\"Age\")\n\nAge\n   18 to 24    25 to 29    30 to 34    35 to 39    40 to 44    45 to 49 \n       5700        7598       11123       13823       16157       19819 \n   50 to 54    55 to 59    60 to 64    65 to 69    70 to 74    75 to 79 \n      26314       30832       33244       32194       23533       15980 \n80 or older \n      17363 \n\n\n\ntable(data$Sex,dnn=\"Sex\")\n\nSex\nfemale   male \n141974 111706 \n\n\n\ntable(data$Income,dnn=\"Income\")\n\nIncome\n           Less than $10,000 $10,000 to less than $15,000 \n                        9811                        11783 \n$15,000 to less than $20,000 $20,000 to less than $25,000 \n                       15994                        20135 \n$25,000 to less than $35,000 $35,000 to less than $50,000 \n                       25883                        36470 \n$50,000 to less than $75,000              $75,000 or more \n                       43219                        90385 \n\n\n\ntable(data$Stroke,dnn=\"Stroke\")\n\nStroke\n    no    yes \n243388  10292 \n\n\n\ntable(data$HeartDiseaseorAttack,dnn=\"Heart Disease or Attack\")\n\nHeart Disease or Attack\n    no    yes \n229787  23893 \n\n\n\ntable(data$HvyAlcoholConsump,dnn=\"Heavy Alcohol Consumption\")\n\nHeavy Alcohol Consumption\n    no    yes \n239424  14256 \n\n\n\n\nTwo-Way Contingency Tables\nNext, we consider two-way contingency tables between the predictors and the response. We will use the ascii package so that we can make the tables look less muddled and more precise regarding categories.\nDiabetes_binary vs. Age:\n\nprint(ascii(table(data$Age,data$Diabetes_binary,dnn=c(\"Age\",\"Diabetes_binary\"))),type=\"rest\")\n\n\n+---------+-------------+---------------------+-------------------------+\n|                       | **Diabetes_binary**                           |\n+                       +---------------------+-------------------------+\n|                       | no diabetes         | prediabetes or diabetes |\n+=========+=============+=====================+=========================+\n| **Age** | 18 to 24    | 5622.00             | 78.00                   |\n+         +-------------+---------------------+-------------------------+\n|         | 25 to 29    | 7458.00             | 140.00                  |\n+         +-------------+---------------------+-------------------------+\n|         | 30 to 34    | 10809.00            | 314.00                  |\n+         +-------------+---------------------+-------------------------+\n|         | 35 to 39    | 13197.00            | 626.00                  |\n+         +-------------+---------------------+-------------------------+\n|         | 40 to 44    | 15106.00            | 1051.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 45 to 49    | 18077.00            | 1742.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 50 to 54    | 23226.00            | 3088.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 55 to 59    | 26569.00            | 4263.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 60 to 64    | 27511.00            | 5733.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 65 to 69    | 25636.00            | 6558.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 70 to 74    | 18392.00            | 5141.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 75 to 79    | 12577.00            | 3403.00                 |\n+         +-------------+---------------------+-------------------------+\n|         | 80 or older | 14154.00            | 3209.00                 |\n+---------+-------------+---------------------+-------------------------+\n\n\nDiabetes_binary vs. Sex:\n\nprint(ascii(table(data$Sex,data$Diabetes_binary,dnn=c(\"Sex\",\"Diabetes_binary\"))),type=\"rest\")\n\n\n+---------+--------+---------------------+-------------------------+\n|                  | **Diabetes_binary**                           |\n+                  +---------------------+-------------------------+\n|                  | no diabetes         | prediabetes or diabetes |\n+=========+========+=====================+=========================+\n| **Sex** | female | 123563.00           | 18411.00                |\n+         +--------+---------------------+-------------------------+\n|         | male   | 94771.00            | 16935.00                |\n+---------+--------+---------------------+-------------------------+\n\n\nDiabetes_binary vs. Income:\n\nprint(ascii(table(data$Income,data$Diabetes_binary,dnn=c(\"Income\",\"Diabetes_binary\"))),type=\"rest\")\n\n\n+------------+------------------------------+---------------------+-------------------------+\n|                                           | **Diabetes_binary**                           |\n+                                           +---------------------+-------------------------+\n|                                           | no diabetes         | prediabetes or diabetes |\n+============+==============================+=====================+=========================+\n| **Income** | Less than $10,000            | 7428.00             | 2383.00                 |\n+            +------------------------------+---------------------+-------------------------+\n|            | $10,000 to less than $15,000 | 8697.00             | 3086.00                 |\n+            +------------------------------+---------------------+-------------------------+\n|            | $15,000 to less than $20,000 | 12426.00            | 3568.00                 |\n+            +------------------------------+---------------------+-------------------------+\n|            | $20,000 to less than $25,000 | 16081.00            | 4054.00                 |\n+            +------------------------------+---------------------+-------------------------+\n|            | $25,000 to less than $35,000 | 21379.00            | 4504.00                 |\n+            +------------------------------+---------------------+-------------------------+\n|            | $35,000 to less than $50,000 | 31179.00            | 5291.00                 |\n+            +------------------------------+---------------------+-------------------------+\n|            | $50,000 to less than $75,000 | 37954.00            | 5265.00                 |\n+            +------------------------------+---------------------+-------------------------+\n|            | $75,000 or more              | 83190.00            | 7195.00                 |\n+------------+------------------------------+---------------------+-------------------------+\n\n\nDiabetes_binary vs. Stroke:\n\nprint(ascii(table(data$Stroke,data$Diabetes_binary,dnn=c(\"Stroke\",\"Diabetes_binary\"))),type=\"rest\")\n\n\n+------------+-----+---------------------+-------------------------+\n|                  | **Diabetes_binary**                           |\n+                  +---------------------+-------------------------+\n|                  | no diabetes         | prediabetes or diabetes |\n+============+=====+=====================+=========================+\n| **Stroke** | no  | 211310.00           | 32078.00                |\n+            +-----+---------------------+-------------------------+\n|            | yes | 7024.00             | 3268.00                 |\n+------------+-----+---------------------+-------------------------+\n\n\nDiabetes_binary vs. HeartDiseaseorAttack:\n\nprint(ascii(table(data$HeartDiseaseorAttack,data$Diabetes_binary,dnn=c(\"Heart Disease or Attack\",\"Diabetes_binary\"))),type=\"rest\")\n\n\n+-----------------------------+-----+---------------------+-------------------------+\n|                                   | **Diabetes_binary**                           |\n+                                   +---------------------+-------------------------+\n|                                   | no diabetes         | prediabetes or diabetes |\n+=============================+=====+=====================+=========================+\n| **Heart Disease or Attack** | no  | 202319.00           | 27468.00                |\n+                             +-----+---------------------+-------------------------+\n|                             | yes | 16015.00            | 7878.00                 |\n+-----------------------------+-----+---------------------+-------------------------+\n\n\nDiabetes_binary vs. HvyAlcoholConsump:\n\nprint(ascii(table(data$HvyAlcoholConsump,data$Diabetes_binary,dnn=c(\"Heavy Alcohol Consumption\",\"Diabetes_binary\"))),type=\"rest\")\n\n\n+-------------------------------+-----+---------------------+-------------------------+\n|                                     | **Diabetes_binary**                           |\n+                                     +---------------------+-------------------------+\n|                                     | no diabetes         | prediabetes or diabetes |\n+===============================+=====+=====================+=========================+\n| **Heavy Alcohol Consumption** | no  | 204910.00           | 34514.00                |\n+                               +-----+---------------------+-------------------------+\n|                               | yes | 13424.00            | 832.00                  |\n+-------------------------------+-----+---------------------+-------------------------+\n\n\nWe will also examine a selection of two-way contingency tables among the different chosen predictors:\nSex vs. Age:\n\nprint(ascii(table(data$Age,data$Sex,dnn=c(\"Age\",\"Sex\"))),type=\"rest\")\n\n\n+---------+-------------+----------+----------+\n|                       | **Sex**             |\n+                       +----------+----------+\n|                       | female   | male     |\n+=========+=============+==========+==========+\n| **Age** | 18 to 24    | 2745.00  | 2955.00  |\n+         +-------------+----------+----------+\n|         | 25 to 29    | 3991.00  | 3607.00  |\n+         +-------------+----------+----------+\n|         | 30 to 34    | 6062.00  | 5061.00  |\n+         +-------------+----------+----------+\n|         | 35 to 39    | 7725.00  | 6098.00  |\n+         +-------------+----------+----------+\n|         | 40 to 44    | 9136.00  | 7021.00  |\n+         +-------------+----------+----------+\n|         | 45 to 49    | 10928.00 | 8891.00  |\n+         +-------------+----------+----------+\n|         | 50 to 54    | 14805.00 | 11509.00 |\n+         +-------------+----------+----------+\n|         | 55 to 59    | 17469.00 | 13363.00 |\n+         +-------------+----------+----------+\n|         | 60 to 64    | 18271.00 | 14973.00 |\n+         +-------------+----------+----------+\n|         | 65 to 69    | 17743.00 | 14451.00 |\n+         +-------------+----------+----------+\n|         | 70 to 74    | 13159.00 | 10374.00 |\n+         +-------------+----------+----------+\n|         | 75 to 79    | 9418.00  | 6562.00  |\n+         +-------------+----------+----------+\n|         | 80 or older | 10522.00 | 6841.00  |\n+---------+-------------+----------+----------+\n\n\nFor respondents between 18 to 24, more males than females responded to the survey. For the other age ranges, more females than males responded. Also, above age 74, there are significantly more female than male respondents; it is well-known that the average lifespan of males is less than that of females. So, it is likely that there are fewer males, compared with females, to respond to the survey.\nHeartDiseaseorAttack vs. Stroke:\n\nprint(ascii(table(data$Stroke,data$HeartDiseaseorAttack,dnn=c(\"Stroke\",\"Heart Disease or Attack\"))),type=\"rest\")\n\n\n+------------+-----+-----------------------------+----------+\n|                  | **Heart Disease or Attack**            |\n+                  +-----------------------------+----------+\n|                  | no                          | yes      |\n+============+=====+=============================+==========+\n| **Stroke** | no  | 223432.00                   | 19956.00 |\n+            +-----+-----------------------------+----------+\n|            | yes | 6355.00                     | 3937.00  |\n+------------+-----+-----------------------------+----------+\n\n\nWe see that among the respondents, some have been assessed to have both a stroke and heart disease.\nHvyAlcoholConsump vs. Stroke:\n\nprint(ascii(table(data$Stroke,data$HvyAlcoholConsump,dnn=c(\"Stroke\",\"Heavy Alcohol Consumption\"))),type=\"rest\")\n\n\n+------------+-----+-------------------------------+----------+\n|                  | **Heavy Alcohol Consumption**            |\n+                  +-------------------------------+----------+\n|                  | no                            | yes      |\n+============+=====+===============================+==========+\n| **Stroke** | no  | 229515.00                     | 13873.00 |\n+            +-----+-------------------------------+----------+\n|            | yes | 9909.00                       | 383.00   |\n+------------+-----+-------------------------------+----------+\n\n\nWe see that few of the respondents are both heavy drinkers and have been assessed to have a stroke. Also, we note that the largest numer of respondents report neither drinking heavily nor having been assessed to have had a stroke.\nHvyAlcoholConsump vs. HeartAttackorDisease:\n\nprint(ascii(table(data$HeartDiseaseorAttack,data$HvyAlcoholConsump,dnn=c(\"Heart Disease or Attack\",\"Heavy Alcohol Consumption\"))),type=\"rest\")\n\n\n+-----------------------------+-----+-------------------------------+----------+\n|                                   | **Heavy Alcohol Consumption**            |\n+                                   +-------------------------------+----------+\n|                                   | no                            | yes      |\n+=============================+=====+===============================+==========+\n| **Heart Disease or Attack** | no  | 216379.00                     | 13408.00 |\n+                             +-----+-------------------------------+----------+\n|                             | yes | 23045.00                      | 848.00   |\n+-----------------------------+-----+-------------------------------+----------+\n\n\nWe see that few of the respondents are both heavy drinkers and have heart disease or have had a heart attack. Also, we note that the largest numer of respondents report neither drinking heavily nor having been assessed to have heart disease or a heart attack. This is similar to heavy drinking vs. stroke.\n\n\nThree-Way Contingency Table\nFor a three-way contingency table relating diabetes status to age and sex:\n\n#Three-way contingency tables\nprint(ascii(table(data$Age,data$Sex,data$Diabetes_binary)),type=\"rest\")\n\n\n+----+-------------+--------+-------------------------+----------+\n|    | Var1        | Var2   | Var3                    | Freq     |\n+====+=============+========+=========================+==========+\n| 1  | 18 to 24    | female | no diabetes             | 2700.00  |\n+----+-------------+--------+-------------------------+----------+\n| 2  | 25 to 29    | female | no diabetes             | 3902.00  |\n+----+-------------+--------+-------------------------+----------+\n| 3  | 30 to 34    | female | no diabetes             | 5871.00  |\n+----+-------------+--------+-------------------------+----------+\n| 4  | 35 to 39    | female | no diabetes             | 7359.00  |\n+----+-------------+--------+-------------------------+----------+\n| 5  | 40 to 44    | female | no diabetes             | 8560.00  |\n+----+-------------+--------+-------------------------+----------+\n| 6  | 45 to 49    | female | no diabetes             | 10026.00 |\n+----+-------------+--------+-------------------------+----------+\n| 7  | 50 to 54    | female | no diabetes             | 13163.00 |\n+----+-------------+--------+-------------------------+----------+\n| 8  | 55 to 59    | female | no diabetes             | 15214.00 |\n+----+-------------+--------+-------------------------+----------+\n| 9  | 60 to 64    | female | no diabetes             | 15303.00 |\n+----+-------------+--------+-------------------------+----------+\n| 10 | 65 to 69    | female | no diabetes             | 14493.00 |\n+----+-------------+--------+-------------------------+----------+\n| 11 | 70 to 74    | female | no diabetes             | 10606.00 |\n+----+-------------+--------+-------------------------+----------+\n| 12 | 75 to 79    | female | no diabetes             | 7584.00  |\n+----+-------------+--------+-------------------------+----------+\n| 13 | 80 or older | female | no diabetes             | 8782.00  |\n+----+-------------+--------+-------------------------+----------+\n| 14 | 18 to 24    | male   | no diabetes             | 2922.00  |\n+----+-------------+--------+-------------------------+----------+\n| 15 | 25 to 29    | male   | no diabetes             | 3556.00  |\n+----+-------------+--------+-------------------------+----------+\n| 16 | 30 to 34    | male   | no diabetes             | 4938.00  |\n+----+-------------+--------+-------------------------+----------+\n| 17 | 35 to 39    | male   | no diabetes             | 5838.00  |\n+----+-------------+--------+-------------------------+----------+\n| 18 | 40 to 44    | male   | no diabetes             | 6546.00  |\n+----+-------------+--------+-------------------------+----------+\n| 19 | 45 to 49    | male   | no diabetes             | 8051.00  |\n+----+-------------+--------+-------------------------+----------+\n| 20 | 50 to 54    | male   | no diabetes             | 10063.00 |\n+----+-------------+--------+-------------------------+----------+\n| 21 | 55 to 59    | male   | no diabetes             | 11355.00 |\n+----+-------------+--------+-------------------------+----------+\n| 22 | 60 to 64    | male   | no diabetes             | 12208.00 |\n+----+-------------+--------+-------------------------+----------+\n| 23 | 65 to 69    | male   | no diabetes             | 11143.00 |\n+----+-------------+--------+-------------------------+----------+\n| 24 | 70 to 74    | male   | no diabetes             | 7786.00  |\n+----+-------------+--------+-------------------------+----------+\n| 25 | 75 to 79    | male   | no diabetes             | 4993.00  |\n+----+-------------+--------+-------------------------+----------+\n| 26 | 80 or older | male   | no diabetes             | 5372.00  |\n+----+-------------+--------+-------------------------+----------+\n| 27 | 18 to 24    | female | prediabetes or diabetes | 45.00    |\n+----+-------------+--------+-------------------------+----------+\n| 28 | 25 to 29    | female | prediabetes or diabetes | 89.00    |\n+----+-------------+--------+-------------------------+----------+\n| 29 | 30 to 34    | female | prediabetes or diabetes | 191.00   |\n+----+-------------+--------+-------------------------+----------+\n| 30 | 35 to 39    | female | prediabetes or diabetes | 366.00   |\n+----+-------------+--------+-------------------------+----------+\n| 31 | 40 to 44    | female | prediabetes or diabetes | 576.00   |\n+----+-------------+--------+-------------------------+----------+\n| 32 | 45 to 49    | female | prediabetes or diabetes | 902.00   |\n+----+-------------+--------+-------------------------+----------+\n| 33 | 50 to 54    | female | prediabetes or diabetes | 1642.00  |\n+----+-------------+--------+-------------------------+----------+\n| 34 | 55 to 59    | female | prediabetes or diabetes | 2255.00  |\n+----+-------------+--------+-------------------------+----------+\n| 35 | 60 to 64    | female | prediabetes or diabetes | 2968.00  |\n+----+-------------+--------+-------------------------+----------+\n| 36 | 65 to 69    | female | prediabetes or diabetes | 3250.00  |\n+----+-------------+--------+-------------------------+----------+\n| 37 | 70 to 74    | female | prediabetes or diabetes | 2553.00  |\n+----+-------------+--------+-------------------------+----------+\n| 38 | 75 to 79    | female | prediabetes or diabetes | 1834.00  |\n+----+-------------+--------+-------------------------+----------+\n| 39 | 80 or older | female | prediabetes or diabetes | 1740.00  |\n+----+-------------+--------+-------------------------+----------+\n| 40 | 18 to 24    | male   | prediabetes or diabetes | 33.00    |\n+----+-------------+--------+-------------------------+----------+\n| 41 | 25 to 29    | male   | prediabetes or diabetes | 51.00    |\n+----+-------------+--------+-------------------------+----------+\n| 42 | 30 to 34    | male   | prediabetes or diabetes | 123.00   |\n+----+-------------+--------+-------------------------+----------+\n| 43 | 35 to 39    | male   | prediabetes or diabetes | 260.00   |\n+----+-------------+--------+-------------------------+----------+\n| 44 | 40 to 44    | male   | prediabetes or diabetes | 475.00   |\n+----+-------------+--------+-------------------------+----------+\n| 45 | 45 to 49    | male   | prediabetes or diabetes | 840.00   |\n+----+-------------+--------+-------------------------+----------+\n| 46 | 50 to 54    | male   | prediabetes or diabetes | 1446.00  |\n+----+-------------+--------+-------------------------+----------+\n| 47 | 55 to 59    | male   | prediabetes or diabetes | 2008.00  |\n+----+-------------+--------+-------------------------+----------+\n| 48 | 60 to 64    | male   | prediabetes or diabetes | 2765.00  |\n+----+-------------+--------+-------------------------+----------+\n| 49 | 65 to 69    | male   | prediabetes or diabetes | 3308.00  |\n+----+-------------+--------+-------------------------+----------+\n| 50 | 70 to 74    | male   | prediabetes or diabetes | 2588.00  |\n+----+-------------+--------+-------------------------+----------+\n| 51 | 75 to 79    | male   | prediabetes or diabetes | 1569.00  |\n+----+-------------+--------+-------------------------+----------+\n| 52 | 80 or older | male   | prediabetes or diabetes | 1469.00  |\n+----+-------------+--------+-------------------------+----------+\n\n\nThis format flattens the three-way table, which is good in a way since we can see everything in one table rather than in two separated tables. We will provide an interpretation below when we examine the first bar chart below!\n\n\nNumeric Summaries\nAlthough we do not include any numeric variables as predictors, we will summarize our numeric variables over the entire set of respondents, then filter for diabetes status:\n\nsummary(data |&gt;\n          select(where(is.numeric)))\n\n      BMI           MentHlth         PhysHlth     \n Min.   :12.00   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:24.00   1st Qu.: 0.000   1st Qu.: 0.000  \n Median :27.00   Median : 0.000   Median : 0.000  \n Mean   :28.38   Mean   : 3.185   Mean   : 4.242  \n 3rd Qu.:31.00   3rd Qu.: 2.000   3rd Qu.: 3.000  \n Max.   :98.00   Max.   :30.000   Max.   :30.000  \n\nsummary(data |&gt;\n          filter(Diabetes_binary == \"no diabetes\") |&gt;\n          select(where(is.numeric)))\n\n      BMI           MentHlth         PhysHlth     \n Min.   :12.00   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:24.00   1st Qu.: 0.000   1st Qu.: 0.000  \n Median :27.00   Median : 0.000   Median : 0.000  \n Mean   :27.81   Mean   : 2.978   Mean   : 3.641  \n 3rd Qu.:31.00   3rd Qu.: 2.000   3rd Qu.: 2.000  \n Max.   :98.00   Max.   :30.000   Max.   :30.000  \n\nsummary(data |&gt;\n          filter(Diabetes_binary == \"prediabetes or diabetes\") |&gt;\n          select(where(is.numeric)))\n\n      BMI           MentHlth         PhysHlth     \n Min.   :13.00   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:27.00   1st Qu.: 0.000   1st Qu.: 0.000  \n Median :31.00   Median : 0.000   Median : 1.000  \n Mean   :31.94   Mean   : 4.462   Mean   : 7.954  \n 3rd Qu.:35.00   3rd Qu.: 3.000   3rd Qu.:15.000  \n Max.   :98.00   Max.   :30.000   Max.   :30.000  \n\n\nThe top table corresponds to overall correlation of the numeric variables. The second one from the top filters for no diabetes. The final one (bottom) is for prediabetes or diabetes.\nThe BMI among prediabetic and diabetic respondents is higher than among nondiabetics, though the IQR is similar. There seem to be outliers - the minimum and maximum BMI values seem too low and too high for a human being! However, it looks like CDC reports these using the typical BMI measure (these wouldn’t be percentiles since 12 being the lowest percentile would suggest a problem with the survey sample).\nPrediabetics and diabetics report more days with poor mental health than nondiabetics. The IQR is also larger, and the mean is notably larger. This pattern is more pronounced for physical health, where the mean number of days of reported bad health among prediabetics and diabetics is over twice that of nondiabetics. The IQR is also quite large for poor physical health days for prediabetics and diabetics when compared with nondiabetics. However, the 1st quartile for mental and physical health for all respondents is 0 days, and the medians are low (mostly 0), so that suggests many respondents did not report bad mental or physical health.\nWe will examine correlations among our numeric variables:\n\ndata |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  round(3)\n\n           BMI MentHlth PhysHlth\nBMI      1.000    0.085    0.121\nMentHlth 0.085    1.000    0.354\nPhysHlth 0.121    0.354    1.000\n\ndata |&gt;\n  filter(Diabetes_binary == \"no diabetes\") |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  round(3)\n\n           BMI MentHlth PhysHlth\nBMI      1.000    0.065    0.078\nMentHlth 0.065    1.000    0.336\nPhysHlth 0.078    0.336    1.000\n\ndata |&gt;\n  filter(Diabetes_binary == \"prediabetes or diabetes\") |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  round(3)\n\n           BMI MentHlth PhysHlth\nBMI      1.000    0.103    0.122\nMentHlth 0.103    1.000    0.391\nPhysHlth 0.122    0.391    1.000\n\n\nThe top table corresponds to overall correlation of the numeric variables. The second one from the top filters for no diabetes. The final one (bottom) is for prediabetes or diabetes.\nThe correlations between the different numeric variables are not strong. The strongest correlation is between mental and physical health, which is not surprising. For non-diabetics, the correlation between mental and physical health is weaker than for prediabetics and diabetics. The BMI is very weakly correlated with mental and physical health, regardless of diabetes status.\n\n\n\nBar Charts\nWe will look at bar charts to visualize counts of diabetes status by age and sex:\n\nggplot(data, \n       aes(\n         x = Diabetes_binary, fill = Age)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Age\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts vs. Diabetes Status, by Sex and Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nWe see a peak of respondents for nondiabetic males and females in the 60 to 64 age bracket, while there is a peak of prediabetic or diabetic respondents in the 65 to 69 age bracket. The three-way contingency table above has the precise counts provided in this visual.\nWe will also look for relationships between diabetes status, sex, and age:\n\nggplot(data |&gt; filter(Age %in% c(\"18 to 24\",\"25 to 29\")), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 18 to 29\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"30 to 34\",\"35 to 39\")), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 30 to 39\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"40 to 44\",\"45 to 49\")), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 40 to 49\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"50 to 54\",\"55 to 59\")), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 50 to 59\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"60 to 64\",\"65 to 69\")), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 60 to 69\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"70 to 74\",\"75 to 79\")), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 70 to 79\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age == \"80 or older\"), \n       aes(\n         x = Diabetes_binary, fill = Stroke)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_discrete(\"Stroke\") +\n  facet_wrap(~ Sex) + ggtitle(str_wrap(\"Bar Chart of Counts of Stroke Incidence vs. Diabetes Status, by Sex and Age 80 or Older\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nThe results are, perhaps, not surprising. In the youngest age bracket, there are almost no incidences of stroke, regardless of diabetic status. There are also few instances of diabetes. With increasing age, more respondents report having strokes, regardless of diabetes status. However, the proportion of strokes is higher among prediabetics and diabetics than among nondiabetics.\n\n\nScatterplots & Histograms For Numeric Variables\nWe will examine the relationship between the number of days of poor mental health (in the past 30 days) and the number of days of physical illness or injury (in the past 30 days), by age bracket, then filter for diabetes status:\n\n  ggplot(data,\n         aes(\n           x=PhysHlth,y=MentHlth,color=Age)) +\n  geom_point(alpha=0.01) +\n  geom_jitter(width = 0.2, alpha = 0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Mental Health vs. Physical Health, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data |&gt; filter(Diabetes_binary == \"no diabetes\"),\n         aes(\n           x=PhysHlth,y=MentHlth,color=Age)) +\n  geom_point(alpha=0.01) +\n  geom_jitter(width = 0.2, alpha = 0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Mental Health vs. Physical Health, by Age (No Diabetes)\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data |&gt; filter(Diabetes_binary == \"prediabetes or diabetes\"),\n         aes(\n           x=PhysHlth,y=MentHlth,color=Age)) +\n  geom_point(alpha=0.01) +\n  geom_jitter(width = 0.2, alpha = 0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Mental Health vs. Physical Health, by Age (Prediabetes or Diabetes)\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFor people younger than 60, there is a stronger association between mental and physical health than for people over 60, and especially than for people over 70.\nNext, we will examine the relationship of each of these to BMI, then stratify according to diabetes status:\n\n  ggplot(data,\n         aes(\n           x=BMI,y=PhysHlth,color=Age)) +\n  geom_point(alpha = 0.01) +\n  geom_jitter(width = 0.2, alpha=0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Physical Health vs. BMI, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data |&gt; filter(Diabetes_binary == \"no diabetes\"),\n         aes(\n           x=BMI,y=PhysHlth,color=Age)) +\n  geom_point(alpha = 0.01) +\n  geom_jitter(width = 0.2, alpha=0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Physical Health vs. BMI for Non-Diabetics, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data |&gt; filter(Diabetes_binary == \"prediabetes or diabetes\"),\n         aes(\n           x=BMI,y=PhysHlth,color=Age)) +\n  geom_point(alpha = 0.01) +\n  geom_jitter(width = 0.2, alpha=0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Physical Health vs. BMI for Prediabetics and Diabetics, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data,\n         aes(\n           x=BMI,y=MentHlth,color=Age)) +\n  geom_point(alpha = 0.01) +\n  geom_jitter(width = 0.2, alpha=0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Mental Health vs. BMI, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data |&gt; filter(Diabetes_binary == \"no diabetes\"),\n         aes(\n           x=BMI,y=MentHlth,color=Age)) +\n  geom_point(alpha = 0.01) +\n  geom_jitter(width = 0.2, alpha=0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Mental Health vs. BMI for Non-Diabetics, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n  ggplot(data |&gt; filter(Diabetes_binary == \"prediabetes or diabetes\"),\n         aes(\n           x=BMI,y=MentHlth,color=Age)) +\n  geom_point(alpha = 0.01) +\n  geom_jitter(width = 0.2, alpha=0.01) +\n  geom_smooth(method = lm, level=0) + ggtitle(str_wrap(\"Scatterplot of Mental Health vs. BMI for Prediabetics and Diabetics, by Age\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe association between physical health and BMI grows stronger with age. We can see this by\nThen, we will examine the distributions of PhysHlth, MentHlth, and BMI based on whether individuals have diabetes.\n\nggplot(data,\n       aes(\n         x=PhysHlth\n       )) + \n  geom_histogram(alpha=0.5,\n    aes(fill = Diabetes_binary, \n        col=I(\"black\")),\n    position = \"identity\",\n    binwidth=1) + \n  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) + xlab(\"PhysHlth\") + ylab(\"Count\") + ggtitle(str_wrap(\"Count of Respondents per Number of Days of Physical Illness or Injury, by Diabetes Status\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data,\n       aes(\n         x=MentHlth\n       )) + \n  geom_histogram(alpha=0.5,\n    aes(fill = Diabetes_binary, \n        col=I(\"black\")),\n    position = \"identity\",\n    binwidth=1) + \n  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) + xlab(\"MentHlth\") + ylab(\"Count\") + ggtitle(str_wrap(\"Count of Respondents per Number of Poor Mental Health Days, by Diabetes Status\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nggplot(data,\n       aes(\n         x=BMI\n       )) + \n  geom_histogram(alpha=0.5,\n    aes(y=after_stat(density),\n        fill = Diabetes_binary, \n        col=I(\"black\")),\n    position = \"identity\",\n    binwidth=1) + \n  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) + xlab(\"BMI\") + ylab(\"Density\") + ggtitle(str_wrap(\"Density of Respondents per BMI, by Diabetes Status\",30)) + theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nMost of the respondents indicated no poor mental health or poor physical health days. However, the ratio of prediabetics or diabetics to nondiabetics who reported number of days of physical illness or injury was greater at 30 days than at 0 days; the same is true for poor mental health days. However, this only shows an association and does not prove that the respondents’ illnesses were due to diabetes or something else.\nThe density of respondents by BMI, by diabetes status, shows a higher BMI for prediabetics and diabetics than for nondiabetics. (This is elucidated more clearly in the box plots below.). The peak density of respondents is the same at just over 25 BMI. However, the nondiabetic respondents’ BMI values fall off much more quickly than the prediabetic and diabetic respondents’ BMI values.\n\n\nBox Plots\nWe will look at box plots to see how the BMI varies by sex and diabetes status:\n\nggplot(data |&gt; filter(Age %in% c(\"18 to 24\",\"25 to 29\")), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"30 to 34\",\"35 to 39\")), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"40 to 44\",\"45 to 49\")), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"50 to 54\",\"55 to 59\")), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"60 to 64\",\"65 to 69\")), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age %in% c(\"70 to 74\",\"75 to 79\")), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\nggplot(data |&gt; filter(Age == \"80 or older\"), aes(x = Sex, y = BMI, fill = Diabetes_binary)) +\ngeom_boxplot(, outlier.alpha=0.1) +\n  stat_summary(fun = mean, color = \"red\", position = position_dodge(0.75),\n                geom = \"point\", shape = 20, size = 1,\n                show.legend = FALSE) +  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +\n  facet_wrap(~ Age)\n\n\n\n\n\n\n\n\nAmong the 18 to 29 age bracket, the distributions of BMI look right-skewed regardless of sex or diabetes status. 30 to 34 year old nondiabetic females continue to show a right-skewed distribution of BMI. The mean BMI (red dot) is notably higher than the median BMI in diabetic males and females between 18 and 29 years compared with other age brackets.\nInterestingly, 45 to 49 year old prediabetic and diabetic females show a slight right-skewed BMI again, as do 55 to 59 year old prediabetic and diabetic males.\n60 to 69 year old nondiabetic males show a right-skewed BMI distribution, as do 70 to 74 year old males and 80 or older females with no diabetes.\nIt is unclear without doing more analysis to determine why the BMI are skewed (lifestyle or other factors). Also, it is possibly beyond the scope of investigating diabetes status.\nIn most of the age brackets, prediabetics and diabetics have a wider IQR for their BMI than nondiabetics. The 1st, 2nd, and 3rd quartiles of prediabetics and diabetics tend to be higher than those of nondiabetics. Females with prediabetes or diabetes have medians that are near or above the 3rd quartile of nondiabetic women. This trend persists across age brackets."
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "Write an intro! We will include (at least) 5 predictors in this model: (ORIGINALS! age, sex, income, smoker, and heart disease or attack) sex, income, stroke, heart disease or attack, and heavy alcohol consumption.\nWe will load the libraries and read in the data here:\n\nlibrary(baguette)\n\nLoading required package: parsnip\n\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nlibrary(ggplot2)\nlibrary(glmnet)\n\nLoading required package: Matrix\n\n\nLoaded glmnet 4.1-8\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(ranger)\n#library(randomForest)\nlibrary(stringr)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tibble       3.2.1\n✔ dplyr        1.1.4     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.2.1\n✔ modeldata    1.4.0     ✔ workflows    1.1.4\n✔ purrr        1.0.2     ✔ workflowsets 1.1.0\n✔ recipes      1.1.0     ✔ yardstick    1.3.1\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()  masks scales::discard()\n✖ tidyr::expand()   masks Matrix::expand()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ tidyr::pack()     masks Matrix::pack()\n✖ recipes::step()   masks stats::step()\n✖ tidyr::unpack()   masks Matrix::unpack()\n✖ recipes::update() masks Matrix::update(), stats::update()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats 1.0.0     ✔ readr   2.1.5\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ recipes::fixed()    masks stringr::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ readr::spec()       masks yardstick::spec()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(vroom)\n\n\nAttaching package: 'vroom'\n\nThe following objects are masked from 'package:readr':\n\n    as.col_spec, col_character, col_date, col_datetime, col_double,\n    col_factor, col_guess, col_integer, col_logical, col_number,\n    col_skip, col_time, cols, cols_condense, cols_only, date_names,\n    date_names_lang, date_names_langs, default_locale, fwf_cols,\n    fwf_empty, fwf_positions, fwf_widths, locale, output_column,\n    problems, spec\n\nThe following object is masked from 'package:yardstick':\n\n    spec\n\nThe following object is masked from 'package:scales':\n\n    col_factor\n\n#diabetes_binary_health_indicators_BRFSS2015.csv\n#dbhi = diabetes binary health indicators\ndata &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1               0      1        1         1    40      1      0\n 2               0      0        0         0    25      1      0\n 3               0      1        1         1    28      0      0\n 4               0      1        0         1    27      0      0\n 5               0      1        1         1    24      0      0\n 6               0      1        1         1    25      1      0\n 7               0      1        0         1    30      1      0\n 8               0      1        1         1    25      1      0\n 9               1      1        1         1    30      1      0\n10               0      0        0         1    24      0      0\n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nNext, we will convert variables to factor variables, where appropriate:\n\ndata &lt;- data |&gt;\n  mutate(Diabetes_binary=\n           factor(Diabetes_binary,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no diabetes\",\"prediabetes or diabetes\")),\n         HighBP=\n           factor(HighBP,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high BP\",\"high BP\")),\n         HighChol=\n           factor(HighChol,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high cholesterol\",\"high cholesterol\")),\n         CholCheck=\n           factor(CholCheck,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no cholesterol check in 5 years\",\"yes cholesterol check in 5 years\")),\n         #BMI=factor(BMI),\n         Smoker=\n           factor(Smoker,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Stroke=\n           factor(Stroke,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HeartDiseaseorAttack=\n           factor(HeartDiseaseorAttack,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         PhysActivity=\n           factor(PhysActivity,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Fruits=\n           factor(Fruits,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Veggies=\n           factor(Veggies,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HvyAlcoholConsump=\n           factor(HvyAlcoholConsump,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         AnyHealthcare=\n           factor(AnyHealthcare,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         NoDocbcCost=\n           factor(NoDocbcCost,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         GenHlth=\n           factor(GenHlth,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                  labels=c(\"excellent\",\"very good\",\"good\",\"fair\",\"poor\")),\n         #MentHlth=\n           #factor(MentHlth),\n         #PhysHlth=\n           #factor(PhysHlth),\n         DiffWalk=\n           factor(DiffWalk,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no difficulty walking\",\"yes difficulty walking\")),\n         Sex=\n           factor(Sex,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"female\",\"male\")),\n         Age=\n           factor(Age,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\"),\n                  labels=c(\"18 to 24\",\"25 to 29\",\"30 to 34\",\"35 to 39\",\"40 to 44\",\"45 to 49\",\"50 to 54\",\"55 to 59\",\"60 to 64\",\"65 to 69\",\"70 to 74\",\"75 to 79\",\"80 or older\")),\n         Education=\n           factor(Education,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"),\n                  labels=c(\"Never attended school or only kindergarten\",\"Grades 1 through 8 (Elementary)\",\"Grades 9 through 11 (Some high school)\",\"Grade 12 or GED (High school graduate)\",\"College 1 year to 3 years (Some college or technical school)\",\"College 4 years or more (College graduate)\")),\n         Income=\n           factor(Income,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"),\n                  labels=c(\"Less than $10,000\",\"$10,000 to less than $15,000\",\"$15,000 to less than $20,000\",\"$20,000 to less than $25,000\",\"$25,000 to less than $35,000\",\"$35,000 to less than $50,000\",\"$50,000 to less than $75,000\",\"$75,000 or more\"))\n         )\n\nNow, subset the data to look at the 5 predictors:\n\ndbhi_data &lt;- data #|&gt; \n#  select(Diabetes_binary,Age,HeartDiseaseorAttack,Income,Sex,Smoker)\ndbhi_data\n\n# A tibble: 253,680 × 22\n   Diabetes_binary         HighBP     HighChol     CholCheck   BMI Smoker Stroke\n   &lt;fct&gt;                   &lt;fct&gt;      &lt;fct&gt;        &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; \n 1 no diabetes             high BP    high choles… yes chol…    40 yes    no    \n 2 no diabetes             no high BP no high cho… no chole…    25 yes    no    \n 3 no diabetes             high BP    high choles… yes chol…    28 no     no    \n 4 no diabetes             high BP    no high cho… yes chol…    27 no     no    \n 5 no diabetes             high BP    high choles… yes chol…    24 no     no    \n 6 no diabetes             high BP    high choles… yes chol…    25 yes    no    \n 7 no diabetes             high BP    no high cho… yes chol…    30 yes    no    \n 8 no diabetes             high BP    high choles… yes chol…    25 yes    no    \n 9 prediabetes or diabetes high BP    high choles… yes chol…    30 yes    no    \n10 no diabetes             no high BP no high cho… yes chol…    24 no     no    \n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,\n#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;fct&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;fct&gt;"
  },
  {
    "objectID": "Modeling.html#introduction",
    "href": "Modeling.html#introduction",
    "title": "Modeling",
    "section": "",
    "text": "Write an intro! We will include (at least) 5 predictors in this model: (ORIGINALS! age, sex, income, smoker, and heart disease or attack) sex, income, stroke, heart disease or attack, and heavy alcohol consumption.\nWe will load the libraries and read in the data here:\n\nlibrary(baguette)\n\nLoading required package: parsnip\n\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nlibrary(ggplot2)\nlibrary(glmnet)\n\nLoading required package: Matrix\n\n\nLoaded glmnet 4.1-8\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(ranger)\n#library(randomForest)\nlibrary(stringr)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tibble       3.2.1\n✔ dplyr        1.1.4     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.2.1\n✔ modeldata    1.4.0     ✔ workflows    1.1.4\n✔ purrr        1.0.2     ✔ workflowsets 1.1.0\n✔ recipes      1.1.0     ✔ yardstick    1.3.1\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard()  masks scales::discard()\n✖ tidyr::expand()   masks Matrix::expand()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ tidyr::pack()     masks Matrix::pack()\n✖ recipes::step()   masks stats::step()\n✖ tidyr::unpack()   masks Matrix::unpack()\n✖ recipes::update() masks Matrix::update(), stats::update()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats 1.0.0     ✔ readr   2.1.5\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ recipes::fixed()    masks stringr::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ readr::spec()       masks yardstick::spec()\n✖ tidyr::unpack()     masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(vroom)\n\n\nAttaching package: 'vroom'\n\nThe following objects are masked from 'package:readr':\n\n    as.col_spec, col_character, col_date, col_datetime, col_double,\n    col_factor, col_guess, col_integer, col_logical, col_number,\n    col_skip, col_time, cols, cols_condense, cols_only, date_names,\n    date_names_lang, date_names_langs, default_locale, fwf_cols,\n    fwf_empty, fwf_positions, fwf_widths, locale, output_column,\n    problems, spec\n\nThe following object is masked from 'package:yardstick':\n\n    spec\n\nThe following object is masked from 'package:scales':\n\n    col_factor\n\n#diabetes_binary_health_indicators_BRFSS2015.csv\n#dbhi = diabetes binary health indicators\ndata &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata\n\n# A tibble: 253,680 × 22\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1               0      1        1         1    40      1      0\n 2               0      0        0         0    25      1      0\n 3               0      1        1         1    28      0      0\n 4               0      1        0         1    27      0      0\n 5               0      1        1         1    24      0      0\n 6               0      1        1         1    25      1      0\n 7               0      1        0         1    30      1      0\n 8               0      1        1         1    25      1      0\n 9               1      1        1         1    30      1      0\n10               0      0        0         1    24      0      0\n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nNext, we will convert variables to factor variables, where appropriate:\n\ndata &lt;- data |&gt;\n  mutate(Diabetes_binary=\n           factor(Diabetes_binary,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no diabetes\",\"prediabetes or diabetes\")),\n         HighBP=\n           factor(HighBP,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high BP\",\"high BP\")),\n         HighChol=\n           factor(HighChol,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no high cholesterol\",\"high cholesterol\")),\n         CholCheck=\n           factor(CholCheck,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no cholesterol check in 5 years\",\"yes cholesterol check in 5 years\")),\n         #BMI=factor(BMI),\n         Smoker=\n           factor(Smoker,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Stroke=\n           factor(Stroke,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HeartDiseaseorAttack=\n           factor(HeartDiseaseorAttack,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         PhysActivity=\n           factor(PhysActivity,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Fruits=\n           factor(Fruits,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         Veggies=\n           factor(Veggies,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         HvyAlcoholConsump=\n           factor(HvyAlcoholConsump,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         AnyHealthcare=\n           factor(AnyHealthcare,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         NoDocbcCost=\n           factor(NoDocbcCost,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no\",\"yes\")),\n         GenHlth=\n           factor(GenHlth,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                  labels=c(\"excellent\",\"very good\",\"good\",\"fair\",\"poor\")),\n         #MentHlth=\n           #factor(MentHlth),\n         #PhysHlth=\n           #factor(PhysHlth),\n         DiffWalk=\n           factor(DiffWalk,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"no difficulty walking\",\"yes difficulty walking\")),\n         Sex=\n           factor(Sex,\n                  levels=c(\"0\",\"1\"),\n                  labels=c(\"female\",\"male\")),\n         Age=\n           factor(Age,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\"),\n                  labels=c(\"18 to 24\",\"25 to 29\",\"30 to 34\",\"35 to 39\",\"40 to 44\",\"45 to 49\",\"50 to 54\",\"55 to 59\",\"60 to 64\",\"65 to 69\",\"70 to 74\",\"75 to 79\",\"80 or older\")),\n         Education=\n           factor(Education,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"),\n                  labels=c(\"Never attended school or only kindergarten\",\"Grades 1 through 8 (Elementary)\",\"Grades 9 through 11 (Some high school)\",\"Grade 12 or GED (High school graduate)\",\"College 1 year to 3 years (Some college or technical school)\",\"College 4 years or more (College graduate)\")),\n         Income=\n           factor(Income,\n                  levels=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"),\n                  labels=c(\"Less than $10,000\",\"$10,000 to less than $15,000\",\"$15,000 to less than $20,000\",\"$20,000 to less than $25,000\",\"$25,000 to less than $35,000\",\"$35,000 to less than $50,000\",\"$50,000 to less than $75,000\",\"$75,000 or more\"))\n         )\n\nNow, subset the data to look at the 5 predictors:\n\ndbhi_data &lt;- data #|&gt; \n#  select(Diabetes_binary,Age,HeartDiseaseorAttack,Income,Sex,Smoker)\ndbhi_data\n\n# A tibble: 253,680 × 22\n   Diabetes_binary         HighBP     HighChol     CholCheck   BMI Smoker Stroke\n   &lt;fct&gt;                   &lt;fct&gt;      &lt;fct&gt;        &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; \n 1 no diabetes             high BP    high choles… yes chol…    40 yes    no    \n 2 no diabetes             no high BP no high cho… no chole…    25 yes    no    \n 3 no diabetes             high BP    high choles… yes chol…    28 no     no    \n 4 no diabetes             high BP    no high cho… yes chol…    27 no     no    \n 5 no diabetes             high BP    high choles… yes chol…    24 no     no    \n 6 no diabetes             high BP    high choles… yes chol…    25 yes    no    \n 7 no diabetes             high BP    no high cho… yes chol…    30 yes    no    \n 8 no diabetes             high BP    high choles… yes chol…    25 yes    no    \n 9 prediabetes or diabetes high BP    high choles… yes chol…    30 yes    no    \n10 no diabetes             no high BP no high cho… yes chol…    24 no     no    \n# ℹ 253,670 more rows\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,\n#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;fct&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;fct&gt;"
  },
  {
    "objectID": "Modeling.html#split-the-data",
    "href": "Modeling.html#split-the-data",
    "title": "Modeling",
    "section": "Split the Data",
    "text": "Split the Data\nSet the seed. Then, use functions from tidymodels to split the data into a training and test set (70/30 split). Then, use the strata argument to stratify the split on the Sex variable.\n\nset.seed(11)\ndbhi_split &lt;- initial_split(dbhi_data, prop = 0.70, strata=Sex) #strata = argument goes in the parentheses, if needed\ndbhi_train &lt;- training(dbhi_split)\ndbhi_test &lt;- testing(dbhi_split)\n\nWe will perform 5-fold cross validation:\n\ndbhi_5_fold &lt;- vfold_cv(dbhi_train, 5)\n\ndbhi_5_fold\n\n#  5-fold cross-validation \n# A tibble: 5 × 2\n  splits                 id   \n  &lt;list&gt;                 &lt;chr&gt;\n1 &lt;split [142060/35515]&gt; Fold1\n2 &lt;split [142060/35515]&gt; Fold2\n3 &lt;split [142060/35515]&gt; Fold3\n4 &lt;split [142060/35515]&gt; Fold4\n5 &lt;split [142060/35515]&gt; Fold5"
  },
  {
    "objectID": "Modeling.html#models",
    "href": "Modeling.html#models",
    "title": "Modeling",
    "section": "Models",
    "text": "Models\nWe will consider two kinds of models: classification tree and random forest. We will …\nGet a recipe. Then, standardize the numeric variables since their scales are pretty different. Finally, create dummy variables for the predictors since they need to be numeric (again).\n\n#bystanders &lt;- colnames(dbhi_data)[c(2:4,7:18,21)]\n#bystanders\n\n#dbhi_train\n#Diabetes_binary ~ Age + BMI + Income + Sex + Smoker\n#ORIGINALS:  update_role(HighBP,HighChol,CholCheck,Stroke,HeartDiseaseorAttack,PhysActivity,Fruits,Veggies,HvyAlcoholConsump,AnyHealthcare,NoDocbcCost,GenHlth,MentHlth,PhysHlth,DiffWalk,Education,new_role = \"bystander\") \ndbhi_recipe &lt;- recipe(Diabetes_binary ~ ., data = dbhi_train) |&gt;\n  update_role(Age,Smoker,BMI,HighBP,HighChol,CholCheck,PhysActivity,Fruits,Veggies,AnyHealthcare,NoDocbcCost,GenHlth,MentHlth,PhysHlth,DiffWalk,Education,new_role = \"bystander\") |&gt;\n  step_dummy(all_nominal_predictors()) |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) #|&gt;\n#  summary()\n#  prep(training = dbhi_train) |&gt;\n#  bake(dbhi_train)\n\ndbhi_recipe\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor:  5\nbystander: 16\n\n\n\n\n\n── Operations \n\n\n• Dummy variables from: all_nominal_predictors()\n\n\n• Centering and scaling for: all_numeric() and -all_outcomes()\n\n\n\nClassification Tree\nYou should provide a thorough explanation of what a classification tree model is. Then you should fit a classification tree with varying values for the complexity parameter and choose the best model (based on 5 fold CV on the training set). Include at least 5 predictors in this model.\nFirst, tell tidymodels that we are performing a classification task:\n\ntree_mod &lt;- decision_tree(tree_depth = tune(),\n                          min_n = 10,\n                          cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\nNext, create a workflow to use in the fitting process:\n\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(dbhi_recipe) |&gt;\n  add_model(tree_mod)\n\nThen, to create the tuning grid for fitting our models, we use cross validation (CV) to select the tuning parameters:\n\ntemp &lt;- tree_wkf |&gt; \n  tune_grid(resamples = dbhi_5_fold, metrics=metric_set(mn_log_loss))\ntemp |&gt; \n  collect_metrics()\n\n# A tibble: 10 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1        1.41e- 5          6 mn_log_loss binary     0.397     5 3.21e-3 Prepro…\n 2        9.46e- 3          9 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 3        1.05e-10         11 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 4        2.89e- 4          3 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 5        2.97e- 8         13 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 6        7.51e- 8          8 mn_log_loss binary     0.392     5 2.56e-3 Prepro…\n 7        5.06e- 5         14 mn_log_loss binary     0.399     5 2.28e-3 Prepro…\n 8        2.87e- 9          4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 9        5.92e- 2          1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n10        1.02e- 6         11 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n\n\n\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          #min_n(),\n                          tree_depth(),\n                          levels = c(5, 5))\n\ntree_grid\n\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             &lt;dbl&gt;      &lt;int&gt;\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# ℹ 15 more rows\n\n\nThis generates 25 (5x5) candidate decision tree models.\n\ntree_fits &lt;- tree_wkf |&gt; \n  tune_grid(resamples = dbhi_5_fold,\n            metrics=metric_set(mn_log_loss),\n            grid = tree_grid)\ntree_fits |&gt;\n  collect_metrics()\n\n# A tibble: 25 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1    0.0000000001          1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 2    0.0000000178          1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 3    0.00000316            1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 4    0.000562              1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 5    0.1                   1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 6    0.0000000001          4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 7    0.0000000178          4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 8    0.00000316            4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n 9    0.000562              4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n10    0.1                   4 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n# ℹ 15 more rows\n\n\nCombine the metrics across the folds, then plot:\n\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  mutate(tree_depth = factor(tree_depth)) |&gt;\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\ntree_fits\n\n# Tuning results\n# 5-fold cross-validation \n# A tibble: 5 × 4\n  splits                 id    .metrics          .notes          \n  &lt;list&gt;                 &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          \n1 &lt;split [142060/35515]&gt; Fold1 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n2 &lt;split [142060/35515]&gt; Fold2 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n3 &lt;split [142060/35515]&gt; Fold3 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n4 &lt;split [142060/35515]&gt; Fold4 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n5 &lt;split [142060/35515]&gt; Fold5 &lt;tibble [25 × 6]&gt; &lt;tibble [0 × 3]&gt;\n\n\nOur best model has a tree_depth of 15 (this minimizes the mean log loss).\nArrange by the mean log loss:\n\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  arrange(mean)\n\n# A tibble: 25 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1    0.0000000001         11 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 2    0.0000000178         11 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 3    0.00000316           11 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 4    0.0000000001         15 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 5    0.0000000178         15 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 6    0.00000316           15 mn_log_loss binary     0.389     5 4.51e-4 Prepro…\n 7    0.0000000001          8 mn_log_loss binary     0.392     5 2.56e-3 Prepro…\n 8    0.0000000178          8 mn_log_loss binary     0.392     5 2.56e-3 Prepro…\n 9    0.00000316            8 mn_log_loss binary     0.392     5 2.56e-3 Prepro…\n10    0.0000000001          1 mn_log_loss binary     0.402     5 7.11e-4 Prepro…\n# ℹ 15 more rows\n\n\nGrab the best model’s tuning parameter values:\n\ntree_best_params &lt;- select_best(tree_fits)\n\nWarning in select_best(tree_fits): No value of `metric` was given;\n\"mn_log_loss\" will be used.\n\ntree_best_params\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1    0.0000000001         11 Preprocessor1_Model16\n\n\nThese are the values for tree_depth and cost_complexity that minimize mean log loss in the dbhi data set.\nFit this chosen model by finalize_workflow() to finalize the model on the training set:\n\ntree_final_wkf &lt;- tree_wkf |&gt;\n  finalize_workflow(tree_best_params)\n\ntree_final_wkf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_dummy()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 11\n  min_n = 10\n\nComputational engine: rpart \n\n\nPerform last_fit() on the dbhi_split object:\n\ntree_final_fit &lt;- tree_final_wkf |&gt;\n  last_fit(dbhi_split, metrics=metric_set(mn_log_loss))\ntree_final_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits                 id            .metrics .notes   .predictions .workflow \n  &lt;list&gt;                 &lt;chr&gt;         &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [177575/76105]&gt; train/test s… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\n\nThis has information about how the final fitted model - which was fit on the entire training data set - performs on the test set.\nLook at the metric with collect_metrics():\n\ntree_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 mn_log_loss binary         0.396 Preprocessor1_Model1\n\n\nPlot to learn about the fit:\n\n#Extract the workflow to better understand the structure of the plot!\ntree_final_model &lt;- extract_workflow(tree_final_fit)\n\n#Plot!\ntree_final_model &lt;- tree_final_model |&gt;\n  extract_fit_engine() |&gt;\n  rpart.plot::rpart.plot(roundint = FALSE,extra=101,digits=-6)\n\n\n\n\n\n\n\ntree_final_model\n\n$obj\nn= 177575 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 177575 24553 no diabetes (0.8617317 0.1382683)  \n    2) HeartDiseaseorAttack_yes&lt; 1.386034 160791 19073 no diabetes (0.8813802 0.1186198) *\n    3) HeartDiseaseorAttack_yes&gt;=1.386034 16784  5480 no diabetes (0.6734986 0.3265014)  \n      6) Stroke_yes&lt; 2.322867 13995  4337 no diabetes (0.6901036 0.3098964) *\n      7) Stroke_yes&gt;=2.322867 2789  1143 no diabetes (0.5901757 0.4098243)  \n       14) HvyAlcoholConsump_yes&gt;=1.923615 83    16 no diabetes (0.8072289 0.1927711)  \n         28) Income_X.50.000.to.less.than..75.000&gt;=0.8810366 5     0 no diabetes (1.0000000 0.0000000) *\n         29) Income_X.50.000.to.less.than..75.000&lt; 0.8810366 78    16 no diabetes (0.7948718 0.2051282)  \n           58) Income_X.75.000.or.more&gt;=0.2976892 16     2 no diabetes (0.8750000 0.1250000) *\n           59) Income_X.75.000.or.more&lt; 0.2976892 62    14 no diabetes (0.7741935 0.2258065)  \n            118) Income_X.25.000.to.less.than..35.000&gt;=1.316765 9     1 no diabetes (0.8888889 0.1111111) *\n            119) Income_X.25.000.to.less.than..35.000&lt; 1.316765 53    13 no diabetes (0.7547170 0.2452830)  \n              238) Sex_male&gt;=0.120171 29     6 no diabetes (0.7931034 0.2068966) *\n              239) Sex_male&lt; 0.120171 24     7 no diabetes (0.7083333 0.2916667)  \n                478) Income_X.35.000.to.less.than..50.000&lt; 1.010926 17     3 no diabetes (0.8235294 0.1764706) *\n                479) Income_X.35.000.to.less.than..50.000&gt;=1.010926 7     3 prediabetes or diabetes (0.4285714 0.5714286) *\n       15) HvyAlcoholConsump_yes&lt; 1.923615 2706  1127 no diabetes (0.5835181 0.4164819) *\n\n$snipped.nodes\nNULL\n\n$xlim\n[1] 0 1\n\n$ylim\n[1] 0 1\n\n$x\n [1] 0.23100161 0.04472613 0.41727710 0.15963341 0.67492078 0.38585713\n [7] 0.27454070 0.49717357 0.38944799 0.60489915 0.50435527 0.70544303\n[13] 0.61926256 0.79162349 0.73416985 0.84907714 0.96398442\n\n$y\n [1] 0.95861553 0.02628681 0.85266909 0.02628681 0.74672264 0.64077620\n [7] 0.02628681 0.53482975 0.02628681 0.42888330 0.02628681 0.32293686\n[13] 0.02628681 0.21699041 0.02628681 0.02628681 0.02628681\n\n$branch.x\n       [,1]       [,2]      [,3]      [,4]      [,5]      [,6]      [,7]\nx 0.2310016 0.04472613 0.4172771 0.1596334 0.6749208 0.3858571 0.2745407\n         NA 0.04472613 0.4172771 0.1596334 0.6749208 0.3858571 0.2745407\n         NA 0.23100161 0.2310016 0.4172771 0.4172771 0.6749208 0.3858571\n       [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]\nx 0.4971736 0.3894480 0.6048992 0.5043553 0.7054430 0.6192626 0.7916235\n  0.4971736 0.3894480 0.6048992 0.5043553 0.7054430 0.6192626 0.7916235\n  0.3858571 0.4971736 0.4971736 0.6048992 0.6048992 0.7054430 0.7054430\n      [,15]     [,16]     [,17]\nx 0.7341698 0.8490771 0.9639844\n  0.7341698 0.8490771 0.9639844\n  0.7916235 0.7916235 0.6749208\n\n$branch.y\n       [,1]       [,2]      [,3]       [,4]      [,5]      [,6]       [,7]\ny 0.9997651 0.06743639 0.8938187 0.06743639 0.7878722 0.6819258 0.06743639\n         NA 0.91327376 0.9132738 0.80732732 0.8073273 0.7013809 0.59543442\n         NA 0.91327376 0.9132738 0.80732732 0.8073273 0.7013809 0.59543442\n       [,8]       [,9]     [,10]      [,11]     [,12]      [,13]     [,14]\ny 0.5759793 0.06743639 0.4700329 0.06743639 0.3640864 0.06743639 0.2581400\n  0.5954344 0.48948798 0.4894880 0.38354153 0.3835415 0.27759509 0.2775951\n  0.5954344 0.48948798 0.4894880 0.38354153 0.3835415 0.27759509 0.2775951\n       [,15]      [,16]      [,17]\ny 0.06743639 0.06743639 0.06743639\n  0.17164864 0.17164864 0.70138087\n  0.17164864 0.17164864 0.70138087\n\n$labs\n [1] \"no diabetes\\n153022  24553\\n100.0000%\" \n [2] \"no diabetes\\n141718  19073\\n90.5482%\"  \n [3] \"no diabetes\\n11304  5480\\n9.4518%\"     \n [4] \"no diabetes\\n9658  4337\\n7.8812%\"      \n [5] \"no diabetes\\n1646  1143\\n1.5706%\"      \n [6] \"no diabetes\\n67  16\\n0.0467%\"          \n [7] \"no diabetes\\n5  0\\n0.0028%\"            \n [8] \"no diabetes\\n62  16\\n0.0439%\"          \n [9] \"no diabetes\\n14  2\\n0.0090%\"           \n[10] \"no diabetes\\n48  14\\n0.0349%\"          \n[11] \"no diabetes\\n8  1\\n0.0051%\"            \n[12] \"no diabetes\\n40  13\\n0.0298%\"          \n[13] \"no diabetes\\n23  6\\n0.0163%\"           \n[14] \"no diabetes\\n17  7\\n0.0135%\"           \n[15] \"no diabetes\\n14  3\\n0.0096%\"           \n[16] \"prediabetes or diabetes\\n3  4\\n0.0039%\"\n[17] \"no diabetes\\n1579  1127\\n1.5239%\"      \n\n$cex\n[1] 0.4625\n\n$boxes\n$boxes$x1\n [1]  0.183660439 -0.002615046  0.376951032  0.121767869  0.637055236\n [6]  0.347991591  0.236675157  0.459308026  0.351582444  0.567033608\n[11]  0.466489731  0.667577484  0.581397019  0.753757950  0.696304306\n[16]  0.777906774  0.926118881\n\n$boxes$y1\n [1]  0.930420747 -0.001907977  0.824474301 -0.001907977  0.718527855\n [6]  0.612581409 -0.001907977  0.506634963 -0.001907977  0.400688517\n[11] -0.001907977  0.294742071 -0.001907977  0.188795625 -0.001907977\n[16] -0.001907977 -0.001907977\n\n$boxes$x2\n [1] 0.2783428 0.0920673 0.4576032 0.1974990 0.7127863 0.4237227 0.3124062\n [8] 0.5350391 0.4273135 0.6427647 0.5422208 0.7433086 0.6571281 0.8294890\n[15] 0.7720354 0.9202475 1.0018500\n\n$boxes$y2\n [1] 0.99976511 0.06743639 0.89381867 0.06743639 0.78787222 0.68192578\n [7] 0.06743639 0.57597933 0.06743639 0.47003288 0.06743639 0.36408644\n[13] 0.06743639 0.25813999 0.06743639 0.06743639 0.06743639\n\n\n$split.labs\n[1] \"\"\n\n$split.cex\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n$split.box\n$split.box$x1\n [1] 0.1161793        NA 0.3483794        NA 0.5581954 0.2329999        NA\n [8] 0.3786743        NA 0.4555495        NA 0.6339093        NA 0.6459569\n[15]        NA        NA        NA\n\n$split.box$y1\n [1] 0.9003190        NA 0.7943725        NA 0.6884261 0.5824796        NA\n [8] 0.4765332        NA 0.3705867        NA 0.2646403        NA 0.1586938\n[15]        NA        NA        NA\n\n$split.box$x2\n [1] 0.3458239        NA 0.4861748        NA 0.7916462 0.5387144        NA\n [8] 0.6156728        NA 0.7542488        NA 0.7769768        NA 0.9372901\n[15]        NA        NA        NA\n\n$split.box$y2\n [1] 0.9262286        NA 0.8202821        NA 0.7143357 0.6083892        NA\n [8] 0.5024428        NA 0.3964963        NA 0.2905499        NA 0.1846034\n[15]        NA        NA        NA\n\n\n\n\nRandom Forest\nYou should provide a thorough explanation of what a random forest is and why we might use it (be sure to relate this to a basic classification tree). You should then fit a random forest model with varying values for the mtry parameter and choose the best model (based on 5 fold CV on the training set). Include at least 5 predictors in this model."
  },
  {
    "objectID": "Modeling.html#final-model-selection",
    "href": "Modeling.html#final-model-selection",
    "title": "Modeling",
    "section": "Final Model Selection",
    "text": "Final Model Selection\nWe will compare the best models from each of the approaches on the test set and declare an overall winner…\nGet the random forest (rf) specification:\n\nrf_spec &lt;- rand_forest(mtry = tune()) |&gt;\n set_engine(\"ranger\", importance=\"impurity\") |&gt;\n set_mode(\"classification\")\n\nCreate the workflow using the same recipe:\n\nrf_wkf &lt;- workflow() |&gt;\n add_recipe(dbhi_recipe) |&gt;\n add_model(rf_spec)\n\nFit to the cross-validation folds:\n\nrf_fit &lt;- rf_wkf |&gt;\n tune_grid(resamples = dbhi_5_fold,\n           grid = 7,\n           metrics = metric_set(mn_log_loss))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\nArrange by the mean log loss:\n\nrf_fit |&gt;\n collect_metrics() |&gt;\n arrange(mean)\n\n# A tibble: 7 × 7\n   mtry .metric     .estimator  mean     n  std_err .config             \n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1     9 mn_log_loss binary     0.375     5 0.000680 Preprocessor1_Model6\n2     8 mn_log_loss binary     0.375     5 0.000696 Preprocessor1_Model7\n3    10 mn_log_loss binary     0.375     5 0.000663 Preprocessor1_Model3\n4     6 mn_log_loss binary     0.376     5 0.000737 Preprocessor1_Model2\n5     4 mn_log_loss binary     0.376     5 0.000772 Preprocessor1_Model5\n6     3 mn_log_loss binary     0.376     5 0.000757 Preprocessor1_Model1\n7     2 mn_log_loss binary     0.378     5 0.000729 Preprocessor1_Model4\n\n\nObtain the best tuning parameter, use it to refit on the entire training set, then extract the final model:\n\nrf_best_params &lt;- select_best(rf_fit)\n\nWarning in select_best(rf_fit): No value of `metric` was given; \"mn_log_loss\"\nwill be used.\n\nrf_best_params\n\n# A tibble: 1 × 2\n   mtry .config             \n  &lt;int&gt; &lt;chr&gt;               \n1     9 Preprocessor1_Model6\n\nrf_final_wkf &lt;- rf_wkf |&gt;\n  finalize_workflow(rf_best_params)\n\nrf_final_fit &lt;- rf_final_wkf |&gt;\n  last_fit(dbhi_split, metrics = metric_set(mn_log_loss))\n\n#Investigate the random forest model\n#Refit to the entire data set\nrf_full_fit &lt;- rf_final_wkf |&gt;\n  fit(dbhi_data)\nrf_full_fit\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_dummy()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~9L,      x), importance = ~\"impurity\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  500 \nSample size:                      253680 \nNumber of independent variables:  11 \nMtry:                             9 \nTarget node size:                 10 \nVariable importance mode:         impurity \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.1128596 \n\n#rf_final_model &lt;- extract_fit_engine(rf_full_fit)\nrf_final_model &lt;- extract_fit_engine(rf_final_fit)\nattributes(rf_final_model)\n\n$names\n [1] \"predictions\"               \"num.trees\"                \n [3] \"num.independent.variables\" \"mtry\"                     \n [5] \"min.node.size\"             \"variable.importance\"      \n [7] \"prediction.error\"          \"forest\"                   \n [9] \"splitrule\"                 \"treetype\"                 \n[11] \"call\"                      \"importance.mode\"          \n[13] \"num.samples\"               \"replace\"                  \n[15] \"max.depth\"                \n\n$class\n[1] \"ranger\"\n\n\nCollect the metrics:\n\nrf_final_fit |&gt; collect_metrics()\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 mn_log_loss binary         0.381 Preprocessor1_Model1\n\n\nProduce a variable importance plot to examine the final model:\n\nimp &lt;- enframe(rf_final_model$variable.importance,\n        name = \"variable\",\n        value = \"importance\")\nggplot(imp, aes(x = reorder(variable, -importance), y = importance)) +\n  geom_bar(stat = 'identity') + \n  xlab('term') +\n  ylab('value') +\n  coord_flip()"
  }
]